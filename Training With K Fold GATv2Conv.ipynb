{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import Draw\n",
    "import networkx as nx\n",
    "from torch_geometric.datasets import MoleculeNet\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import model_selection, preprocessing, metrics, decomposition\n",
    "\n",
    "import torch\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json,pickle\n",
    "from collections import OrderedDict\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import MolFromSmiles\n",
    "import networkx as nx\n",
    "\n",
    "from torch_geometric.data import InMemoryDataset, Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm.notebook import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import Data_Prep.Graph_Data as gd\n",
    "from Data_Prep.Graph_Data import Molecule_data\n",
    "from math import sqrt\n",
    "# from torch_geometric.nn import GATv2Conv\n",
    "from models.attenFP_v1 import AttentionConvNet\n",
    "# from optuna_v1.attenFP_v1 import AttentionConvNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createFoldsData():\n",
    "    iy = 0\n",
    "    folds = 10\n",
    "    for fold in tqdm(range(folds)):\n",
    "        df_train = pd.read_csv('New_fold/fold_'+str(iy)+'_'+'x_train.csv')\n",
    "        df_test  = pd.read_csv('New_fold/fold_'+str(iy)+'_'+'x_test.csv')\n",
    "        smiles = df_train['SMILES']\n",
    "#         codIds = df_train['CODID']\n",
    "        band_gap = df_train['logS']\n",
    "        band_gap = band_gap.to_numpy()\n",
    "\n",
    "        smiles_test = df_test['SMILES']\n",
    "#         codIds_test = df_test['CODID']\n",
    "        band_gap_test = df_test['logS']\n",
    "        band_gap_test = band_gap_test.to_numpy()\n",
    "\n",
    "\n",
    "        smile_graph = {}\n",
    "        band_gap_arr = []\n",
    "        smiles_array = []\n",
    "\n",
    "        for i,smile in enumerate(smiles):\n",
    "            g = gd.smile_to_graph(smile)\n",
    "            if g != None:\n",
    "                smile_graph[smile] = g\n",
    "                band_gap_arr.append(band_gap[i])\n",
    "                smiles_array.append(smile)\n",
    "\n",
    "        smile_graph_test = {}\n",
    "        band_gap_arr_test = []\n",
    "        smiles_array_test = []\n",
    "\n",
    "        for i,smile in enumerate(smiles_test):\n",
    "            g = gd.smile_to_graph(smile)\n",
    "            if g != None:\n",
    "                smile_graph_test[smile] = g\n",
    "                band_gap_arr_test.append(band_gap_test[i])\n",
    "                smiles_array_test.append(smile)\n",
    "\n",
    "        train_data = Molecule_data(root='data', dataset='train_data_set_fold_'+str(iy),y=band_gap_arr,\n",
    "                                   smile_graph=smile_graph,smiles=smiles_array)\n",
    "\n",
    "        test_data = Molecule_data(root='data', dataset='test_data_set_fold_'+str(iy),y=band_gap_arr_test,\n",
    "                                   smile_graph=smile_graph_test,smiles=smiles_array_test)\n",
    "\n",
    "        iy+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Data_Prep/solubility_1.csv')\n",
    "df = df.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "smiles = df['SMILES']\n",
    "# codIds = df['CODID']\n",
    "band_gap = df['logS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "band_gap = band_gap.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createFoldsCsv():\n",
    "    from sklearn.model_selection import StratifiedKFold\n",
    "    from sklearn.model_selection import KFold\n",
    "    kf = KFold(n_splits=10,shuffle = True, random_state = 2) #, random_state = 2\n",
    "    ix = 0\n",
    "    train1 = df\n",
    "    for train_index, test_index in (kf.split(train1)):\n",
    "        print (\"TRAIN:\", len(train_index), \"TEST:\", len(test_index))\n",
    "        X_train,X_test=train1.iloc[train_index], train1.iloc[test_index]\n",
    "        X_train.to_csv('New_fold/fold_'+str(ix)+'_'+'x_train.csv',index=False)\n",
    "        X_test.to_csv('New_fold/fold_'+str(ix)+'_'+'x_test.csv',index=False)\n",
    "        ix+=1\n",
    "    createFoldsData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data_file_train = 'data/processed/' + 'train_data_set_fold_'+str(0)+'.pt'\n",
    "processed_data_file_test = 'data/processed/'  + 'test_data_set_fold_'+str(0)+'.pt'\n",
    "if ((not os.path.isfile(processed_data_file_train)) or (not os.path.isfile(processed_data_file_test))):\n",
    "        print('please run create_data.py to prepare data in pytorch format!')\n",
    "        createFoldsCsv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:7\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():  \n",
    "    device = \"cuda:7\"\n",
    "    print(\"cuda:7\")\n",
    "else:  \n",
    "    device = \"cpu\" \n",
    "    print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer,train_loader):\n",
    "    train_labels = 0\n",
    "    train_predictions = 0\n",
    "    total_loss = total_examples = 0\n",
    "    for data in train_loader:\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data)\n",
    "        # out = model(data)\n",
    "        y = data.y.view([-1])\n",
    "        out1 = out.view([-1])\n",
    "        # print(\"train : \", y.shape)\n",
    "        loss = F.mse_loss(out1, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "#         train_labels += train_labels + y\n",
    "#         train_predictions += train_predictions + out1\n",
    "        total_loss += float(loss) * data.num_graphs\n",
    "        total_examples += data.num_graphs\n",
    "    return total_loss,sqrt(total_loss / total_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def test(loader, model):\n",
    "    # mse = []\n",
    "    model.eval()\n",
    "    total_preds = torch.Tensor()\n",
    "    total_labels = torch.Tensor()\n",
    "    total_loss = total_examples = 0\n",
    "    for data in loader:\n",
    "        data = data.to(device)\n",
    "        out = model(data)\n",
    "        # out = model(data)\n",
    "        # mse.append(F.mse_loss(out, data.y, reduction='none').cpu())\n",
    "        # return float(torch.cat(mse, dim=0).mean().sqrt())\n",
    "        y = data.y.view([-1])\n",
    "        out1 = out.view([-1])\n",
    "        # print(\"test : \", y.shape)\n",
    "        test_loss = F.mse_loss(out1, y)\n",
    "        # print(\"no of graphs: \", data.num_graphs)\n",
    "        total_loss += float(test_loss) * data.num_graphs\n",
    "        total_examples += data.num_graphs\n",
    "#         total_preds = torch.cat((total_preds, out1.cpu()), 0)\n",
    "#         total_labels = torch.cat((total_labels, data.y.view(-1, 1).cpu()), 0)\n",
    "        # mse.append(test_loss).cpu()\n",
    "    # return test_loss,float(torch.cat(mse, dim=0).mean().sqrt())\n",
    "    return total_loss,sqrt(total_loss / total_examples) #,total_labels.numpy().flatten(),total_preds.numpy().flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the model.\n",
    "\n",
    "# optimizer = torch.optim.RMSprop(model.parameters(), lr=0.0021931604377098835,\n",
    "#                                weight_decay=1.2733069489371785e-05)\n",
    "the_last_loss = 100\n",
    "patience = 30\n",
    "trigger_times = 0\n",
    "count_loss_difference = 0\n",
    "#LR = 0.005\n",
    "learning_rate = 0.00688267742977242\n",
    "weight_decay=0.000307616688331247\n",
    "#LR = 0.0028894537419258915\n",
    "LOG_INTERVAL = 20\n",
    "NUM_EPOCHS = 200\n",
    "results = []\n",
    "TRAIN_BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_ret = []\n",
    "best_mse = 0.80\n",
    "best_ci = 0\n",
    "best_epoch = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff523094b0a64069945b3ba258ef6b40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 1.7414 Test: 1.3998 \n",
      "Epoch: 001, Loss: 1.4517 Test: 1.4380 \n",
      "trigger times: 1\n",
      "Epoch: 002, Loss: 1.3908 Test: 1.3181 \n",
      "Epoch: 003, Loss: 1.3960 Test: 1.3828 \n",
      "trigger times: 1\n",
      "Epoch: 004, Loss: 1.3700 Test: 1.2738 \n",
      "Epoch: 005, Loss: 1.3461 Test: 1.2370 \n",
      "Epoch: 006, Loss: 1.3548 Test: 1.3104 \n",
      "trigger times: 1\n",
      "Epoch: 007, Loss: 1.3390 Test: 1.2331 \n",
      "Epoch: 008, Loss: 1.3344 Test: 1.2506 \n",
      "trigger times: 1\n",
      "Epoch: 009, Loss: 1.3303 Test: 1.2198 \n",
      "Epoch: 010, Loss: 1.3366 Test: 1.2300 \n",
      "trigger times: 1\n",
      "Epoch: 011, Loss: 1.3300 Test: 1.2250 \n",
      "trigger times: 2\n",
      "Epoch: 012, Loss: 1.3231 Test: 1.2289 \n",
      "trigger times: 3\n",
      "Epoch: 013, Loss: 1.3214 Test: 1.2199 \n",
      "trigger times: 4\n",
      "Epoch: 014, Loss: 1.3199 Test: 1.2101 \n",
      "Epoch: 015, Loss: 1.3276 Test: 1.2275 \n",
      "trigger times: 1\n",
      "Epoch: 016, Loss: 1.3230 Test: 1.2305 \n",
      "trigger times: 2\n",
      "Epoch: 017, Loss: 1.3381 Test: 1.2233 \n",
      "trigger times: 3\n",
      "Epoch: 018, Loss: 1.3322 Test: 1.2292 \n",
      "trigger times: 4\n",
      "Epoch: 019, Loss: 1.3186 Test: 1.3194 \n",
      "trigger times: 5\n",
      "Epoch: 020, Loss: 1.3370 Test: 1.2118 \n",
      "trigger times: 6\n",
      "Epoch: 021, Loss: 1.3143 Test: 1.2207 \n",
      "trigger times: 7\n",
      "Epoch: 022, Loss: 1.3264 Test: 1.3761 \n",
      "trigger times: 8\n",
      "Epoch: 023, Loss: 1.3341 Test: 1.2508 \n",
      "trigger times: 9\n",
      "Epoch: 024, Loss: 1.3246 Test: 1.2311 \n",
      "trigger times: 10\n",
      "Epoch: 025, Loss: 1.3309 Test: 1.3027 \n",
      "trigger times: 11\n",
      "Epoch: 026, Loss: 1.3285 Test: 1.2132 \n",
      "trigger times: 12\n",
      "Epoch: 027, Loss: 1.3398 Test: 1.2424 \n",
      "trigger times: 13\n",
      "Epoch: 028, Loss: 1.3213 Test: 1.2130 \n",
      "trigger times: 14\n",
      "Epoch: 029, Loss: 1.3120 Test: 1.3606 \n",
      "trigger times: 15\n",
      "Epoch: 030, Loss: 1.3330 Test: 1.2780 \n",
      "trigger times: 16\n",
      "Epoch: 031, Loss: 1.3361 Test: 1.2162 \n",
      "trigger times: 17\n",
      "Epoch: 032, Loss: 1.3284 Test: 1.2099 \n",
      "Epoch: 033, Loss: 1.3326 Test: 1.2910 \n",
      "trigger times: 1\n",
      "Epoch: 034, Loss: 1.3242 Test: 1.2077 \n",
      "Epoch: 035, Loss: 1.3254 Test: 1.2598 \n",
      "trigger times: 1\n",
      "Epoch: 036, Loss: 1.3190 Test: 1.2884 \n",
      "trigger times: 2\n",
      "Epoch: 037, Loss: 1.3257 Test: 1.2135 \n",
      "trigger times: 3\n",
      "Epoch: 038, Loss: 1.3344 Test: 1.2159 \n",
      "trigger times: 4\n",
      "Epoch: 039, Loss: 1.3305 Test: 1.2536 \n",
      "trigger times: 5\n",
      "Epoch: 040, Loss: 1.3562 Test: 1.2241 \n",
      "trigger times: 6\n",
      "Epoch: 041, Loss: 1.3332 Test: 1.2078 \n",
      "trigger times: 7\n",
      "Epoch: 042, Loss: 1.3327 Test: 1.2126 \n",
      "trigger times: 8\n",
      "Epoch: 043, Loss: 1.3449 Test: 1.3396 \n",
      "trigger times: 9\n",
      "Epoch: 044, Loss: 1.3238 Test: 1.2416 \n",
      "trigger times: 10\n",
      "Epoch: 045, Loss: 1.3403 Test: 1.2322 \n",
      "trigger times: 11\n",
      "Epoch: 046, Loss: 1.3092 Test: 1.2421 \n",
      "trigger times: 12\n",
      "Epoch: 047, Loss: 1.3441 Test: 1.2151 \n",
      "trigger times: 13\n",
      "Epoch: 048, Loss: 1.3099 Test: 1.2832 \n",
      "trigger times: 14\n",
      "Epoch: 049, Loss: 1.3337 Test: 1.2301 \n",
      "trigger times: 15\n",
      "Epoch: 050, Loss: 1.3312 Test: 1.3687 \n",
      "trigger times: 16\n",
      "Epoch: 051, Loss: 1.3429 Test: 1.2196 \n",
      "trigger times: 17\n",
      "Epoch: 052, Loss: 1.3141 Test: 1.2696 \n",
      "trigger times: 18\n",
      "Epoch: 053, Loss: 1.3224 Test: 1.2359 \n",
      "trigger times: 19\n",
      "Epoch: 054, Loss: 1.3285 Test: 1.2247 \n",
      "trigger times: 20\n",
      "Epoch: 055, Loss: 1.3348 Test: 1.2096 \n",
      "trigger times: 21\n",
      "Epoch: 056, Loss: 1.3184 Test: 1.2576 \n",
      "trigger times: 22\n",
      "Epoch: 057, Loss: 1.3236 Test: 1.2568 \n",
      "trigger times: 23\n",
      "Epoch: 058, Loss: 1.3300 Test: 1.2211 \n",
      "trigger times: 24\n",
      "Epoch: 059, Loss: 1.3201 Test: 1.2146 \n",
      "trigger times: 25\n",
      "Epoch: 060, Loss: 1.3280 Test: 1.2490 \n",
      "trigger times: 26\n",
      "Epoch: 061, Loss: 1.3529 Test: 1.2348 \n",
      "trigger times: 27\n",
      "Epoch: 062, Loss: 1.3406 Test: 1.2628 \n",
      "trigger times: 28\n",
      "Epoch: 063, Loss: 1.3217 Test: 1.3200 \n",
      "trigger times: 29\n",
      "Epoch: 064, Loss: 1.3302 Test: 1.2585 \n",
      "trigger times: 30\n",
      "Early stopping!\n",
      "Start to test process.\n",
      "Epoch: 000, Loss: 2.2771 Test: 1.5704 \n",
      "Epoch: 001, Loss: 1.4973 Test: 1.4831 \n",
      "Epoch: 002, Loss: 1.4232 Test: 1.4124 \n",
      "Epoch: 003, Loss: 1.3906 Test: 1.4006 \n",
      "Epoch: 004, Loss: 1.3630 Test: 1.4001 \n",
      "Epoch: 005, Loss: 1.3619 Test: 1.3930 \n",
      "Epoch: 006, Loss: 1.3395 Test: 1.3981 \n",
      "trigger times: 1\n",
      "Epoch: 007, Loss: 1.3417 Test: 1.3709 \n",
      "Epoch: 008, Loss: 1.3400 Test: 1.3804 \n",
      "trigger times: 1\n",
      "Epoch: 009, Loss: 1.3289 Test: 1.3901 \n",
      "trigger times: 2\n",
      "Epoch: 010, Loss: 1.3349 Test: 1.3847 \n",
      "trigger times: 3\n",
      "Epoch: 011, Loss: 1.3311 Test: 1.3833 \n",
      "trigger times: 4\n",
      "Epoch: 012, Loss: 1.3348 Test: 1.4154 \n",
      "trigger times: 5\n",
      "Epoch: 013, Loss: 1.3497 Test: 1.3858 \n",
      "trigger times: 6\n",
      "Epoch: 014, Loss: 1.3563 Test: 1.4276 \n",
      "trigger times: 7\n",
      "Epoch: 015, Loss: 1.3452 Test: 1.3852 \n",
      "trigger times: 8\n",
      "Epoch: 016, Loss: 1.3307 Test: 1.4002 \n",
      "trigger times: 9\n",
      "Epoch: 017, Loss: 1.3300 Test: 1.3815 \n",
      "trigger times: 10\n",
      "Epoch: 018, Loss: 1.3389 Test: 1.3641 \n",
      "Epoch: 019, Loss: 1.3537 Test: 1.4367 \n",
      "trigger times: 1\n",
      "Epoch: 020, Loss: 1.3420 Test: 1.3827 \n",
      "trigger times: 2\n",
      "Epoch: 021, Loss: 1.3347 Test: 1.4146 \n",
      "trigger times: 3\n",
      "Epoch: 022, Loss: 1.3343 Test: 1.4240 \n",
      "trigger times: 4\n",
      "Epoch: 023, Loss: 1.3533 Test: 1.3625 \n",
      "Epoch: 024, Loss: 1.3429 Test: 1.3686 \n",
      "trigger times: 1\n",
      "Epoch: 025, Loss: 1.3312 Test: 1.3907 \n",
      "trigger times: 2\n",
      "Epoch: 026, Loss: 1.3479 Test: 1.3899 \n",
      "trigger times: 3\n",
      "Epoch: 027, Loss: 1.3415 Test: 1.3909 \n",
      "trigger times: 4\n",
      "Epoch: 028, Loss: 1.3282 Test: 1.3733 \n",
      "trigger times: 5\n",
      "Epoch: 029, Loss: 1.3436 Test: 1.3703 \n",
      "trigger times: 6\n",
      "Epoch: 030, Loss: 1.3517 Test: 1.4315 \n",
      "trigger times: 7\n",
      "Epoch: 031, Loss: 1.3270 Test: 1.3773 \n",
      "trigger times: 8\n",
      "Epoch: 032, Loss: 1.3554 Test: 1.3872 \n",
      "trigger times: 9\n",
      "Epoch: 033, Loss: 1.3462 Test: 1.3843 \n",
      "trigger times: 10\n",
      "Epoch: 034, Loss: 1.3417 Test: 1.4019 \n",
      "trigger times: 11\n",
      "Epoch: 035, Loss: 1.3390 Test: 1.3720 \n",
      "trigger times: 12\n",
      "Epoch: 036, Loss: 1.3438 Test: 1.4231 \n",
      "trigger times: 13\n",
      "Epoch: 037, Loss: 1.3437 Test: 1.3710 \n",
      "trigger times: 14\n",
      "Epoch: 038, Loss: 1.3518 Test: 1.3988 \n",
      "trigger times: 15\n",
      "Epoch: 039, Loss: 1.3639 Test: 1.3619 \n",
      "Epoch: 040, Loss: 1.3523 Test: 1.3801 \n",
      "trigger times: 1\n",
      "Epoch: 041, Loss: 1.3451 Test: 1.6068 \n",
      "trigger times: 2\n",
      "Epoch: 042, Loss: 1.3514 Test: 1.4430 \n",
      "trigger times: 3\n",
      "Epoch: 043, Loss: 1.3266 Test: 1.3941 \n",
      "trigger times: 4\n",
      "Epoch: 044, Loss: 1.3371 Test: 1.3603 \n",
      "Epoch: 045, Loss: 1.3299 Test: 1.4953 \n",
      "trigger times: 1\n",
      "Epoch: 046, Loss: 1.3376 Test: 1.3983 \n",
      "trigger times: 2\n",
      "Epoch: 047, Loss: 1.3273 Test: 1.4126 \n",
      "trigger times: 3\n",
      "Epoch: 048, Loss: 1.3414 Test: 1.3759 \n",
      "trigger times: 4\n",
      "Epoch: 049, Loss: 1.3263 Test: 1.3633 \n",
      "trigger times: 5\n",
      "Epoch: 050, Loss: 1.3720 Test: 1.3691 \n",
      "trigger times: 6\n",
      "Epoch: 051, Loss: 1.3400 Test: 1.3706 \n",
      "trigger times: 7\n",
      "Epoch: 052, Loss: 1.3393 Test: 1.5031 \n",
      "trigger times: 8\n",
      "Epoch: 053, Loss: 1.3592 Test: 1.3610 \n",
      "trigger times: 9\n",
      "Epoch: 054, Loss: 1.3288 Test: 1.3837 \n",
      "trigger times: 10\n",
      "Epoch: 055, Loss: 1.3225 Test: 1.3637 \n",
      "trigger times: 11\n",
      "Epoch: 056, Loss: 1.3503 Test: 1.3640 \n",
      "trigger times: 12\n",
      "Epoch: 057, Loss: 1.3257 Test: 1.3785 \n",
      "trigger times: 13\n",
      "Epoch: 058, Loss: 1.3376 Test: 1.3799 \n",
      "trigger times: 14\n",
      "Epoch: 059, Loss: 1.3367 Test: 1.3671 \n",
      "trigger times: 15\n",
      "Epoch: 060, Loss: 1.3502 Test: 1.3773 \n",
      "trigger times: 16\n",
      "Epoch: 061, Loss: 1.3487 Test: 1.3707 \n",
      "trigger times: 17\n",
      "Epoch: 062, Loss: 1.3453 Test: 1.3752 \n",
      "trigger times: 18\n",
      "Epoch: 063, Loss: 1.3434 Test: 1.3771 \n",
      "trigger times: 19\n",
      "Epoch: 064, Loss: 1.3666 Test: 1.4044 \n",
      "trigger times: 20\n",
      "Epoch: 065, Loss: 1.3589 Test: 1.3651 \n",
      "trigger times: 21\n",
      "Epoch: 066, Loss: 1.3369 Test: 1.3728 \n",
      "trigger times: 22\n",
      "Epoch: 067, Loss: 1.3250 Test: 1.3725 \n",
      "trigger times: 23\n",
      "Epoch: 068, Loss: 1.3284 Test: 1.3658 \n",
      "trigger times: 24\n",
      "Epoch: 069, Loss: 1.3293 Test: 1.3682 \n",
      "trigger times: 25\n",
      "Epoch: 070, Loss: 1.3387 Test: 1.3938 \n",
      "trigger times: 26\n",
      "Epoch: 071, Loss: 1.3348 Test: 1.3748 \n",
      "trigger times: 27\n",
      "Epoch: 072, Loss: 1.3362 Test: 1.3936 \n",
      "trigger times: 28\n",
      "Epoch: 073, Loss: 1.3442 Test: 1.5179 \n",
      "trigger times: 29\n",
      "Epoch: 074, Loss: 1.3563 Test: 1.3725 \n",
      "trigger times: 30\n",
      "Early stopping!\n",
      "Start to test process.\n",
      "Epoch: 000, Loss: 2.5134 Test: 1.7516 \n",
      "Epoch: 001, Loss: 1.6280 Test: 1.4875 \n",
      "Epoch: 002, Loss: 1.4521 Test: 1.3627 \n",
      "Epoch: 003, Loss: 1.3598 Test: 1.3526 \n",
      "Epoch: 004, Loss: 1.3380 Test: 1.3202 \n",
      "Epoch: 005, Loss: 1.3008 Test: 1.2974 \n",
      "Epoch: 006, Loss: 1.2921 Test: 1.2889 \n",
      "Epoch: 007, Loss: 1.3007 Test: 1.3029 \n",
      "trigger times: 1\n",
      "Epoch: 008, Loss: 1.2935 Test: 1.3311 \n",
      "trigger times: 2\n",
      "Epoch: 009, Loss: 1.2942 Test: 1.2988 \n",
      "trigger times: 3\n",
      "Epoch: 010, Loss: 1.2964 Test: 1.3025 \n",
      "trigger times: 4\n",
      "Epoch: 011, Loss: 1.2894 Test: 1.3737 \n",
      "trigger times: 5\n",
      "Epoch: 012, Loss: 1.2836 Test: 1.3020 \n",
      "trigger times: 6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 013, Loss: 1.3122 Test: 1.2994 \n",
      "trigger times: 7\n",
      "Epoch: 014, Loss: 1.2961 Test: 1.2983 \n",
      "trigger times: 8\n",
      "Epoch: 015, Loss: 1.2834 Test: 1.2858 \n",
      "Epoch: 016, Loss: 1.2905 Test: 1.3094 \n",
      "trigger times: 1\n",
      "Epoch: 017, Loss: 1.3112 Test: 1.2945 \n",
      "trigger times: 2\n",
      "Epoch: 018, Loss: 1.2961 Test: 1.2976 \n",
      "trigger times: 3\n",
      "Epoch: 019, Loss: 1.2833 Test: 1.2849 \n",
      "Epoch: 020, Loss: 1.2742 Test: 1.3213 \n",
      "trigger times: 1\n",
      "Epoch: 021, Loss: 1.2837 Test: 1.3259 \n",
      "trigger times: 2\n",
      "Epoch: 022, Loss: 1.2801 Test: 1.2843 \n",
      "Epoch: 023, Loss: 1.2866 Test: 1.4912 \n",
      "trigger times: 1\n",
      "Epoch: 024, Loss: 1.2766 Test: 1.2959 \n",
      "trigger times: 2\n",
      "Epoch: 025, Loss: 1.2904 Test: 1.2860 \n",
      "trigger times: 3\n",
      "Epoch: 026, Loss: 1.2843 Test: 1.2888 \n",
      "trigger times: 4\n",
      "Epoch: 027, Loss: 1.2903 Test: 1.3411 \n",
      "trigger times: 5\n",
      "Epoch: 028, Loss: 1.2906 Test: 1.2855 \n",
      "trigger times: 6\n",
      "Epoch: 029, Loss: 1.2784 Test: 1.3014 \n",
      "trigger times: 7\n",
      "Epoch: 030, Loss: 1.2956 Test: 1.2852 \n",
      "trigger times: 8\n",
      "Epoch: 031, Loss: 1.2831 Test: 1.3288 \n",
      "trigger times: 9\n",
      "Epoch: 032, Loss: 1.2747 Test: 1.3236 \n",
      "trigger times: 10\n",
      "Epoch: 033, Loss: 1.3082 Test: 1.3343 \n",
      "trigger times: 11\n",
      "Epoch: 034, Loss: 1.2715 Test: 1.3107 \n",
      "trigger times: 12\n",
      "Epoch: 035, Loss: 1.3034 Test: 1.3294 \n",
      "trigger times: 13\n",
      "Epoch: 036, Loss: 1.3093 Test: 1.2922 \n",
      "trigger times: 14\n",
      "Epoch: 037, Loss: 1.3366 Test: 1.3128 \n",
      "trigger times: 15\n",
      "Epoch: 038, Loss: 1.2992 Test: 1.3173 \n",
      "trigger times: 16\n",
      "Epoch: 039, Loss: 1.2696 Test: 1.3347 \n",
      "trigger times: 17\n",
      "Epoch: 040, Loss: 1.2801 Test: 1.2962 \n",
      "trigger times: 18\n",
      "Epoch: 041, Loss: 1.2927 Test: 1.3225 \n",
      "trigger times: 19\n",
      "Epoch: 042, Loss: 1.2869 Test: 1.3249 \n",
      "trigger times: 20\n",
      "Epoch: 043, Loss: 1.2676 Test: 1.3157 \n",
      "trigger times: 21\n",
      "Epoch: 044, Loss: 1.2997 Test: 1.3330 \n",
      "trigger times: 22\n",
      "Epoch: 045, Loss: 1.2877 Test: 1.3115 \n",
      "trigger times: 23\n",
      "Epoch: 046, Loss: 1.2824 Test: 1.3264 \n",
      "trigger times: 24\n",
      "Epoch: 047, Loss: 1.2935 Test: 1.2754 \n",
      "Epoch: 048, Loss: 1.2772 Test: 1.3057 \n",
      "trigger times: 1\n",
      "Epoch: 049, Loss: 1.2672 Test: 1.3102 \n",
      "trigger times: 2\n",
      "Epoch: 050, Loss: 1.2844 Test: 1.3285 \n",
      "trigger times: 3\n",
      "Epoch: 051, Loss: 1.2676 Test: 1.2813 \n",
      "trigger times: 4\n",
      "Epoch: 052, Loss: 1.2744 Test: 1.2844 \n",
      "trigger times: 5\n",
      "Epoch: 053, Loss: 1.2678 Test: 1.2991 \n",
      "trigger times: 6\n",
      "Epoch: 054, Loss: 1.2644 Test: 1.2882 \n",
      "trigger times: 7\n",
      "Epoch: 055, Loss: 1.2560 Test: 1.2909 \n",
      "trigger times: 8\n",
      "Epoch: 056, Loss: 1.2704 Test: 1.3176 \n",
      "trigger times: 9\n",
      "Epoch: 057, Loss: 1.2773 Test: 1.3785 \n",
      "trigger times: 10\n",
      "Epoch: 058, Loss: 1.2791 Test: 1.3142 \n",
      "trigger times: 11\n",
      "Epoch: 059, Loss: 1.2799 Test: 1.2700 \n",
      "Epoch: 060, Loss: 1.2811 Test: 1.2806 \n",
      "trigger times: 1\n",
      "Epoch: 061, Loss: 1.2707 Test: 1.3241 \n",
      "trigger times: 2\n",
      "Epoch: 062, Loss: 1.2700 Test: 1.3128 \n",
      "trigger times: 3\n",
      "Epoch: 063, Loss: 1.2675 Test: 1.3283 \n",
      "trigger times: 4\n",
      "Epoch: 064, Loss: 1.2937 Test: 1.2808 \n",
      "trigger times: 5\n",
      "Epoch: 065, Loss: 1.2652 Test: 1.2970 \n",
      "trigger times: 6\n",
      "Epoch: 066, Loss: 1.2754 Test: 1.3492 \n",
      "trigger times: 7\n",
      "Epoch: 067, Loss: 1.2929 Test: 1.2801 \n",
      "trigger times: 8\n",
      "Epoch: 068, Loss: 1.2671 Test: 1.2744 \n",
      "trigger times: 9\n",
      "Epoch: 069, Loss: 1.2726 Test: 1.2905 \n",
      "trigger times: 10\n",
      "Epoch: 070, Loss: 1.2718 Test: 1.2918 \n",
      "trigger times: 11\n",
      "Epoch: 071, Loss: 1.2688 Test: 1.3049 \n",
      "trigger times: 12\n",
      "Epoch: 072, Loss: 1.2825 Test: 1.3618 \n",
      "trigger times: 13\n",
      "Epoch: 073, Loss: 1.2952 Test: 1.2824 \n",
      "trigger times: 14\n",
      "Epoch: 074, Loss: 1.2610 Test: 1.3744 \n",
      "trigger times: 15\n",
      "Epoch: 075, Loss: 1.2953 Test: 1.3055 \n",
      "trigger times: 16\n",
      "Epoch: 076, Loss: 1.2698 Test: 1.2975 \n",
      "trigger times: 17\n",
      "Epoch: 077, Loss: 1.2721 Test: 1.2956 \n",
      "trigger times: 18\n",
      "Epoch: 078, Loss: 1.2690 Test: 1.2992 \n",
      "trigger times: 19\n",
      "Epoch: 079, Loss: 1.2664 Test: 1.2977 \n",
      "trigger times: 20\n",
      "Epoch: 080, Loss: 1.2651 Test: 1.3290 \n",
      "trigger times: 21\n",
      "Epoch: 081, Loss: 1.2811 Test: 1.3064 \n",
      "trigger times: 22\n",
      "Epoch: 082, Loss: 1.2549 Test: 1.3152 \n",
      "trigger times: 23\n",
      "Epoch: 083, Loss: 1.2828 Test: 1.3440 \n",
      "trigger times: 24\n",
      "Epoch: 084, Loss: 1.2723 Test: 1.5076 \n",
      "trigger times: 25\n",
      "Epoch: 085, Loss: 1.2875 Test: 1.2896 \n",
      "trigger times: 26\n",
      "Epoch: 086, Loss: 1.2721 Test: 1.2985 \n",
      "trigger times: 27\n",
      "Epoch: 087, Loss: 1.2708 Test: 1.3621 \n",
      "trigger times: 28\n",
      "Epoch: 088, Loss: 1.2749 Test: 1.2972 \n",
      "trigger times: 29\n",
      "Epoch: 089, Loss: 1.2911 Test: 1.2935 \n",
      "trigger times: 30\n",
      "Early stopping!\n",
      "Start to test process.\n",
      "Epoch: 000, Loss: 1.7750 Test: 1.4127 \n",
      "Epoch: 001, Loss: 1.4508 Test: 1.4762 \n",
      "trigger times: 1\n",
      "Epoch: 002, Loss: 1.3775 Test: 1.4593 \n",
      "trigger times: 2\n",
      "Epoch: 003, Loss: 1.3499 Test: 1.2875 \n",
      "Epoch: 004, Loss: 1.3347 Test: 1.2715 \n",
      "Epoch: 005, Loss: 1.3546 Test: 1.2703 \n",
      "Epoch: 006, Loss: 1.3192 Test: 1.2622 \n",
      "Epoch: 007, Loss: 1.3274 Test: 1.2610 \n",
      "Epoch: 008, Loss: 1.3178 Test: 1.2674 \n",
      "trigger times: 1\n",
      "Epoch: 009, Loss: 1.3237 Test: 1.3628 \n",
      "trigger times: 2\n",
      "Epoch: 010, Loss: 1.3175 Test: 1.2846 \n",
      "trigger times: 3\n",
      "Epoch: 011, Loss: 1.3198 Test: 1.2859 \n",
      "trigger times: 4\n",
      "Epoch: 012, Loss: 1.3127 Test: 1.2750 \n",
      "trigger times: 5\n",
      "Epoch: 013, Loss: 1.3095 Test: 1.2576 \n",
      "Epoch: 014, Loss: 1.3165 Test: 1.2651 \n",
      "trigger times: 1\n",
      "Epoch: 015, Loss: 1.3052 Test: 1.2888 \n",
      "trigger times: 2\n",
      "Epoch: 016, Loss: 1.3070 Test: 1.2577 \n",
      "trigger times: 3\n",
      "Epoch: 017, Loss: 1.3494 Test: 1.3262 \n",
      "trigger times: 4\n",
      "Epoch: 018, Loss: 1.3254 Test: 1.4485 \n",
      "trigger times: 5\n",
      "Epoch: 019, Loss: 1.3323 Test: 1.2633 \n",
      "trigger times: 6\n",
      "Epoch: 020, Loss: 1.3041 Test: 1.2641 \n",
      "trigger times: 7\n",
      "Epoch: 021, Loss: 1.3045 Test: 1.3549 \n",
      "trigger times: 8\n",
      "Epoch: 022, Loss: 1.3030 Test: 1.2628 \n",
      "trigger times: 9\n",
      "Epoch: 023, Loss: 1.3144 Test: 1.2911 \n",
      "trigger times: 10\n",
      "Epoch: 024, Loss: 1.3202 Test: 1.2846 \n",
      "trigger times: 11\n",
      "Epoch: 025, Loss: 1.3415 Test: 1.2975 \n",
      "trigger times: 12\n",
      "Epoch: 026, Loss: 1.3111 Test: 1.2938 \n",
      "trigger times: 13\n",
      "Epoch: 027, Loss: 1.3239 Test: 1.2460 \n",
      "Epoch: 028, Loss: 1.3166 Test: 1.2663 \n",
      "trigger times: 1\n",
      "Epoch: 029, Loss: 1.3016 Test: 1.2613 \n",
      "trigger times: 2\n",
      "Epoch: 030, Loss: 1.3002 Test: 1.2664 \n",
      "trigger times: 3\n",
      "Epoch: 031, Loss: 1.3242 Test: 1.3285 \n",
      "trigger times: 4\n",
      "Epoch: 032, Loss: 1.3143 Test: 1.2815 \n",
      "trigger times: 5\n",
      "Epoch: 033, Loss: 1.3352 Test: 1.3868 \n",
      "trigger times: 6\n",
      "Epoch: 034, Loss: 1.3048 Test: 1.2702 \n",
      "trigger times: 7\n",
      "Epoch: 035, Loss: 1.2911 Test: 1.2707 \n",
      "trigger times: 8\n",
      "Epoch: 036, Loss: 1.2969 Test: 1.2696 \n",
      "trigger times: 9\n",
      "Epoch: 037, Loss: 1.3075 Test: 1.3051 \n",
      "trigger times: 10\n",
      "Epoch: 038, Loss: 1.3247 Test: 1.2746 \n",
      "trigger times: 11\n",
      "Epoch: 039, Loss: 1.3237 Test: 1.4179 \n",
      "trigger times: 12\n",
      "Epoch: 040, Loss: 1.3213 Test: 1.2735 \n",
      "trigger times: 13\n",
      "Epoch: 041, Loss: 1.3004 Test: 1.2778 \n",
      "trigger times: 14\n",
      "Epoch: 042, Loss: 1.3000 Test: 1.2570 \n",
      "trigger times: 15\n",
      "Epoch: 043, Loss: 1.2986 Test: 1.2761 \n",
      "trigger times: 16\n",
      "Epoch: 044, Loss: 1.2961 Test: 1.2604 \n",
      "trigger times: 17\n",
      "Epoch: 045, Loss: 1.3018 Test: 1.2903 \n",
      "trigger times: 18\n",
      "Epoch: 046, Loss: 1.3324 Test: 1.2653 \n",
      "trigger times: 19\n",
      "Epoch: 047, Loss: 1.2974 Test: 1.2713 \n",
      "trigger times: 20\n",
      "Epoch: 048, Loss: 1.3001 Test: 1.2647 \n",
      "trigger times: 21\n",
      "Epoch: 049, Loss: 1.3034 Test: 1.2480 \n",
      "trigger times: 22\n",
      "Epoch: 050, Loss: 1.3025 Test: 1.2926 \n",
      "trigger times: 23\n",
      "Epoch: 051, Loss: 1.3124 Test: 1.2621 \n",
      "trigger times: 24\n",
      "Epoch: 052, Loss: 1.3047 Test: 1.2690 \n",
      "trigger times: 25\n",
      "Epoch: 053, Loss: 1.2989 Test: 1.2945 \n",
      "trigger times: 26\n",
      "Epoch: 054, Loss: 1.2957 Test: 1.2695 \n",
      "trigger times: 27\n",
      "Epoch: 055, Loss: 1.2937 Test: 1.2679 \n",
      "trigger times: 28\n",
      "Epoch: 056, Loss: 1.3106 Test: 1.2842 \n",
      "trigger times: 29\n",
      "Epoch: 057, Loss: 1.3066 Test: 1.2629 \n",
      "trigger times: 30\n",
      "Early stopping!\n",
      "Start to test process.\n",
      "Epoch: 000, Loss: 1.7733 Test: 1.4310 \n",
      "Epoch: 001, Loss: 1.4257 Test: 1.3708 \n",
      "Epoch: 002, Loss: 1.3570 Test: 1.4025 \n",
      "trigger times: 1\n",
      "Epoch: 003, Loss: 1.3561 Test: 1.2546 \n",
      "Epoch: 004, Loss: 1.3311 Test: 1.2589 \n",
      "trigger times: 1\n",
      "Epoch: 005, Loss: 1.3163 Test: 1.2215 \n",
      "Epoch: 006, Loss: 1.3413 Test: 1.2564 \n",
      "trigger times: 1\n",
      "Epoch: 007, Loss: 1.3328 Test: 1.2534 \n",
      "trigger times: 2\n",
      "Epoch: 008, Loss: 1.3287 Test: 1.2549 \n",
      "trigger times: 3\n",
      "Epoch: 009, Loss: 1.3099 Test: 1.2416 \n",
      "trigger times: 4\n",
      "Epoch: 010, Loss: 1.3159 Test: 1.2142 \n",
      "Epoch: 011, Loss: 1.3163 Test: 1.2165 \n",
      "trigger times: 1\n",
      "Epoch: 012, Loss: 1.3124 Test: 1.2516 \n",
      "trigger times: 2\n",
      "Epoch: 013, Loss: 1.3367 Test: 1.2467 \n",
      "trigger times: 3\n",
      "Epoch: 014, Loss: 1.3096 Test: 1.2121 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 015, Loss: 1.3177 Test: 1.3604 \n",
      "trigger times: 1\n",
      "Epoch: 016, Loss: 1.3151 Test: 1.2197 \n",
      "trigger times: 2\n",
      "Epoch: 017, Loss: 1.2967 Test: 1.3145 \n",
      "trigger times: 3\n",
      "Epoch: 018, Loss: 1.3047 Test: 1.2293 \n",
      "trigger times: 4\n",
      "Epoch: 019, Loss: 1.3175 Test: 1.2837 \n",
      "trigger times: 5\n",
      "Epoch: 020, Loss: 1.3125 Test: 1.2210 \n",
      "trigger times: 6\n",
      "Epoch: 021, Loss: 1.3088 Test: 1.2241 \n",
      "trigger times: 7\n",
      "Epoch: 022, Loss: 1.3008 Test: 1.2480 \n",
      "trigger times: 8\n",
      "Epoch: 023, Loss: 1.2978 Test: 1.3689 \n",
      "trigger times: 9\n",
      "Epoch: 024, Loss: 1.3091 Test: 1.2647 \n",
      "trigger times: 10\n",
      "Epoch: 025, Loss: 1.3004 Test: 1.2373 \n",
      "trigger times: 11\n",
      "Epoch: 026, Loss: 1.2920 Test: 1.2119 \n",
      "Epoch: 027, Loss: 1.2993 Test: 1.2029 \n",
      "Epoch: 028, Loss: 1.2836 Test: 1.3579 \n",
      "trigger times: 1\n",
      "Epoch: 029, Loss: 1.3121 Test: 1.2489 \n",
      "trigger times: 2\n",
      "Epoch: 030, Loss: 1.3128 Test: 1.2476 \n",
      "trigger times: 3\n",
      "Epoch: 031, Loss: 1.2911 Test: 1.1984 \n",
      "Epoch: 032, Loss: 1.3080 Test: 1.2396 \n",
      "trigger times: 1\n",
      "Epoch: 033, Loss: 1.2975 Test: 1.2166 \n",
      "trigger times: 2\n",
      "Epoch: 034, Loss: 1.2984 Test: 1.2712 \n",
      "trigger times: 3\n",
      "Epoch: 035, Loss: 1.3306 Test: 1.2908 \n",
      "trigger times: 4\n",
      "Epoch: 036, Loss: 1.3114 Test: 1.3265 \n",
      "trigger times: 5\n",
      "Epoch: 037, Loss: 1.2943 Test: 1.2204 \n",
      "trigger times: 6\n",
      "Epoch: 038, Loss: 1.3100 Test: 1.1941 \n",
      "Epoch: 039, Loss: 1.2991 Test: 1.3259 \n",
      "trigger times: 1\n",
      "Epoch: 040, Loss: 1.3015 Test: 1.2942 \n",
      "trigger times: 2\n",
      "Epoch: 041, Loss: 1.2901 Test: 1.2626 \n",
      "trigger times: 3\n",
      "Epoch: 042, Loss: 1.2847 Test: 1.2166 \n",
      "trigger times: 4\n",
      "Epoch: 043, Loss: 1.2925 Test: 1.2151 \n",
      "trigger times: 5\n",
      "Epoch: 044, Loss: 1.3077 Test: 1.2056 \n",
      "trigger times: 6\n",
      "Epoch: 045, Loss: 1.3113 Test: 1.2994 \n",
      "trigger times: 7\n",
      "Epoch: 046, Loss: 1.2999 Test: 1.1973 \n",
      "trigger times: 8\n",
      "Epoch: 047, Loss: 1.2942 Test: 1.2289 \n",
      "trigger times: 9\n",
      "Epoch: 048, Loss: 1.2891 Test: 1.2266 \n",
      "trigger times: 10\n",
      "Epoch: 049, Loss: 1.2955 Test: 1.1930 \n",
      "Epoch: 050, Loss: 1.2889 Test: 1.2001 \n",
      "trigger times: 1\n",
      "Epoch: 051, Loss: 1.2858 Test: 1.2240 \n",
      "trigger times: 2\n",
      "Epoch: 052, Loss: 1.3019 Test: 1.2026 \n",
      "trigger times: 3\n",
      "Epoch: 053, Loss: 1.3191 Test: 1.2062 \n",
      "trigger times: 4\n",
      "Epoch: 054, Loss: 1.3052 Test: 1.2049 \n",
      "trigger times: 5\n",
      "Epoch: 055, Loss: 1.2928 Test: 1.1971 \n",
      "trigger times: 6\n",
      "Epoch: 056, Loss: 1.2821 Test: 1.3217 \n",
      "trigger times: 7\n",
      "Epoch: 057, Loss: 1.2799 Test: 1.1922 \n",
      "Epoch: 058, Loss: 1.3015 Test: 1.3908 \n",
      "trigger times: 1\n",
      "Epoch: 059, Loss: 1.3100 Test: 1.2207 \n",
      "trigger times: 2\n",
      "Epoch: 060, Loss: 1.3007 Test: 1.3770 \n",
      "trigger times: 3\n",
      "Epoch: 061, Loss: 1.3183 Test: 1.1918 \n",
      "Epoch: 062, Loss: 1.3003 Test: 1.1978 \n",
      "trigger times: 1\n",
      "Epoch: 063, Loss: 1.2770 Test: 1.2015 \n",
      "trigger times: 2\n",
      "Epoch: 064, Loss: 1.2847 Test: 1.3051 \n",
      "trigger times: 3\n",
      "Epoch: 065, Loss: 1.3042 Test: 1.2117 \n",
      "trigger times: 4\n",
      "Epoch: 066, Loss: 1.2832 Test: 1.1873 \n",
      "Epoch: 067, Loss: 1.3024 Test: 1.1918 \n",
      "trigger times: 1\n",
      "Epoch: 068, Loss: 1.2950 Test: 1.2768 \n",
      "trigger times: 2\n",
      "Epoch: 069, Loss: 1.2799 Test: 1.1986 \n",
      "trigger times: 3\n",
      "Epoch: 070, Loss: 1.2780 Test: 1.2077 \n",
      "trigger times: 4\n",
      "Epoch: 071, Loss: 1.2697 Test: 1.1871 \n",
      "Epoch: 072, Loss: 1.2778 Test: 1.2173 \n",
      "trigger times: 1\n",
      "Epoch: 073, Loss: 1.2774 Test: 1.3045 \n",
      "trigger times: 2\n",
      "Epoch: 074, Loss: 1.2951 Test: 1.2214 \n",
      "trigger times: 3\n",
      "Epoch: 075, Loss: 1.2672 Test: 1.1865 \n",
      "Epoch: 076, Loss: 1.2792 Test: 1.1834 \n",
      "Epoch: 077, Loss: 1.2725 Test: 1.2876 \n",
      "trigger times: 1\n",
      "Epoch: 078, Loss: 1.2939 Test: 1.1851 \n",
      "trigger times: 2\n",
      "Epoch: 079, Loss: 1.2802 Test: 1.1904 \n",
      "trigger times: 3\n",
      "Epoch: 080, Loss: 1.2811 Test: 1.2054 \n",
      "trigger times: 4\n",
      "Epoch: 081, Loss: 1.2796 Test: 1.2858 \n",
      "trigger times: 5\n",
      "Epoch: 082, Loss: 1.2905 Test: 1.1781 \n",
      "Epoch: 083, Loss: 1.2692 Test: 1.1811 \n",
      "trigger times: 1\n",
      "Epoch: 084, Loss: 1.3041 Test: 1.2196 \n",
      "trigger times: 2\n",
      "Epoch: 085, Loss: 1.2790 Test: 1.2350 \n",
      "trigger times: 3\n",
      "Epoch: 086, Loss: 1.2719 Test: 1.1874 \n",
      "trigger times: 4\n",
      "Epoch: 087, Loss: 1.2856 Test: 1.1949 \n",
      "trigger times: 5\n",
      "Epoch: 088, Loss: 1.2876 Test: 1.2327 \n",
      "trigger times: 6\n",
      "Epoch: 089, Loss: 1.2745 Test: 1.2250 \n",
      "trigger times: 7\n",
      "Epoch: 090, Loss: 1.2756 Test: 1.1813 \n",
      "trigger times: 8\n",
      "Epoch: 091, Loss: 1.3142 Test: 1.4049 \n",
      "trigger times: 9\n",
      "Epoch: 092, Loss: 1.2806 Test: 1.1844 \n",
      "trigger times: 10\n",
      "Epoch: 093, Loss: 1.2641 Test: 1.2786 \n",
      "trigger times: 11\n",
      "Epoch: 094, Loss: 1.2819 Test: 1.1951 \n",
      "trigger times: 12\n",
      "Epoch: 095, Loss: 1.2783 Test: 1.2461 \n",
      "trigger times: 13\n",
      "Epoch: 096, Loss: 1.2742 Test: 1.1851 \n",
      "trigger times: 14\n",
      "Epoch: 097, Loss: 1.2778 Test: 1.2714 \n",
      "trigger times: 15\n",
      "Epoch: 098, Loss: 1.2805 Test: 1.1995 \n",
      "trigger times: 16\n",
      "Epoch: 099, Loss: 1.3037 Test: 1.1773 \n",
      "Epoch: 100, Loss: 1.2751 Test: 1.2013 \n",
      "trigger times: 1\n",
      "Epoch: 101, Loss: 1.2728 Test: 1.2055 \n",
      "trigger times: 2\n",
      "Epoch: 102, Loss: 1.2668 Test: 1.1746 \n",
      "Epoch: 103, Loss: 1.2675 Test: 1.1837 \n",
      "trigger times: 1\n",
      "Epoch: 104, Loss: 1.2723 Test: 1.1902 \n",
      "trigger times: 2\n",
      "Epoch: 105, Loss: 1.3004 Test: 1.2402 \n",
      "trigger times: 3\n",
      "Epoch: 106, Loss: 1.2711 Test: 1.1892 \n",
      "trigger times: 4\n",
      "Epoch: 107, Loss: 1.2553 Test: 1.2436 \n",
      "trigger times: 5\n",
      "Epoch: 108, Loss: 1.2608 Test: 1.1752 \n",
      "trigger times: 6\n",
      "Epoch: 109, Loss: 1.2643 Test: 1.2735 \n",
      "trigger times: 7\n",
      "Epoch: 110, Loss: 1.2733 Test: 1.2148 \n",
      "trigger times: 8\n",
      "Epoch: 111, Loss: 1.2649 Test: 1.1998 \n",
      "trigger times: 9\n",
      "Epoch: 112, Loss: 1.2823 Test: 1.2633 \n",
      "trigger times: 10\n",
      "Epoch: 113, Loss: 1.2756 Test: 1.1788 \n",
      "trigger times: 11\n",
      "Epoch: 114, Loss: 1.2664 Test: 1.2409 \n",
      "trigger times: 12\n",
      "Epoch: 115, Loss: 1.2702 Test: 1.1759 \n",
      "trigger times: 13\n",
      "Epoch: 116, Loss: 1.2784 Test: 1.1945 \n",
      "trigger times: 14\n",
      "Epoch: 117, Loss: 1.2737 Test: 1.1712 \n",
      "Epoch: 118, Loss: 1.2575 Test: 1.4389 \n",
      "trigger times: 1\n",
      "Epoch: 119, Loss: 1.2657 Test: 1.1897 \n",
      "trigger times: 2\n",
      "Epoch: 120, Loss: 1.2454 Test: 1.1909 \n",
      "trigger times: 3\n",
      "Epoch: 121, Loss: 1.2536 Test: 1.1827 \n",
      "trigger times: 4\n",
      "Epoch: 122, Loss: 1.2449 Test: 1.1693 \n",
      "Epoch: 123, Loss: 1.2494 Test: 1.1792 \n",
      "trigger times: 1\n",
      "Epoch: 124, Loss: 1.2399 Test: 1.1845 \n",
      "trigger times: 2\n",
      "Epoch: 125, Loss: 1.2598 Test: 1.1596 \n",
      "Epoch: 126, Loss: 1.2447 Test: 1.2053 \n",
      "trigger times: 1\n",
      "Epoch: 127, Loss: 1.2569 Test: 1.2209 \n",
      "trigger times: 2\n",
      "Epoch: 128, Loss: 1.2735 Test: 1.1569 \n",
      "Epoch: 129, Loss: 1.2537 Test: 1.1629 \n",
      "trigger times: 1\n",
      "Epoch: 130, Loss: 1.2399 Test: 1.2939 \n",
      "trigger times: 2\n",
      "Epoch: 131, Loss: 1.2478 Test: 1.2010 \n",
      "trigger times: 3\n",
      "Epoch: 132, Loss: 1.2562 Test: 1.1690 \n",
      "trigger times: 4\n",
      "Epoch: 133, Loss: 1.2610 Test: 1.1608 \n",
      "trigger times: 5\n",
      "Epoch: 134, Loss: 1.2725 Test: 1.1721 \n",
      "trigger times: 6\n",
      "Epoch: 135, Loss: 1.2615 Test: 1.1607 \n",
      "trigger times: 7\n",
      "Epoch: 136, Loss: 1.2582 Test: 1.1685 \n",
      "trigger times: 8\n",
      "Epoch: 137, Loss: 1.2577 Test: 1.2386 \n",
      "trigger times: 9\n",
      "Epoch: 138, Loss: 1.2465 Test: 1.1761 \n",
      "trigger times: 10\n",
      "Epoch: 139, Loss: 1.2565 Test: 1.1782 \n",
      "trigger times: 11\n",
      "Epoch: 140, Loss: 1.2574 Test: 1.2140 \n",
      "trigger times: 12\n",
      "Epoch: 141, Loss: 1.2448 Test: 1.1680 \n",
      "trigger times: 13\n",
      "Epoch: 142, Loss: 1.2421 Test: 1.2410 \n",
      "trigger times: 14\n",
      "Epoch: 143, Loss: 1.2504 Test: 1.3313 \n",
      "trigger times: 15\n",
      "Epoch: 144, Loss: 1.2813 Test: 1.1830 \n",
      "trigger times: 16\n",
      "Epoch: 145, Loss: 1.2482 Test: 1.3297 \n",
      "trigger times: 17\n",
      "Epoch: 146, Loss: 1.2661 Test: 1.1559 \n",
      "Epoch: 147, Loss: 1.2517 Test: 1.1800 \n",
      "trigger times: 1\n",
      "Epoch: 148, Loss: 1.2526 Test: 1.2141 \n",
      "trigger times: 2\n",
      "Epoch: 149, Loss: 1.2536 Test: 1.2179 \n",
      "trigger times: 3\n",
      "Epoch: 150, Loss: 1.2452 Test: 1.1713 \n",
      "trigger times: 4\n",
      "Epoch: 151, Loss: 1.2877 Test: 1.1675 \n",
      "trigger times: 5\n",
      "Epoch: 152, Loss: 1.2584 Test: 1.2097 \n",
      "trigger times: 6\n",
      "Epoch: 153, Loss: 1.2513 Test: 1.1764 \n",
      "trigger times: 7\n",
      "Epoch: 154, Loss: 1.2560 Test: 1.1725 \n",
      "trigger times: 8\n",
      "Epoch: 155, Loss: 1.2513 Test: 1.2071 \n",
      "trigger times: 9\n",
      "Epoch: 156, Loss: 1.2422 Test: 1.1801 \n",
      "trigger times: 10\n",
      "Epoch: 157, Loss: 1.2554 Test: 1.2109 \n",
      "trigger times: 11\n",
      "Epoch: 158, Loss: 1.2533 Test: 1.2575 \n",
      "trigger times: 12\n",
      "Epoch: 159, Loss: 1.2543 Test: 1.1641 \n",
      "trigger times: 13\n",
      "Epoch: 160, Loss: 1.2937 Test: 1.1625 \n",
      "trigger times: 14\n",
      "Epoch: 161, Loss: 1.2440 Test: 1.2051 \n",
      "trigger times: 15\n",
      "Epoch: 162, Loss: 1.2510 Test: 1.1764 \n",
      "trigger times: 16\n",
      "Epoch: 163, Loss: 1.2595 Test: 1.2155 \n",
      "trigger times: 17\n",
      "Epoch: 164, Loss: 1.2567 Test: 1.1640 \n",
      "trigger times: 18\n",
      "Epoch: 165, Loss: 1.2594 Test: 1.1827 \n",
      "trigger times: 19\n",
      "Epoch: 166, Loss: 1.2453 Test: 1.1816 \n",
      "trigger times: 20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 167, Loss: 1.2445 Test: 1.3873 \n",
      "trigger times: 21\n",
      "Epoch: 168, Loss: 1.2717 Test: 1.2034 \n",
      "trigger times: 22\n",
      "Epoch: 169, Loss: 1.2454 Test: 1.1669 \n",
      "trigger times: 23\n",
      "Epoch: 170, Loss: 1.2558 Test: 1.2148 \n",
      "trigger times: 24\n",
      "Epoch: 171, Loss: 1.2626 Test: 1.3116 \n",
      "trigger times: 25\n",
      "Epoch: 172, Loss: 1.2552 Test: 1.1668 \n",
      "trigger times: 26\n",
      "Epoch: 173, Loss: 1.2492 Test: 1.2835 \n",
      "trigger times: 27\n",
      "Epoch: 174, Loss: 1.2491 Test: 1.1675 \n",
      "trigger times: 28\n",
      "Epoch: 175, Loss: 1.2551 Test: 1.2048 \n",
      "trigger times: 29\n",
      "Epoch: 176, Loss: 1.2661 Test: 1.1588 \n",
      "trigger times: 30\n",
      "Early stopping!\n",
      "Start to test process.\n",
      "Epoch: 000, Loss: 2.0862 Test: 1.6479 \n",
      "Epoch: 001, Loss: 1.5018 Test: 1.5324 \n",
      "Epoch: 002, Loss: 1.4208 Test: 1.4911 \n",
      "Epoch: 003, Loss: 1.3808 Test: 1.4933 \n",
      "trigger times: 1\n",
      "Epoch: 004, Loss: 1.3699 Test: 1.4995 \n",
      "trigger times: 2\n",
      "Epoch: 005, Loss: 1.3505 Test: 1.4797 \n",
      "Epoch: 006, Loss: 1.3438 Test: 1.5194 \n",
      "trigger times: 1\n",
      "Epoch: 007, Loss: 1.3479 Test: 1.4929 \n",
      "trigger times: 2\n",
      "Epoch: 008, Loss: 1.3542 Test: 1.4971 \n",
      "trigger times: 3\n",
      "Epoch: 009, Loss: 1.3502 Test: 1.5170 \n",
      "trigger times: 4\n",
      "Epoch: 010, Loss: 1.3473 Test: 1.5699 \n",
      "trigger times: 5\n",
      "Epoch: 011, Loss: 1.3422 Test: 1.4905 \n",
      "trigger times: 6\n",
      "Epoch: 012, Loss: 1.3381 Test: 1.5143 \n",
      "trigger times: 7\n",
      "Epoch: 013, Loss: 1.3305 Test: 1.4970 \n",
      "trigger times: 8\n",
      "Epoch: 014, Loss: 1.3494 Test: 1.5605 \n",
      "trigger times: 9\n",
      "Epoch: 015, Loss: 1.3382 Test: 1.5385 \n",
      "trigger times: 10\n",
      "Epoch: 016, Loss: 1.3380 Test: 1.4991 \n",
      "trigger times: 11\n",
      "Epoch: 017, Loss: 1.3426 Test: 1.5351 \n",
      "trigger times: 12\n",
      "Epoch: 018, Loss: 1.3469 Test: 1.5079 \n",
      "trigger times: 13\n",
      "Epoch: 019, Loss: 1.3394 Test: 1.5880 \n",
      "trigger times: 14\n",
      "Epoch: 020, Loss: 1.3531 Test: 1.5162 \n",
      "trigger times: 15\n",
      "Epoch: 021, Loss: 1.3311 Test: 1.5312 \n",
      "trigger times: 16\n",
      "Epoch: 022, Loss: 1.3290 Test: 1.5140 \n",
      "trigger times: 17\n",
      "Epoch: 023, Loss: 1.3389 Test: 1.5932 \n",
      "trigger times: 18\n",
      "Epoch: 024, Loss: 1.3565 Test: 1.5376 \n",
      "trigger times: 19\n",
      "Epoch: 025, Loss: 1.3376 Test: 1.5203 \n",
      "trigger times: 20\n",
      "Epoch: 026, Loss: 1.3369 Test: 1.5595 \n",
      "trigger times: 21\n",
      "Epoch: 027, Loss: 1.3377 Test: 1.5200 \n",
      "trigger times: 22\n",
      "Epoch: 028, Loss: 1.3363 Test: 1.5497 \n",
      "trigger times: 23\n",
      "Epoch: 029, Loss: 1.3380 Test: 1.5955 \n",
      "trigger times: 24\n",
      "Epoch: 030, Loss: 1.3324 Test: 1.5287 \n",
      "trigger times: 25\n",
      "Epoch: 031, Loss: 1.3430 Test: 1.5341 \n",
      "trigger times: 26\n",
      "Epoch: 032, Loss: 1.3445 Test: 1.5300 \n",
      "trigger times: 27\n",
      "Epoch: 033, Loss: 1.3385 Test: 1.5232 \n",
      "trigger times: 28\n",
      "Epoch: 034, Loss: 1.3416 Test: 1.5376 \n",
      "trigger times: 29\n",
      "Epoch: 035, Loss: 1.3282 Test: 1.5183 \n",
      "trigger times: 30\n",
      "Early stopping!\n",
      "Start to test process.\n",
      "Epoch: 000, Loss: 1.7522 Test: 1.3985 \n",
      "Epoch: 001, Loss: 1.4204 Test: 1.3506 \n",
      "Epoch: 002, Loss: 1.3614 Test: 1.3160 \n",
      "Epoch: 003, Loss: 1.3370 Test: 1.3013 \n",
      "Epoch: 004, Loss: 1.3345 Test: 1.3214 \n",
      "trigger times: 1\n",
      "Epoch: 005, Loss: 1.3524 Test: 1.3257 \n",
      "trigger times: 2\n",
      "Epoch: 006, Loss: 1.3300 Test: 1.4543 \n",
      "trigger times: 3\n",
      "Epoch: 007, Loss: 1.3418 Test: 1.2578 \n",
      "Epoch: 008, Loss: 1.3309 Test: 1.2805 \n",
      "trigger times: 1\n",
      "Epoch: 009, Loss: 1.3292 Test: 1.2654 \n",
      "trigger times: 2\n",
      "Epoch: 010, Loss: 1.3387 Test: 1.2699 \n",
      "trigger times: 3\n",
      "Epoch: 011, Loss: 1.3354 Test: 1.2661 \n",
      "trigger times: 4\n",
      "Epoch: 012, Loss: 1.3161 Test: 1.3872 \n",
      "trigger times: 5\n",
      "Epoch: 013, Loss: 1.3357 Test: 1.3918 \n",
      "trigger times: 6\n",
      "Epoch: 014, Loss: 1.3361 Test: 1.3179 \n",
      "trigger times: 7\n",
      "Epoch: 015, Loss: 1.3302 Test: 1.2835 \n",
      "trigger times: 8\n",
      "Epoch: 016, Loss: 1.3385 Test: 1.3952 \n",
      "trigger times: 9\n",
      "Epoch: 017, Loss: 1.3225 Test: 1.4014 \n",
      "trigger times: 10\n",
      "Epoch: 018, Loss: 1.3374 Test: 1.2752 \n",
      "trigger times: 11\n",
      "Epoch: 019, Loss: 1.3580 Test: 1.2695 \n",
      "trigger times: 12\n",
      "Epoch: 020, Loss: 1.3316 Test: 1.2819 \n",
      "trigger times: 13\n",
      "Epoch: 021, Loss: 1.3064 Test: 1.2897 \n",
      "trigger times: 14\n",
      "Epoch: 022, Loss: 1.3133 Test: 1.2813 \n",
      "trigger times: 15\n",
      "Epoch: 023, Loss: 1.3420 Test: 1.2625 \n",
      "trigger times: 16\n",
      "Epoch: 024, Loss: 1.3282 Test: 1.3157 \n",
      "trigger times: 17\n",
      "Epoch: 025, Loss: 1.3132 Test: 1.2641 \n",
      "trigger times: 18\n",
      "Epoch: 026, Loss: 1.3071 Test: 1.2616 \n",
      "trigger times: 19\n",
      "Epoch: 027, Loss: 1.3041 Test: 1.2465 \n",
      "Epoch: 028, Loss: 1.3133 Test: 1.2483 \n",
      "trigger times: 1\n",
      "Epoch: 029, Loss: 1.2992 Test: 1.2549 \n",
      "trigger times: 2\n",
      "Epoch: 030, Loss: 1.3162 Test: 1.2511 \n",
      "trigger times: 3\n",
      "Epoch: 031, Loss: 1.3029 Test: 1.2521 \n",
      "trigger times: 4\n",
      "Epoch: 032, Loss: 1.3300 Test: 1.4660 \n",
      "trigger times: 5\n",
      "Epoch: 033, Loss: 1.3234 Test: 1.2744 \n",
      "trigger times: 6\n",
      "Epoch: 034, Loss: 1.3166 Test: 1.2578 \n",
      "trigger times: 7\n",
      "Epoch: 035, Loss: 1.3282 Test: 1.2594 \n",
      "trigger times: 8\n",
      "Epoch: 036, Loss: 1.2995 Test: 1.4010 \n",
      "trigger times: 9\n",
      "Epoch: 037, Loss: 1.3241 Test: 1.2817 \n",
      "trigger times: 10\n",
      "Epoch: 038, Loss: 1.3239 Test: 1.2629 \n",
      "trigger times: 11\n",
      "Epoch: 039, Loss: 1.3256 Test: 1.3069 \n",
      "trigger times: 12\n",
      "Epoch: 040, Loss: 1.3067 Test: 1.3134 \n",
      "trigger times: 13\n",
      "Epoch: 041, Loss: 1.3185 Test: 1.2437 \n",
      "Epoch: 042, Loss: 1.3227 Test: 1.2810 \n",
      "trigger times: 1\n",
      "Epoch: 043, Loss: 1.3088 Test: 1.2811 \n",
      "trigger times: 2\n",
      "Epoch: 044, Loss: 1.3007 Test: 1.2440 \n",
      "trigger times: 3\n",
      "Epoch: 045, Loss: 1.3097 Test: 1.2677 \n",
      "trigger times: 4\n",
      "Epoch: 046, Loss: 1.2995 Test: 1.2500 \n",
      "trigger times: 5\n",
      "Epoch: 047, Loss: 1.3588 Test: 1.4322 \n",
      "trigger times: 6\n",
      "Epoch: 048, Loss: 1.3048 Test: 1.2529 \n",
      "trigger times: 7\n",
      "Epoch: 049, Loss: 1.2963 Test: 1.2614 \n",
      "trigger times: 8\n",
      "Epoch: 050, Loss: 1.3136 Test: 1.2476 \n",
      "trigger times: 9\n",
      "Epoch: 051, Loss: 1.3107 Test: 1.2566 \n",
      "trigger times: 10\n",
      "Epoch: 052, Loss: 1.3207 Test: 1.2418 \n",
      "Epoch: 053, Loss: 1.2902 Test: 1.3720 \n",
      "trigger times: 1\n",
      "Epoch: 054, Loss: 1.2950 Test: 1.3959 \n",
      "trigger times: 2\n",
      "Epoch: 055, Loss: 1.3232 Test: 1.2417 \n",
      "Epoch: 056, Loss: 1.3141 Test: 1.2500 \n",
      "trigger times: 1\n",
      "Epoch: 057, Loss: 1.2921 Test: 1.2602 \n",
      "trigger times: 2\n",
      "Epoch: 058, Loss: 1.2997 Test: 1.2509 \n",
      "trigger times: 3\n",
      "Epoch: 059, Loss: 1.3180 Test: 1.4709 \n",
      "trigger times: 4\n",
      "Epoch: 060, Loss: 1.3106 Test: 1.2752 \n",
      "trigger times: 5\n",
      "Epoch: 061, Loss: 1.3761 Test: 1.4160 \n",
      "trigger times: 6\n",
      "Epoch: 062, Loss: 1.3079 Test: 1.2500 \n",
      "trigger times: 7\n",
      "Epoch: 063, Loss: 1.2909 Test: 1.2469 \n",
      "trigger times: 8\n",
      "Epoch: 064, Loss: 1.3264 Test: 1.2605 \n",
      "trigger times: 9\n",
      "Epoch: 065, Loss: 1.3093 Test: 1.4698 \n",
      "trigger times: 10\n",
      "Epoch: 066, Loss: 1.3226 Test: 1.2603 \n",
      "trigger times: 11\n",
      "Epoch: 067, Loss: 1.3306 Test: 1.2698 \n",
      "trigger times: 12\n",
      "Epoch: 068, Loss: 1.2998 Test: 1.2513 \n",
      "trigger times: 13\n",
      "Epoch: 069, Loss: 1.2944 Test: 1.2650 \n",
      "trigger times: 14\n",
      "Epoch: 070, Loss: 1.3088 Test: 1.2429 \n",
      "trigger times: 15\n",
      "Epoch: 071, Loss: 1.2932 Test: 1.2644 \n",
      "trigger times: 16\n",
      "Epoch: 072, Loss: 1.2936 Test: 1.2514 \n",
      "trigger times: 17\n",
      "Epoch: 073, Loss: 1.2998 Test: 1.2476 \n",
      "trigger times: 18\n",
      "Epoch: 074, Loss: 1.3062 Test: 1.2497 \n",
      "trigger times: 19\n",
      "Epoch: 075, Loss: 1.3062 Test: 1.2571 \n",
      "trigger times: 20\n",
      "Epoch: 076, Loss: 1.3025 Test: 1.2619 \n",
      "trigger times: 21\n",
      "Epoch: 077, Loss: 1.3087 Test: 1.2611 \n",
      "trigger times: 22\n",
      "Epoch: 078, Loss: 1.2993 Test: 1.2419 \n",
      "trigger times: 23\n",
      "Epoch: 079, Loss: 1.3389 Test: 1.2775 \n",
      "trigger times: 24\n",
      "Epoch: 080, Loss: 1.3032 Test: 1.2854 \n",
      "trigger times: 25\n",
      "Epoch: 081, Loss: 1.2987 Test: 1.2804 \n",
      "trigger times: 26\n",
      "Epoch: 082, Loss: 1.3065 Test: 1.2887 \n",
      "trigger times: 27\n",
      "Epoch: 083, Loss: 1.2943 Test: 1.2633 \n",
      "trigger times: 28\n",
      "Epoch: 084, Loss: 1.3157 Test: 1.2561 \n",
      "trigger times: 29\n",
      "Epoch: 085, Loss: 1.3185 Test: 1.3018 \n",
      "trigger times: 30\n",
      "Early stopping!\n",
      "Start to test process.\n",
      "Epoch: 000, Loss: 1.6260 Test: 1.4572 \n",
      "Epoch: 001, Loss: 1.3787 Test: 1.4186 \n",
      "Epoch: 002, Loss: 1.3803 Test: 1.4144 \n",
      "Epoch: 003, Loss: 1.3471 Test: 1.4238 \n",
      "trigger times: 1\n",
      "Epoch: 004, Loss: 1.3506 Test: 1.3931 \n",
      "Epoch: 005, Loss: 1.3380 Test: 1.3992 \n",
      "trigger times: 1\n",
      "Epoch: 006, Loss: 1.3513 Test: 1.3912 \n",
      "Epoch: 007, Loss: 1.3646 Test: 1.4356 \n",
      "trigger times: 1\n",
      "Epoch: 008, Loss: 1.3281 Test: 1.4516 \n",
      "trigger times: 2\n",
      "Epoch: 009, Loss: 1.3517 Test: 1.3647 \n",
      "Epoch: 010, Loss: 1.3262 Test: 1.4041 \n",
      "trigger times: 1\n",
      "Epoch: 011, Loss: 1.3168 Test: 1.3711 \n",
      "trigger times: 2\n",
      "Epoch: 012, Loss: 1.3290 Test: 1.3896 \n",
      "trigger times: 3\n",
      "Epoch: 013, Loss: 1.3203 Test: 1.4734 \n",
      "trigger times: 4\n",
      "Epoch: 014, Loss: 1.3261 Test: 1.3572 \n",
      "Epoch: 015, Loss: 1.3127 Test: 1.3845 \n",
      "trigger times: 1\n",
      "Epoch: 016, Loss: 1.3132 Test: 1.3560 \n",
      "Epoch: 017, Loss: 1.3461 Test: 1.3732 \n",
      "trigger times: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 018, Loss: 1.3187 Test: 1.3593 \n",
      "trigger times: 2\n",
      "Epoch: 019, Loss: 1.3104 Test: 1.3467 \n",
      "Epoch: 020, Loss: 1.3151 Test: 1.3666 \n",
      "trigger times: 1\n",
      "Epoch: 021, Loss: 1.3298 Test: 1.4590 \n",
      "trigger times: 2\n",
      "Epoch: 022, Loss: 1.3088 Test: 1.4923 \n",
      "trigger times: 3\n",
      "Epoch: 023, Loss: 1.3160 Test: 1.3603 \n",
      "trigger times: 4\n",
      "Epoch: 024, Loss: 1.3004 Test: 1.3771 \n",
      "trigger times: 5\n",
      "Epoch: 025, Loss: 1.2948 Test: 1.3730 \n",
      "trigger times: 6\n",
      "Epoch: 026, Loss: 1.2914 Test: 1.3737 \n",
      "trigger times: 7\n",
      "Epoch: 027, Loss: 1.3200 Test: 1.3712 \n",
      "trigger times: 8\n",
      "Epoch: 028, Loss: 1.2927 Test: 1.3449 \n",
      "Epoch: 029, Loss: 1.3036 Test: 1.3566 \n",
      "trigger times: 1\n",
      "Epoch: 030, Loss: 1.3037 Test: 1.3608 \n",
      "trigger times: 2\n",
      "Epoch: 031, Loss: 1.2926 Test: 1.3400 \n",
      "Epoch: 032, Loss: 1.3214 Test: 1.3743 \n",
      "trigger times: 1\n",
      "Epoch: 033, Loss: 1.2890 Test: 1.3696 \n",
      "trigger times: 2\n",
      "Epoch: 034, Loss: 1.2954 Test: 1.3266 \n",
      "Epoch: 035, Loss: 1.2929 Test: 1.3322 \n",
      "trigger times: 1\n",
      "Epoch: 036, Loss: 1.2923 Test: 1.3515 \n",
      "trigger times: 2\n",
      "Epoch: 037, Loss: 1.3110 Test: 1.3574 \n",
      "trigger times: 3\n",
      "Epoch: 038, Loss: 1.2959 Test: 1.3325 \n",
      "trigger times: 4\n",
      "Epoch: 039, Loss: 1.2970 Test: 1.3717 \n",
      "trigger times: 5\n",
      "Epoch: 040, Loss: 1.3042 Test: 1.3439 \n",
      "trigger times: 6\n",
      "Epoch: 041, Loss: 1.3046 Test: 1.3732 \n",
      "trigger times: 7\n",
      "Epoch: 042, Loss: 1.3063 Test: 1.3779 \n",
      "trigger times: 8\n",
      "Epoch: 043, Loss: 1.2946 Test: 1.3611 \n",
      "trigger times: 9\n",
      "Epoch: 044, Loss: 1.2964 Test: 1.3488 \n",
      "trigger times: 10\n",
      "Epoch: 045, Loss: 1.2993 Test: 1.4614 \n",
      "trigger times: 11\n",
      "Epoch: 046, Loss: 1.3265 Test: 1.3428 \n",
      "trigger times: 12\n",
      "Epoch: 047, Loss: 1.3055 Test: 1.3713 \n",
      "trigger times: 13\n",
      "Epoch: 048, Loss: 1.2926 Test: 1.3445 \n",
      "trigger times: 14\n",
      "Epoch: 049, Loss: 1.2861 Test: 1.6162 \n",
      "trigger times: 15\n",
      "Epoch: 050, Loss: 1.3112 Test: 1.3820 \n",
      "trigger times: 16\n",
      "Epoch: 051, Loss: 1.2938 Test: 1.3218 \n",
      "Epoch: 052, Loss: 1.2911 Test: 1.3562 \n",
      "trigger times: 1\n",
      "Epoch: 053, Loss: 1.3015 Test: 1.3628 \n",
      "trigger times: 2\n",
      "Epoch: 054, Loss: 1.2912 Test: 1.3362 \n",
      "trigger times: 3\n",
      "Epoch: 055, Loss: 1.2808 Test: 1.3493 \n",
      "trigger times: 4\n",
      "Epoch: 056, Loss: 1.3020 Test: 1.3908 \n",
      "trigger times: 5\n",
      "Epoch: 057, Loss: 1.3273 Test: 1.3271 \n",
      "trigger times: 6\n",
      "Epoch: 058, Loss: 1.2909 Test: 1.3364 \n",
      "trigger times: 7\n",
      "Epoch: 059, Loss: 1.2769 Test: 1.3256 \n",
      "trigger times: 8\n",
      "Epoch: 060, Loss: 1.2824 Test: 1.4059 \n",
      "trigger times: 9\n",
      "Epoch: 061, Loss: 1.2951 Test: 1.3887 \n",
      "trigger times: 10\n",
      "Epoch: 062, Loss: 1.3008 Test: 1.3994 \n",
      "trigger times: 11\n",
      "Epoch: 063, Loss: 1.2835 Test: 1.3871 \n",
      "trigger times: 12\n",
      "Epoch: 064, Loss: 1.2886 Test: 1.3271 \n",
      "trigger times: 13\n",
      "Epoch: 065, Loss: 1.2780 Test: 1.3614 \n",
      "trigger times: 14\n",
      "Epoch: 066, Loss: 1.2941 Test: 1.3599 \n",
      "trigger times: 15\n",
      "Epoch: 067, Loss: 1.2925 Test: 1.3349 \n",
      "trigger times: 16\n",
      "Epoch: 068, Loss: 1.2840 Test: 1.3286 \n",
      "trigger times: 17\n",
      "Epoch: 069, Loss: 1.3127 Test: 1.3336 \n",
      "trigger times: 18\n",
      "Epoch: 070, Loss: 1.3068 Test: 1.3347 \n",
      "trigger times: 19\n",
      "Epoch: 071, Loss: 1.2861 Test: 1.3361 \n",
      "trigger times: 20\n",
      "Epoch: 072, Loss: 1.3075 Test: 1.3313 \n",
      "trigger times: 21\n",
      "Epoch: 073, Loss: 1.2870 Test: 1.3549 \n",
      "trigger times: 22\n",
      "Epoch: 074, Loss: 1.2795 Test: 1.3649 \n",
      "trigger times: 23\n",
      "Epoch: 075, Loss: 1.2863 Test: 1.3545 \n",
      "trigger times: 24\n",
      "Epoch: 076, Loss: 1.2858 Test: 1.3567 \n",
      "trigger times: 25\n",
      "Epoch: 077, Loss: 1.2745 Test: 1.3981 \n",
      "trigger times: 26\n",
      "Epoch: 078, Loss: 1.2799 Test: 1.3243 \n",
      "trigger times: 27\n",
      "Epoch: 079, Loss: 1.2734 Test: 1.3344 \n",
      "trigger times: 28\n",
      "Epoch: 080, Loss: 1.2984 Test: 1.4594 \n",
      "trigger times: 29\n",
      "Epoch: 081, Loss: 1.2961 Test: 1.3319 \n",
      "trigger times: 30\n",
      "Early stopping!\n",
      "Start to test process.\n",
      "Epoch: 000, Loss: 1.7865 Test: 1.4995 \n",
      "Epoch: 001, Loss: 1.3866 Test: 1.3644 \n",
      "Epoch: 002, Loss: 1.3489 Test: 1.3092 \n",
      "Epoch: 003, Loss: 1.3262 Test: 1.2863 \n",
      "Epoch: 004, Loss: 1.3256 Test: 1.2775 \n",
      "Epoch: 005, Loss: 1.3239 Test: 1.2713 \n",
      "Epoch: 006, Loss: 1.3108 Test: 1.2690 \n",
      "Epoch: 007, Loss: 1.2900 Test: 1.2837 \n",
      "trigger times: 1\n",
      "Epoch: 008, Loss: 1.2946 Test: 1.2850 \n",
      "trigger times: 2\n",
      "Epoch: 009, Loss: 1.2834 Test: 1.2801 \n",
      "trigger times: 3\n",
      "Epoch: 010, Loss: 1.2939 Test: 1.2881 \n",
      "trigger times: 4\n",
      "Epoch: 011, Loss: 1.2905 Test: 1.3374 \n",
      "trigger times: 5\n",
      "Epoch: 012, Loss: 1.2898 Test: 1.3148 \n",
      "trigger times: 6\n",
      "Epoch: 013, Loss: 1.2914 Test: 1.2672 \n",
      "Epoch: 014, Loss: 1.2974 Test: 1.4169 \n",
      "trigger times: 1\n",
      "Epoch: 015, Loss: 1.2763 Test: 1.2593 \n",
      "Epoch: 016, Loss: 1.3065 Test: 1.2258 \n",
      "Epoch: 017, Loss: 1.2696 Test: 1.2235 \n",
      "Epoch: 018, Loss: 1.2657 Test: 1.2248 \n",
      "trigger times: 1\n",
      "Epoch: 019, Loss: 1.2725 Test: 1.2486 \n",
      "trigger times: 2\n",
      "Epoch: 020, Loss: 1.2724 Test: 1.3116 \n",
      "trigger times: 3\n",
      "Epoch: 021, Loss: 1.2595 Test: 1.2689 \n",
      "trigger times: 4\n",
      "Epoch: 022, Loss: 1.2831 Test: 1.2201 \n",
      "Epoch: 023, Loss: 1.2733 Test: 1.2513 \n",
      "trigger times: 1\n",
      "Epoch: 024, Loss: 1.2863 Test: 1.2345 \n",
      "trigger times: 2\n",
      "Epoch: 025, Loss: 1.2792 Test: 1.2396 \n",
      "trigger times: 3\n",
      "Epoch: 026, Loss: 1.2874 Test: 1.3200 \n",
      "trigger times: 4\n",
      "Epoch: 027, Loss: 1.2686 Test: 1.2353 \n",
      "trigger times: 5\n",
      "Epoch: 028, Loss: 1.2435 Test: 1.3083 \n",
      "trigger times: 6\n",
      "Epoch: 029, Loss: 1.2609 Test: 1.2386 \n",
      "trigger times: 7\n",
      "Epoch: 030, Loss: 1.2919 Test: 1.2173 \n",
      "Epoch: 031, Loss: 1.2687 Test: 1.2431 \n",
      "trigger times: 1\n",
      "Epoch: 032, Loss: 1.2650 Test: 1.2421 \n",
      "trigger times: 2\n",
      "Epoch: 033, Loss: 1.2958 Test: 1.2245 \n",
      "trigger times: 3\n",
      "Epoch: 034, Loss: 1.2557 Test: 1.2282 \n",
      "trigger times: 4\n",
      "Epoch: 035, Loss: 1.3097 Test: 1.3420 \n",
      "trigger times: 5\n",
      "Epoch: 036, Loss: 1.2540 Test: 1.3415 \n",
      "trigger times: 6\n",
      "Epoch: 037, Loss: 1.2708 Test: 1.2182 \n",
      "trigger times: 7\n",
      "Epoch: 038, Loss: 1.2770 Test: 1.2368 \n",
      "trigger times: 8\n",
      "Epoch: 039, Loss: 1.2601 Test: 1.2218 \n",
      "trigger times: 9\n",
      "Epoch: 040, Loss: 1.2564 Test: 1.2140 \n",
      "Epoch: 041, Loss: 1.2976 Test: 1.2136 \n",
      "Epoch: 042, Loss: 1.2778 Test: 1.2796 \n",
      "trigger times: 1\n",
      "Epoch: 043, Loss: 1.2735 Test: 1.2080 \n",
      "Epoch: 044, Loss: 1.3042 Test: 1.2876 \n",
      "trigger times: 1\n",
      "Epoch: 045, Loss: 1.2643 Test: 1.2402 \n",
      "trigger times: 2\n",
      "Epoch: 046, Loss: 1.2834 Test: 1.2154 \n",
      "trigger times: 3\n",
      "Epoch: 047, Loss: 1.2613 Test: 1.3156 \n",
      "trigger times: 4\n",
      "Epoch: 048, Loss: 1.2699 Test: 1.2126 \n",
      "trigger times: 5\n",
      "Epoch: 049, Loss: 1.2683 Test: 1.2495 \n",
      "trigger times: 6\n",
      "Epoch: 050, Loss: 1.2774 Test: 1.2630 \n",
      "trigger times: 7\n",
      "Epoch: 051, Loss: 1.2525 Test: 1.2095 \n",
      "trigger times: 8\n",
      "Epoch: 052, Loss: 1.2527 Test: 1.3020 \n",
      "trigger times: 9\n",
      "Epoch: 053, Loss: 1.2587 Test: 1.2599 \n",
      "trigger times: 10\n",
      "Epoch: 054, Loss: 1.2728 Test: 1.2338 \n",
      "trigger times: 11\n",
      "Epoch: 055, Loss: 1.2675 Test: 1.2228 \n",
      "trigger times: 12\n",
      "Epoch: 056, Loss: 1.2577 Test: 1.2137 \n",
      "trigger times: 13\n",
      "Epoch: 057, Loss: 1.2581 Test: 1.2193 \n",
      "trigger times: 14\n",
      "Epoch: 058, Loss: 1.2625 Test: 1.2157 \n",
      "trigger times: 15\n",
      "Epoch: 059, Loss: 1.2521 Test: 1.2588 \n",
      "trigger times: 16\n",
      "Epoch: 060, Loss: 1.2930 Test: 1.2881 \n",
      "trigger times: 17\n",
      "Epoch: 061, Loss: 1.2681 Test: 1.2199 \n",
      "trigger times: 18\n",
      "Epoch: 062, Loss: 1.2523 Test: 1.5591 \n",
      "trigger times: 19\n",
      "Epoch: 063, Loss: 1.2758 Test: 1.3536 \n",
      "trigger times: 20\n",
      "Epoch: 064, Loss: 1.2668 Test: 1.2351 \n",
      "trigger times: 21\n",
      "Epoch: 065, Loss: 1.2719 Test: 1.3353 \n",
      "trigger times: 22\n",
      "Epoch: 066, Loss: 1.2663 Test: 1.4857 \n",
      "trigger times: 23\n",
      "Epoch: 067, Loss: 1.3090 Test: 1.1999 \n",
      "Epoch: 068, Loss: 1.2505 Test: 1.2068 \n",
      "trigger times: 1\n",
      "Epoch: 069, Loss: 1.2778 Test: 1.3420 \n",
      "trigger times: 2\n",
      "Epoch: 070, Loss: 1.2609 Test: 1.2128 \n",
      "trigger times: 3\n",
      "Epoch: 071, Loss: 1.2578 Test: 1.2141 \n",
      "trigger times: 4\n",
      "Epoch: 072, Loss: 1.2523 Test: 1.2085 \n",
      "trigger times: 5\n",
      "Epoch: 073, Loss: 1.2472 Test: 1.2229 \n",
      "trigger times: 6\n",
      "Epoch: 074, Loss: 1.2518 Test: 1.2160 \n",
      "trigger times: 7\n",
      "Epoch: 075, Loss: 1.2580 Test: 1.2083 \n",
      "trigger times: 8\n",
      "Epoch: 076, Loss: 1.2632 Test: 1.2231 \n",
      "trigger times: 9\n",
      "Epoch: 077, Loss: 1.2603 Test: 1.2076 \n",
      "trigger times: 10\n",
      "Epoch: 078, Loss: 1.2486 Test: 1.2107 \n",
      "trigger times: 11\n",
      "Epoch: 079, Loss: 1.2636 Test: 1.2192 \n",
      "trigger times: 12\n",
      "Epoch: 080, Loss: 1.2584 Test: 1.2135 \n",
      "trigger times: 13\n",
      "Epoch: 081, Loss: 1.2526 Test: 1.2355 \n",
      "trigger times: 14\n",
      "Epoch: 082, Loss: 1.2532 Test: 1.2282 \n",
      "trigger times: 15\n",
      "Epoch: 083, Loss: 1.2430 Test: 1.2528 \n",
      "trigger times: 16\n",
      "Epoch: 084, Loss: 1.2668 Test: 1.2117 \n",
      "trigger times: 17\n",
      "Epoch: 085, Loss: 1.2616 Test: 1.3258 \n",
      "trigger times: 18\n",
      "Epoch: 086, Loss: 1.2621 Test: 1.2241 \n",
      "trigger times: 19\n",
      "Epoch: 087, Loss: 1.2421 Test: 1.2217 \n",
      "trigger times: 20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 088, Loss: 1.2518 Test: 1.2142 \n",
      "trigger times: 21\n",
      "Epoch: 089, Loss: 1.2462 Test: 1.2482 \n",
      "trigger times: 22\n",
      "Epoch: 090, Loss: 1.2725 Test: 1.2001 \n",
      "trigger times: 23\n",
      "Epoch: 091, Loss: 1.2647 Test: 1.2616 \n",
      "trigger times: 24\n",
      "Epoch: 092, Loss: 1.2528 Test: 1.2483 \n",
      "trigger times: 25\n",
      "Epoch: 093, Loss: 1.2501 Test: 1.2132 \n",
      "trigger times: 26\n",
      "Epoch: 094, Loss: 1.2540 Test: 1.2120 \n",
      "trigger times: 27\n",
      "Epoch: 095, Loss: 1.2489 Test: 1.2240 \n",
      "trigger times: 28\n",
      "Epoch: 096, Loss: 1.2706 Test: 1.2011 \n",
      "trigger times: 29\n",
      "Epoch: 097, Loss: 1.2651 Test: 1.2181 \n",
      "trigger times: 30\n",
      "Early stopping!\n",
      "Start to test process.\n",
      "Epoch: 000, Loss: 1.7316 Test: 1.4199 \n",
      "Epoch: 001, Loss: 1.3602 Test: 1.2958 \n",
      "Epoch: 002, Loss: 1.3390 Test: 1.3035 \n",
      "trigger times: 1\n",
      "Epoch: 003, Loss: 1.2986 Test: 1.2903 \n",
      "Epoch: 004, Loss: 1.2792 Test: 1.2555 \n",
      "Epoch: 005, Loss: 1.3183 Test: 1.2864 \n",
      "trigger times: 1\n",
      "Epoch: 006, Loss: 1.2813 Test: 1.2383 \n",
      "Epoch: 007, Loss: 1.2634 Test: 1.2353 \n",
      "Epoch: 008, Loss: 1.2809 Test: 1.2284 \n",
      "Epoch: 009, Loss: 1.2764 Test: 1.2937 \n",
      "trigger times: 1\n",
      "Epoch: 010, Loss: 1.2733 Test: 1.2310 \n",
      "trigger times: 2\n",
      "Epoch: 011, Loss: 1.2671 Test: 1.2780 \n",
      "trigger times: 3\n",
      "Epoch: 012, Loss: 1.2670 Test: 1.2142 \n",
      "Epoch: 013, Loss: 1.2783 Test: 1.2076 \n",
      "Epoch: 014, Loss: 1.2621 Test: 1.2151 \n",
      "trigger times: 1\n",
      "Epoch: 015, Loss: 1.2667 Test: 1.2225 \n",
      "trigger times: 2\n",
      "Epoch: 016, Loss: 1.2765 Test: 1.2236 \n",
      "trigger times: 3\n",
      "Epoch: 017, Loss: 1.2734 Test: 1.2238 \n",
      "trigger times: 4\n",
      "Epoch: 018, Loss: 1.2611 Test: 1.2879 \n",
      "trigger times: 5\n",
      "Epoch: 019, Loss: 1.2665 Test: 1.2420 \n",
      "trigger times: 6\n",
      "Epoch: 020, Loss: 1.2582 Test: 1.2123 \n",
      "trigger times: 7\n",
      "Epoch: 021, Loss: 1.2763 Test: 1.2354 \n",
      "trigger times: 8\n",
      "Epoch: 022, Loss: 1.2525 Test: 1.2377 \n",
      "trigger times: 9\n",
      "Epoch: 023, Loss: 1.2667 Test: 1.2557 \n",
      "trigger times: 10\n",
      "Epoch: 024, Loss: 1.2797 Test: 1.2119 \n",
      "trigger times: 11\n",
      "Epoch: 025, Loss: 1.2646 Test: 1.2135 \n",
      "trigger times: 12\n",
      "Epoch: 026, Loss: 1.2760 Test: 1.2491 \n",
      "trigger times: 13\n",
      "Epoch: 027, Loss: 1.2745 Test: 1.2504 \n",
      "trigger times: 14\n",
      "Epoch: 028, Loss: 1.2869 Test: 1.2807 \n",
      "trigger times: 15\n",
      "Epoch: 029, Loss: 1.2629 Test: 1.2209 \n",
      "trigger times: 16\n",
      "Epoch: 030, Loss: 1.2576 Test: 1.2172 \n",
      "trigger times: 17\n",
      "Epoch: 031, Loss: 1.2743 Test: 1.2673 \n",
      "trigger times: 18\n",
      "Epoch: 032, Loss: 1.2953 Test: 1.2928 \n",
      "trigger times: 19\n",
      "Epoch: 033, Loss: 1.2638 Test: 1.2410 \n",
      "trigger times: 20\n",
      "Epoch: 034, Loss: 1.2509 Test: 1.2271 \n",
      "trigger times: 21\n",
      "Epoch: 035, Loss: 1.2615 Test: 1.2113 \n",
      "trigger times: 22\n",
      "Epoch: 036, Loss: 1.2501 Test: 1.2531 \n",
      "trigger times: 23\n",
      "Epoch: 037, Loss: 1.2525 Test: 1.2240 \n",
      "trigger times: 24\n",
      "Epoch: 038, Loss: 1.2693 Test: 1.2334 \n",
      "trigger times: 25\n",
      "Epoch: 039, Loss: 1.2653 Test: 1.4079 \n",
      "trigger times: 26\n",
      "Epoch: 040, Loss: 1.2752 Test: 1.2095 \n",
      "trigger times: 27\n",
      "Epoch: 041, Loss: 1.2571 Test: 1.2091 \n",
      "trigger times: 28\n",
      "Epoch: 042, Loss: 1.2732 Test: 1.2521 \n",
      "trigger times: 29\n",
      "Epoch: 043, Loss: 1.2501 Test: 1.2384 \n",
      "trigger times: 30\n",
      "Early stopping!\n",
      "Start to test process.\n"
     ]
    }
   ],
   "source": [
    "folds = 10\n",
    "results = []\n",
    "best_rmse_arr = []\n",
    "scores = []\n",
    "true_val = []\n",
    "pred_val = []\n",
    "for fold in tqdm(range(folds)):\n",
    "    model = AttentionConvNet().to(device)\n",
    "    # model = define_model(trial).to(device)\n",
    "    #optimizer_name = trial.suggest_categorical(\"optimizer\", [\"Adam\", \"RMSprop\", \"SGD\"])\n",
    "    # optimizer = torch.optim.Adam(model.parameters(), lr=.0023467,\n",
    "    #                              weight_decay=.00095)\n",
    "#     optimizer = torch.optim.Adam(model.parameters(), lr=0.007531829,\n",
    "#                                    weight_decay=0.000252036)\n",
    "#     model = AttentiveFP(in_channels=39, hidden_channels=200, out_channels=1,\n",
    "#                     edge_dim=10, num_layers=2, num_timesteps=2,\n",
    "#                     dropout=0.2).to(device)\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate,\n",
    "                             weight_decay=weight_decay)\n",
    "    val_losses = []\n",
    "    train_losses = []\n",
    "    mae_arr = []\n",
    "    patience = 30\n",
    "    trigger_times = 0\n",
    "    the_last_loss = 100\n",
    "    \n",
    "    model_file_name = 'saved_models/model_' +  str(fold) +  '.model'\n",
    "    result_file_name = 'result_' + str(fold) +  '.csv'\n",
    "    \n",
    "    train_data = Molecule_data(root='data', dataset='train_data_set_fold_'+str(fold),y=None,smile_graph=None,smiles=None)\n",
    "    test_data = Molecule_data(root='data', dataset='test_data_set_fold_'+str(fold),y=None,smile_graph=None,smiles=None)\n",
    "    model\n",
    "    \n",
    "    \n",
    "    train_loader   = DataLoader(train_data,batch_size=TRAIN_BATCH_SIZE,shuffle=True)\n",
    "    test_loader  = DataLoader(test_data,batch_size=TRAIN_BATCH_SIZE,shuffle=True)\n",
    "#     model = AttentiveFP(in_channels=112, hidden_channels=279, out_channels=1,\n",
    "#                     num_layers=3, num_timesteps=2,\n",
    "#                     dropout=0.047352327938708194).to(device)\n",
    "    best_ret = []\n",
    "    \n",
    "#     model = model.cuda(device)\n",
    "#     optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "#     best_mae = 0.00\n",
    "    \n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        train_loss,train_rmse=train(model, optimizer,train_loader)\n",
    "        test_loss,test_rmse = test(test_loader, model)\n",
    "#         score = metrics.r2_score(true, prediction)\n",
    "#         , true, prediction\n",
    "        \n",
    "        print(f'Epoch: {epoch:03d}, Loss: {train_rmse:.4f} '\n",
    "          f'Test: {test_rmse:.4f} ') #f'score: {score:.4f} '   \n",
    "        \n",
    "        ret = [epoch,train_rmse,test_rmse]\n",
    "        \n",
    "        train_losses.append(train_rmse)\n",
    "        val_losses.append(test_rmse)\n",
    "#         scores.append(score)\n",
    "        # Early Stopping\n",
    "        the_current_loss = test_rmse   #.item()\n",
    "        best_ret.append(ret)\n",
    "        if the_current_loss > the_last_loss:\n",
    "            trigger_times += 1\n",
    "            print('trigger times:', trigger_times)\n",
    "    \n",
    "            if trigger_times >= patience:\n",
    "                print('Early stopping!\\nStart to test process.')\n",
    "                break\n",
    "        else:\n",
    "            ret = [epoch,train_rmse,test_rmse] #, score\n",
    "            trigger_times = 0\n",
    "            the_last_loss = the_current_loss\n",
    "            best_rmse = the_current_loss\n",
    "            \n",
    "            torch.save(model.state_dict(), model_file_name)\n",
    "        # Early stopping\n",
    "#         the_current_loss = test_loss.item()\n",
    "        \n",
    "#         best_ret.append(ret)\n",
    "        \n",
    "#         if the_current_loss > the_last_loss:\n",
    "#             trigger_times += 1\n",
    "#             print('trigger times:', trigger_times)\n",
    "            \n",
    "#             if trigger_times >= patience:\n",
    "#                 print('Early stopping!\\nStart to test process.')\n",
    "#                 break\n",
    "#         else:\n",
    "#             ret = [epoch,train_loss,test_loss.item()]\n",
    "#             trigger_times = 0\n",
    "#             best_mae = the_current_loss\n",
    "#             the_last_loss = the_current_loss\n",
    "            \n",
    "#             torch.save(model.state_dict(), model_file_name)\n",
    "\n",
    "    results.append(best_ret)\n",
    "    best_rmse_arr.append(best_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "format_float = \"{:.2f}\".format(best_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(format_float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "resSt = results[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_val = resSt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1.4516923435313405, 1.4380451801306202]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65\n",
      "65\n",
      "75\n",
      "75\n",
      "90\n",
      "90\n",
      "58\n",
      "58\n",
      "177\n",
      "177\n",
      "36\n",
      "36\n",
      "86\n",
      "86\n",
      "82\n",
      "82\n",
      "98\n",
      "98\n",
      "44\n",
      "44\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEWCAYAAAB2X2wCAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAADDSklEQVR4nOydd5wc5X3/38+UbbfXT6d2kk5IIAnUQHRDgACm2dgE4tiGuGDHITYp2GA7sQ1uhED8cxwHO8ROCMUYbIyNwQkYHNGbQCCEJEC9l+tl67Tn98czM7t7RTqdTkJlPq+XXrrbnZl9dm73M5/5PN/v5xFSSiJEiBAhwqEP7b0eQIQIESJEGBtEhB4hQoQIhwkiQo8QIUKEwwQRoUeIECHCYYKI0CNEiBDhMEFE6BEiRIhwmCAi9AiHBYQQdwkhvrub56UQYuZ+eN2NQojz/J//QQjxnyPZdhSvc6YQ4t3RjjPCkYGI0CPsM4QQ1wohXhNCFIUQdw3x/LlCiHeEEDkhxFNCiGm7OdbZQghPCJEp+/fofhz7fwgh7hni8fn++2kY6bGklP8opfzsGI2r4gIkpXxOSjlrLI4d4fBFROgRxgLbge8Cdw58QgjRBPwa+AbQALwG/GJPx5NSpsv+fXCsB1yGu4A/EUJUDXj8E8DvpJRd+/G1I0QYU0SEHmGfIaX8tZTyYaBziKf/BFgppXxQSlkAvgksEELM3tvXEULMEUI8LYToEUKsFEJcupttbxBC7BBCbBdCXL2bsb8EbAMuL9tXBz4O3C2EmCGEWCyE6BRCdAgh7hNC1A3zmt8UQvys7Pc/F0Js8vf92oBtTxZCvOS/lx1CiNuFEDH/uWf9zd7071D+zL9z2TqSc+HbTz8SQvyPEKJfCPGKEGLGcOcgwuGDiNAj7G8cB7wZ/CKlzALr/MdHDCGECTwKPAE0A38N3CeEGGRDCCEuBK4HzgeOBvbkW9+DUuQBzgNM4DFAALcAk4A5wBTURWlP4z0W+Hfgz/19G4GWsk1c4DqgCTgNOBf4PICU8o/8bRb4dygVdzQjPBcfA74F1ANrgZv3NOYIhz4iQo+wv5EGegc81gtU72afSb7yDP59BDjVP9Y/SSktKeVi4Hco4hqIjwD/LaVc4V9AvrmHMd4LnCWECAj3E8DPpZS2lHKtlPJJKWVRStkOfB84aw/HA7gCZdk8K6UsoiwnL3hSSrlUSvmylNKRUm4E/mOEx4WRnYtfSymXSCkd4D5g4QiPHeEQhvFeDyDCYY8MUDPgsRqgXwgxFVgVPCilTPs/bpdSlqtZhBB/BmyRUnplD28CJg/xmpOApQO2GxZSys2+zXGVEOJ24MPAmf7rNgM/9H+vRomg7t0dr2wMW8peIyuECC0pIcQxqIvDiUAK9V1cOvAguzv2Hs7FzrKfc6gLQITDHJFCj7C/sRJYEPziTz7OQPnqm8snP/dwnO3AFCFE+Wd2Ksr/HogdKGukfLs94W6UMr8c2CClfN1//BZAAvOllDXAVSgbZk+oGIMQIoWyXQL8O/AOcLR/3H8Y4XFh785FhCMIEaFH2GcIIQwhRALQAV0IkRBCBHd/vwHmCiEu97e5EVgupXxnL1/mFSALfFkIYQohzgY+CDwwxLa/BD4lhDjWJ9KbRnD8h1AE/C0UuQeoRt1l9AghJgM3jHC8vwI+IIQ4w5/s/DaV37dqoA/I+BPEfzVg/13AUcMce2/ORYQjCBGhRxgLfB3IA19FKdi8/xi+73w5alKuGzgF+OjevoCU0gIuBS4COoAfA58Y6sIgpXwM+AGwGDUhuHgEx89SIvX7yp76FnACyvf/H1QJ5kjGuxL4AvBzlFrvBraWbXI9qpKmH/gpg0s5v4mqsgnmEMqPPeJzEeHIgogWuIgQIUKEwwORQo8QIUKEwwQRoUeIECHCYYKI0CNEiBDhMEFE6BEiRIhwmOA9ayxqamqSra2t79XLR4gQIcIhiaVLl3ZIKccN9dx7Ruitra289tpr79XLR4gQIcIhCSHEsJ3PkeUSIUKECIcJIkKPECFChMMEEaFHiBAhwmGCKG0xQoQDANu22bp1K4VC4b0eSoRDBIlEgpaWFkzTHPE+EaFHiHAAsHXrVqqrq2ltbUWIkYYqRjhSIaWks7OTrVu3Mn369BHvF1kuESIcABQKBRobGyMyjzAiCCFobGzc6zu6iNAjRDhAiMg8wt5gNJ+XQ47Q13Sv4d/e+De6CtFi7BEiRIhQjkOO0Nf3rucny39CZ36oBeYjRIgQ4cjFIUfohqbmcR3PeY9HEiHCoQVd11m4cGH4b+PGjcNu+6lPfYpf/epXgx5/+umn+cAHPjDkPrfccgszZ85k1qxZ/P73vx/22FdccQXr168HVMf4vHnzmD9/PmeddRabNpWaIIUQ/Pmf/3n4u+M4jBs3Lnz9Xbt28YEPfIAFCxZw7LHHcvHFFwOwceNGkslkxXu95557hj8xI0BnZyfnnHMO6XSaa6+9dtjtbrjhBmbPns38+fO57LLL6Onp2eP+5513Ht3dI1mmds845Ajd1FQJT0ToESLsHZLJJMuWLQv/jWWW0qpVq3jggQdYuXIljz/+OJ///OdxXXfQditXrsR1XY46qrS63lNPPcXy5cs5++yz+e53vxs+XlVVxYoVK8jn8wA8+eSTTJ5cWgf7xhtv5Pzzz+fNN99k1apV/NM//VP43IwZMyre6yc+8Yl9en+JRILvfOc7fO9739vtdueffz4rVqxg+fLlHHPMMdxyyy173P/P//zP+fGPf7xP4wtwyJUtGv5SlY6MCD3CoYlvPbqSVdv7xvSYx06q4aYPHrfX+y1btoxrrrmGXC7HjBkzuPPOO6mvr6/Y5vHHH+fv/u7vaGpq4oQTThjyOL/97W/56Ec/SjweZ/r06cycOZMlS5Zw2mmnVWx333338aEPfWjIY5x22mn88Ic/rHjsoosu4n/+53+44ooruP/++/nYxz7Gc889B8COHTt4//vfH247f/78vX7/I0VVVRVnnHEGa9eu3e125eM59dRTw7uc3e1/6aWXcuaZZ/K1r31tn8d5yCn0yHKJEGF0yOfzoQVx2WWXAfCJT3yCW2+9leXLlzNv3jy+9a1vVexTKBT4i7/4Cx599FGee+45du7cOeSxt23bxpQpU8LfW1pa2LZt26DtXnjhBRYtWjTkMR5//HE+/OEPVzz20Y9+lAceeIBCocDy5cs55ZRTwue+8IUv8JnPfIZzzjmHm2++me3bt4fPrVu3rsJyCS4C5bjuuusqtgn+lSv9fcGdd97JRRddtMft6uvrKRaLdHbu+7zgoafQfUK3Pfs9HkmECKPDaJT0WCCwXAL09vbS09PDWWedBcAnP/lJ/vRP/7Rin3feeYfp06dz9NFHA3DVVVfxk5/8ZNCxh1qbeKiyux07djBuXGXy6znnnMOuXbtobm6usFxAqe6NGzdy//33hx55gAsuuID169fz+OOP89hjj3H88cezYsUKoGS57A7/8i//stvn9wU333wzhmFw5ZVXjmj75uZmtm/fTmNj4z69bqTQI0SIsFuMpB66paWFLVu2hL9v3bqVSZMmDdoumUwOapZ56qmn2LRpE8cddxw33njjoH0uvfRSrr/+ej72sY8Neq6hoYGPf/zj3HvvvZx00kk8++yzI3lLwP5T6HfffTe/+93vuO+++0ZcS14oFEgmk/v0uhAp9AgRjljU1tZSX1/Pc889x5lnnsm9994bqvUAs2fPZsOGDaxbt44ZM2Zw//33D3msSy+9lI9//ON88YtfZPv27axZs4aTTz550HZz5sxh7dq1gyZkk8kkP/jBD5g3bx5f//rXaWhoCJ+7+uqrqa2tZd68eTz99NPh44sXL+bUU08llUrR39/PunXrmDp16ojf//5Q6I8//ji33norzzzzDKlUakT7SCnZuXPnmExSRwo9QoQjGHfffTc33HAD8+fPZ9myZYMUciKR4Cc/+QmXXHIJZ5xxBtOmTRvyOMcddxwf+chHOPbYY7nwwgv50Y9+hK7rg7a75JJLKki5HBMnTuRjH/sYP/rRjyoeb2lp4W//9m8Hbb906VJOPPFE5s+fz2mnncZnP/tZTjrpJGCwhz5wsnU0aG1t5Ytf/CJ33XUXLS0trFq1CoDPfvaz4WI91157Lf39/Zx//vksXLiQa665Zo/7L126lFNPPRXD2Hd9LYbyvg4ETjzxRDmaFYs29G7g0ocv5Z/O/CcuOeqS/TCyCBHGHm+//TZz5sx5r4fxniOfz3POOefwwgsvDEn4RyL+9m//lksvvZRzzz130HNDfW6EEEullCcOdaxIoUeIEOGAIZlM8q1vfWvICpgjFXPnzh2SzEeDQ85DjxqLIkQ4tHHBBRe810M4qPAXf/EXY3asSKFHiBAhwmGCQ4/Qo07RCBEiRBgSeyR0IcSdQog2IcSKYZ6/QQixzP+3QgjhCiEahtp2LBAp9AgRIkQYGiNR6HcBFw73pJTyn6WUC6WUC4G/B56RUu63sPKoDj1ChAgRhsYeCV1K+SwwUoL+GDB058EYIVLoESKMDvszPnek8bJweMfnfuMb32D+/PksXLiQ97///RX5MsuXL+e0007juOOOY968eWHH7FjG545ZlYsQIoVS8sO+WyHE54DPAXvV0VUOXaja1YjQI0TYOwzMchlLBPGwK1asCPNUhsJw8blNTU3cdNNNfPe73+WnP/0pUBmfm0wmh43PDZqOli9fHj43kiyX/fH+brjhBr7zne8A8MMf/pBvf/vb3HHHHTiOw1VXXcW9997LggUL6OzsxDRVxV4QnzsWaYtjWbb4QeCF3dktUsqfAD8B1Vg0mhcRQmBoRkToEQ5dPPZV2PnW2B5zwjy4aO8zSMYqPnek8bKHe3xuTU1N+HM2mw2zXJ544gnmz5/PggULACpCuA7W+NyPsp/tlgCmZkaEHiHCXmJ/xueOFEdCfO7XvvY1pkyZwn333ce3v/1tAFavXo0QggsuuIATTjiB2267Ldz+oIvPFULUAmcBV43F8fYEQxhR2WKEQxejUNJjgf0ZnztSHAnxuTfffDM333wzt9xyC7fffjvf+ta3cByH559/nldffZVUKsW5557LokWLwg7RAxafK4S4H3gJmCWE2CqE+IwQ4hohxDVlm10GPCGlzO7TaEaIyHKJEOHAYaQRsCPBkRCfG+DjH/84Dz30EKACxs466yyamppIpVJcfPHFvP766+G2Byw+V0o5+CwO3uYuVHnjAUFE6BEi7DvGMj53pDjc43PXrFkT3s088sgjzJ49G1B3E7fddhu5XI5YLMYzzzzDddddB4xtfO4hl+UCitCjOvQIEfYdd999dzgpetRRR/Hf//3fFc+Xx+c2NTVxxhlnDFvl0draSl9fH5Zl8fDDD/PEE09w7LHHVmwTxOeed955g/Yvj8/9xje+ET6+u/jca6+9FsMw8DwvjM/duHFj6KEHuPrqq/mbv/mbvTk1I35/n/3sZ7nmmms48cQT+epXv8q7776LpmlMmzaNO+64A1A++Re/+EVOOukkhBBcfPHFXHLJJeH7OGLjcwEu/vXFzGuax61/dOsYjypChP2DKD5XIYrPHYwjOj4XIoUeIcKhiig+dzCO6PhciDz0CBEOZUTxuZU4ouNzIapDjxAhQoShcEgSeqTQI0SIEGEwDk1CjxqLIkSIEGEQDklCjyyXCBEiRBiMQ5LQI8slQoS9x/6Mz33yySdZtGgR8+bNY9GiRSxevHjYYx/O8bk33HADs2fPZv78+Vx22WX09PQAKpSsfDyapoXRBGMZnxsReoQIRwiCLJfg31h0JgZoamri0Ucf5a233uLuu++uIOJyDBefu3z5cs4+++yKLJfy+Fxg2PjcN998k1WrVlW07AdZLsG/T3ziE/v0/oL43O9973u73e78889nxYoVLF++nGOOOYZbbrkFgCuvvDIcy7333ktra2vY+BTE544FDrmyRceyiOckjmO910OJEGFUuHXJrbzT9c6YHnN2w2y+cvJX9nq/sYrPPf7448OfjzvuOAqFAsVikXg8XrHd4R6fWz6eU089dci7nOB9BDhY43MPCNa+9jKTfrYJszdS6BEi7A0OVHzuQw89xPHHHz+IzOHIiM8NcOedd3LRRRcNevwXv/hFBaEfdPG5BxJmPKF+sN33diARIowSo1HSY4EDEZ+7cuVKvvKVr/DEE08M+fyREJ8LKkLXMAyuvPLKisdfeeUVUqkUc+fOrXj8gMXnHmyIJSJCjxDhQGKk8blbt27lsssu45577mHGjBlDbnMkxOfefffd/O53v+O+++4bdO4eeOCBId/HAYvPPdhQUujeezuQCBEOcYxlfG5PTw+XXHIJt9xyC+973/uGfc3DPT738ccf59Zbb+WZZ54hlUpVPOd5Hg8++OCgi85YxucecgrdTKirmIgIPUKEfcbdd9/NDTfcwPz581m2bNkghVwen3vGGWcwbdq0IY9z++23s3btWr7zne+ESretrW3QdkF87lAoj88tx+7ic0888UTmz5/PaaedFsbnwmAPfeBk62jQ2trKF7/4Re666y5aWlpYtWoVAJ/97GcJkmOvvfZa+vv7Of/881m4cCHXXFNaB+jZZ5+lpaWlosIneB9HbHxuX0cbP/3C1by2MMP9f//02A8sQoT9gCg+VyGKzx2MIzo+N1LoESIcuojicwfjiI7PDSZFNee9ubOIECHCviGKz63EER2fqxsmaALNUZMJESJEiBBB4ZAjdABiBqYrovb/CBEiRCjDIUnowtQxHC1ahm6M0NbWxjvvjG0reoQIEQ48DklC12KmUuhRJvqY4JVXXuHRRx99r4cRIUKEfcQhSegiZmA4keUyVnBdF9eNOm8Pd+zP+NwlS5aEx12wYAG/+c1vhj32kRifO3BM5fXpYxmfu8cqFyHEncAHgDYp5dxhtjkb+AFgAh1SyrOG2m6soMdiGEUtIvSByPfA5pdh1oV7tVtE6EcGBma5jCXmzp3La6+9hmEY7NixgwULFvDBD35wULPMcPG5TU1N3HTTTXz3u9/lpz/9KVAZn5tMJoeNzw2ajpYvXx4+N5Isl71BEJ+7YsWKMC9mKJx//vnccsstGIbBV77yFW655RZuvfXW3Y4piM8di7TFkZQt3gXcDgx5iRNC1AE/Bi6UUm4WQjTv86j2AC1uYvZECn0Q3noQ/vd6+MpGSNbvcfMAnudFhH4AsfMf/5Hi22M7ZxGfM5sJ//APe73fWMXnlre5FwqFYfNfovjcwTig8blSymeBrt1s8nHg11LKzf72g/t9xxh6LIYRVbkMhpX1/8/t1W6u6+J5XlQGephjf8fnvvLKKxx33HHMmzePO+64Y8hW9iM5PnfDhg0cf/zxnHXWWRXjOdjic48BTCHE00A18K9Syn0zrPYAPR7DcCLLZRBcv+rHKex+uwHwPNV167rumORJRNg9RqOkxwL7Oz73lFNOYeXKlbz99tt88pOf5KKLLiIRpKP6OFLjcydOnMjmzZtpbGxk6dKlfPjDH2blypXU1NQAB1d8rgEsAi4BLgC+IYQ4ZqgNhRCfE0K8JoR4rb29ffQvGI9juOKQLlt0LIvFd/0Hub7esTuo66/i5BT3bjffbolslwhDYaTxuQHmzJkT+t8DcaTG58bj8ZCsFy1axIwZM1i9enW4z1jF544FoW8FHpdSZqWUHcCzwIKhNpRS/kRKeaKU8sSBV+m9gRGPYbraQVm2uOrZxfzm1m/tcbud61bzxmOPsunN18fuxb19U+jB/xGODJTH5wJ7jM8Fho3P3bBhA46jvo+bNm3i3XffHTIONojPHYggPveee+6hq6vS4b366qu58cYbmTdvXsXjixcvJpdT9uJo43PL1x0N/n31q18d8TEGIojPfeSRRyrmFdrb20PBtH79etasWRNODB9s8bm/Bc4UQhhCiBRwCvD2GBx3WBjxBLonsOy9U6JjBddxyHQPPa2wZdUK1r/+Kq6z+4tNf2cHAPn+vjEcWEDokUKPMDKMVXzu888/z4IFC0J//sc//jFNTU2DtjtS43OfffZZ5s+fz4IFC7jiiiu44447wsz3sYzPRUq523/A/cAOwEap8c8A1wDXlG1zA7AKWAH83Z6OKaVk0aJFcrT41X3/Ir/3kUvkS+ufG/Ux9gVvPP47+cNP/ql0bGvQc7/9fzfL733kEtnX2b7bY7z8m1/K733kEvn8A/eM3cD+53opb6qRcu3ivdrtpz/9qbzppptkT0/P2I0lQgVWrVr1Xg/hoEAul5OnnHKKdBznvR7KQYO/+Zu/kX/4wx+GfG6ozw3wmhyGV/d4SZBSDjauBm/zz8A/j/Kastcw/YkWq5A/UC9Zgd72XVj5HPn+ftL1DRXPFbMZAHI9PVQ3DFYoAfaPQg889L2zXCKFHuFAoTw+d2/skcMZR3R8LkDMz0R/rwi9kFGkXejvG0TohYwqHcz27L7zq79TTQrn+/aH5TL6KpcIEfY3ovjcShzR8bnw3hN6MecTuk/s5Sj4Cn3PhL4/FfreeegRoUeIcHjgkCZ0u7B3SnSsENgq+cxgMi4eFIQ+OsslqnKJEOHQxqFH6N2biO1cCoBVHL1Cz/X24I1SkRayylYZqNA9z6WY27PlYhcLFHwiPxiqXCKFHiHC4YFDj9C3v0Hi9f8ERq/QbavIf/3tX7Di6SdHtX+o0AeQcTFXarnP7YbQA3Webmgk3983di330aRohAhHNA49Qk/UENcU8TiF0dWhZ7o6sfJ5encNn0uxOwQ+efB/gGKZYs/27obQOxShN0+fgee6WPm9y14ZFoFCt6NJ0QiDsT/jcwNs3ryZdDrN9773vWG3OZzjcx988EGOO+44NE0La9MDLF++nNNOOy3Muwk6Zg9ofO5Bh3gtCeETujU6Qs/6TUEDCTmA9DyENvS1TnpeqMQLgxS6sluMeJxcb8+wrx9UuDS3zmD90iXk+/qIp6r26j0MiVFWuUQK/cjA/ozPDXDddddVBFINxOEenzt37lx+/etf85d/+ZcVjzuOw1VXXcW9997LggUL6OzsxDRN4MDH5x5cSJQRetEa1SECfzvwwstRyGT46bWf5pK//TJHHX/SoOeL+Rz4FslADz34vWFSCz07S8lv3Tu389Kv7uf9f/k3GKYZWi7N06YDyrqpmzBxVO+lAgdZlYuUkk2bf8KkiZcTiw1fk3+k4blfrqZjy9BiYrRompLmzI8MGaG0W4xVfC7Aww8/zFFHHUVV1fDi5HCPz50zZ86Qjz/xxBNhpyhQEcJ1QONzDzokaogLFw+JO0pCz/hZEcUhFHpv206sfJ51r74y5L7l+wyscgkUf+PkKVj5fOjxr3v1Zd5+7ik6Nm0AlEJP1daRblB/1DGbGD3IPPRicQfr1t1Ge/sfxvS4EUaH/Rmfm81mufXWW7npppt2O4YjKT63HKtXr0YIwQUXXMAJJ5zAbbfdFj53sMXnHljEa4gBjiFxrdEq9OEJPe+nH257d9WQ+waqXtP1QQo9OF7D5CnqdXp7qEtMoKdtF6A6TCfMPIb+zg6qG8eRrFbRmWNH6PtW5TLWZYueHxbmydH9nQ5XjEZJjwX2Z3zuTTfdxHXXXUc6nd7tGI6U+NyBcByH559/nldffZVUKsW5557LokWLwg7Rgyk+98DCTGBoJo7u4RVHF5+7Ow8955Nr59bNQxJtQNo145oHeejlCh1K1k5fm1I1Pf4kbF9HO9WNTST9LOT8WEXojkKhly9sMfaWizqePIRjjiOMLD73lVde4ctf/jKtra384Ac/4B//8R+5/fbbB213JMTnDoWWlhbOOussmpqaSKVSXHzxxbz+eilpdazicw89hQ4YiVocXeJZoyOKzG489HJy3fbOKmaedGrF8wFp142fyJZVbyGlDD/whWwGTTeoHT8BKJUuhgq9bSee59LX3sb0hYuIJVNour4fFPreEXq4+5gTuuO/RqTQD0aUx+eeeeaZe4zPnTFjxrDxueWWxje/+c1hq0GC+NyBUbFBfO68efP4+te/HiYRgorPra2tZd68eRVJjYsXL+bUU08llUqNOj73QOGCCy7gtttuI5fLEYvFeOaZZ7juuuuAgy8+94BDi9fgGKMn9EChF7OZQTXgub5ehKahG8aQtkvRvwjUjp+Ia9sVlTbFTIZEOk1VnZpUyvZ0Iz0vVOi9bbvo3bUTxyrSNGUaQgiS1TXvqYdeTuL7S6F7MlLoByvGKj53pDjc43N/85vf0NLSwksvvcQll1wS5tbU19fzxS9+kZNOOomFCxdywgkncMkll4TvY6zicw9JhU6iBkf3kNboFrgICF16HnYhTyxZCqLP9/WSqqmldvxEtr29ctC+JYWuVHi+vx8zrtIfC7ks8ao0yZoahNDI9naT6e7CdRyE0Oht20nHZlVn2zS1FWBsCd3bew89UuhHDjJDZA8tXLiQl19+edDjd911V/jzhRdeyDvvjHxR629+85vDPnfFFVdwzjnn8K1vfQtd1wfVwv/bv/3bbsd79tlnc/bZZwNwww03cMMNNwzaprW1lXx+7HOehqvb/8///M/w58suuyyccB6Iq666iquuumrQ4/feey+f//znx2SMh6RCJ16Dq8tREbpjWRSyGWrGjQcG++i5vj6SNbW0zD6WXRvWYhcr1W4xm0VoGjXjmtX+mf6y5zIkUlVomk6qtpZsT3fYvDT+qBn0tbfRtmk9CEFji/LZd0fofe1trFs6dLXNkDjoLJfAQ48IPYJCeXxuBIWxjM89NAk9UYune0h77wk9mKgMCHVgpYpS6DU0T5+J57p071ClUK8/9gjbV79DIZtRKtyvUCkn9EImQ9yf5a9pHk/Hpo30+HbL1HkLkZ7Hhjdeo37CxFDVJ6tryPf10dfeRndZ7TrA0/f+J7/955vJl73GbrGPlstYV7mECj2qcolQhgsuuCDKQi/DER+fS6IGT5dg7b2iDEoWG1vUB2pg6WK+v5dkdW1oqfS27cR1HJ6+5z9Z+r+/VSq8qopEuhpQhL5jzbsUczn/OUXo0xcuYse61exY8w5CaEw5Vq2HuGv9WhpbSj5ksqaGvs527v3q33L39V9gxVNP+sfNsH7pEqT02LLizZG9uVE0Fu1fhR6UQ0YeeoQIBwKHJqHHa7FjLiJn73WwVdbPTGiY3AIMZbn0kqyppbY5IPRd9LbtQnoe7RvXUcxmiKfSJH1Cb9+0gfu/cQMvPXR/qN4BjjrhZJCSVc89RXXTOOonllqWA/8clEJ3ikWMWIzJs+bw+zv+lZd//QtWv/I8ruOg6Tqbli/b8xvzXPAJ9OCZFFUKPbJcIkQ4MDhkJ0WtuIVwJbnenrCqZCTIdKturMbJgUIvlS66jkMxmyVVU0sinSZeVUVv286wjb97x3Y03SDd0Bgq9OX/93uk9Fj36ssUs9lQoTe3HkW6sYlMZwd148dT3diEput4rsu4qSWFPvHo2TS2TOXSL/0DdRMm8tjt3+eFX/6M6sYmGiZPoX7iJDa99cae35hbRpoHjUKPqlwiRDiQODQVeqIWK6lIotev8R4psj3dCE2jfpJSzOUKPZicTNbUAlDbPIHeXTtDHx1Uw1G8Ko0Ri4UhXEJo9OzagZQeCT/HQgjBjBNOCo+j6To1TWoitVyhH3XCSXzq//2YhkktaJrO+z/31zROnkJ/RzvHnnkO0+YtpLdtFz07d+z+jZUT+l6kLR4IhR5VuUSIcGBwaBJ6vAY7oQi9r314Qt+84k0yXZX5CJnuLqpq60ikqkCIymwWv6ko5Xdw1jWrtv3unUqZB0j4yYjJtNruhIs/WBpaWevzUYtOBgjtm5rm8RhmbLdBXGYiwaVf+hpzzjyHeX/8fqbNV2FIe1TpQYWLmToIq1wihX4wYH/G5w6MrL3mmmuGPfbhHJ8b4Hvf+x5CCDr8qGzbtvnkJz/JvHnzmDNnDrfccku47ZEdnwuqDj3uK/T2tiE38TyXX//TNznurHM5/y9Kf4BsTzdV9Q0ITSORqqpQ6Dmf0EOFPn4C65a+Qvf2Rppbp9Pb3ka+rzck7UQ6TX9XB4suuYwtq1bQtmFdaLkATJ27kOPOOjfsNp19+h/RNGUamqbv9u01TJrMxdd+KRxLddM4Ni1fxoLzLx5+p0Chx6shs0slQo6gZfuANBaNhUK3C3DnBXDhLTDt9H0/3hGI/R2fO5L8lMM9Phdgy5YtPPnkkxWVPA8++CDFYpG33nqLXC7Hsccey8c+9jFaW1uP8PhcgEQtmuHhxKFvGMsl09mJa9vsWl+Ku5RS0r5xPVOOUzGb8XSaQibDhjdeY9u7q2iaorztVJnl4joO29e8w8wTTyVelWbT8jdC0m6YPIXqxiaqG5uYsehk2jasI54qEbphmlz4+evC3+f9cSnqc6QQQvBHV346LJMcFoFCDwjdKYKZ2OPxyxX6/itbHAOFntkFO5bB9mWHPKE/dddPVD/CGKJ52lGc86nP7fV+YxmfOxIc7vG5oDJibrvttor3KYQgm83iOA75fJ5YLEaN7wQc2fG5APEaDAl2laB3GMslCMLq2LwR11GE0rVtC9me7hKhp6oo5rK88fijvPKbX9Lmx9uWK3QAp1ikfuIkmqfPCPcDuOSvr+fSL6k/wnFnnUfrghMY1zp9zN/u7NP/iGnzFu5+o5DQfeIfoe1y6Ch0f1UnZ+w7AI8U7M/4XIANGzZw/PHHc9ZZZw0ZVwuHf3zuI488wuTJk8Pc8wBXXHEFVVVVTJw4kalTp3L99deHeTVHdnwuQKIGU0qKKY++YSyXXr+hx3UcOrduobn1KDa9peq5p81TJztRlaaQ6Q8nPVc9uxiEIOFbKrXN48Pj1U+YhNCVVRI8LzQN3V/ZqLZ5PJf/w7fH+p2OHOWWC4y40uVAtP7LsWgsCgh9L5fXGw6/W/87Tp90Og2Jhj1vPMYYjZIeC+zP+NyJEyeyefNmGhsbWbp0KR/+8IdZuXJlqEIDHM7xublcjptvvpknnnhi0HNLlixB13W2b99Od3c3Z555Juedd15oPR2w+FwhxJ1CiDYhxJDGkRDibCFErxBimf9vcP7lWCNei4GkmHTpa1c14gNRXv0S2C6bV7xJbfP4cJIyUZWmffPGsNsz291FMl0detw1TeMQQp2iuomTmDp3AVOOm8/EmbP269sbFQYR+siU7AEpWxwLhW6NnULvLfby98/9PY9teGyfj3UkYCTxufF4PCSjRYsWMWPGDFavXj1ou8M5PnfdunVs2LCBBQsW0NraytatWznhhBPYuXMnP//5z7nwwgsxTZPm5mbe9773Vaw5OlbxuSOxXO4CLtzDNs9JKRf6//a/TE0oyyWfcnAdJ2znL0dv205qxo0nlkyya8M6PNdl66q3mDq3dCsUT6dxikrJTvUtjcBuAdANk+omtXRa/YTJpGpq+ciN/xjmuBxUGGS5jEyhByRummYloa9bDP8yF6zBEcMjRalscQw89DFU6Hn/olB0R7cm7eGC8vhcYI/xucCw8bnt7e3h52f9+vWsWbOmYuIzQBCfOxBBfO4999xDl7+iWICrr76aG2+8kXnz5lU8vnjxYnL++r6jjc9dtmzZoH9f/epXR3yMcsybN4+2tjY2btzIxo0baWlp4fXXX2fChAlMnTqVxYsXI6Ukm83y8ssvM3v2bOAAx+dKKZ8Fuva03YFCR8dTvLjk/dTGBPlEZaXLuqVLeOgfb8SxLHp37aRu/ASaW2fQtn4tuzaspZjLVhK674XHkilOvvQKoDQhGqC2eQKJ6prQZjloMUihj4z4AoU+iNDb3obeLZDtGPWQxjScK7iwjIFCt/xzZblRffxYxec+++yz4ZqZV1xxBXfccUdFpnmAwz0+dzh84QtfIJPJMHfuXE466SQ+/elPh5O4B2N87mlCiDeB7cD1UsrBubOAEOJzwOeAUYfzSGmTz28mocfIBrXobTsxTJPf/eutOMUi295ZRW/7LmYsOplYMsmbTzzGK7/5JUAFoQfVKhNmHkPLsXOJp6pIDeg6nXfuBcP69AcVQkL3LzwDFXq2A9rfgdYzKncrU+gVVS7hJOToFfGYVrnY+cr/9wGBMrePsPr4/Rmfe/nll3P55ZfvcQyHe3zucNun02kefPDBIbcby/jcsSD014FpUsqMEOJi4GHg6KE2lFL+BPgJwIknnrh3ISw+NE35TDFdJ5tUJLby2cV0bN5IMl1D1uli3dJXyPX2UNs8gZqmcTi2xbqlSzjrqqtJ1daFxwpU96SjZ6EbBh++4RskaysV+pz3Vd6CDgfXdVm1ahXHHXccCNDEAS4gKi9bhMFEvOSn8Pz34Wu7QCuNLSDxWCxWqdDHgED3S5XLGFguRyqhHwwoj8+NEhcVxjI+d58JXUrZV/bz/wohfiyEaJJSjv5efTfQdZ/QDQPLc0nXN7Bp+RuMmzadi6/9En/4rx/z9nNPAaryZOq8hRx1wkkcf8EHaF1YWS4VBGlNPFp5WS3Hzh31uN59910eeughXup5ice6HuM3H/rNqI81Knh78NALvUrF29kS6VOp0B2nLI54DAldjoVCH0PLJSR0NyL09wLBKj4RFMYyPnefCV0IMQHYJaWUQoiTUb78vhdUDgNNV80ypqZjS4cPfvHv8TyPybOORQjB1LkL2PaO8rZqx08gVVPLZV+5achjtS44gVMu+0iFDTNatLe3A7Czbydb+rfs8/H2GqHlMkwdekCExf4KQi/30IvFsovAGNR970mhZ7PrSKWOGlEVRekCEyn0CBGGw0jKFu8HXgJmCSG2CiE+I4S4RggRhDVcAazwPfQfAh+Ve5tpuxfQtZJCL0qPScfMoWX2cSEpTC1rwAnKE4dDoirNGR/9BEYsts/jCjIbXNvFcq29jvXdZwy0XAYSn11G6OW7+Qp9eMtl3z10KZ0wGz1ALreBl195Pz09S0Z2MHvsJ0Udb3RLGEaIcLBijwpdSjm4+LPy+duB28dsRHtAYLkkDYOCGEyaE2ceo1YD8hdgPlAICd1xkUgc6WAK84C9/h6rXALFPYDQh61yCT3r3KiHFCh09To2uh4Pf7csdRNn2yMMJbIiDz1ChD3hkOsU1TRlucR1E8cD13XQy5IQdcOkdcEJZHq6RnYrPwbwPC8k9MCHtl0bUzuYCH2UCn0MqlzUzxZQInTXKwzaZrcYgwtMgEChRx56hMMNh1yWS6DQm9Zlue1Ol3x2cEnhBX/1d8P65rtDsVjEtvf+S97f3x/u5zlK8R5w9TeoymXApOgwhF6u0CvLFsduUlS9TqWP7rmK0L29JfR9uMAEKPivfaQp9P0Znwsq7fC0007juOOOY968eYM6QgMczvG5N9xwA7Nnz2b+/Plcdtll9PT0VDy/efNm0uk03/ve98LHxjI+95AjdE1TKi9WdJjSAf2vvzRom3gqFS4Rtze49957efLJJ/d6v0Cdg7Jc4D1oWtnTpOgeLBfDMIaxXEZG6NKTFDf2Vj5WTugDKl28QKGP1MceQ8slbCw6whbeCLJcgn9j0ZkYwHEcrrrqKu644w5WrlzJ008/jWkOvkMdLj53+fLlnH322RVZLuXxucCw8blvvvkmq1atqmjZD7Jcgn+f+MQn9un9BfG55UQ8FM4//3xWrFjB8uXLOeaYYypyz0HFDVx00UUVjwXxuWOBQ85yEUJD0+Lo/iRb9uln4ew9NzSMBN3d3VT5Kw7tDcoJXToSzPeALAJCj1UBYsQK3XVdNE1D1/V9slyK63ro+K8VjL/uBMzx6hyWq+/ybtGO/15B7hiVtbPXlsthULbY8+g6rO2jj1QYCrFJVdR9cMZe7zdW8blPPPFE2CkKDBsydbjH55aP59RTT624y3n44Yc56qijBnHMER+fq2lJBIp87JeWjckxpZQUCgUsa++JuKOjg0Qiga7reK660IxWoff+fiPWlv49bzgQrk+MuglGYjDxBQRtDVboAaF7nleqztlLz9or+F2h+XLfvHJSNEBxQx92T5+/zUgVuk+ArqUWxN4HHKmTovszPnf16tUIIbjgggs44YQTuO2224bc7nCPzy3HnXfeGarxbDbLrbfeyk03DbaCj/j4XF1PIMhi6YLYpjasrduItUze8467geM4uK47akJvampSfxCfa0ZD6NKT9D+1BSTEpuylZeRaIHTQdDDigxS6axUoEic1hELXdR3djwZ2XVdlSuytxeGqC4F0S5VH5WRd7qFL18Pz1PhGHAtQbv04Bf9OZHQIJ0XfI0IfjZIeC+zP+FzHcXj++ed59dVXSaVSnHvuuSxatGhQB+ThHJ9bjptvvhnDMLjyyisBuOmmm7juuutID5MJdcDicw9G6FoCcHlllqpiySxevM/HDCZwRjMpGhC6aZohoY2qxjkgRWcUKwe5Fuh+Pb2RGGSVLClO53Y+hSwMr9ChLEI3tFxG6KEHYy4be7lCD7pFpZTgSjxZHLTNblF+pzBCX3/lypWDJqXgyFXoo8VIqsVaWlo466yzaGpqIpVKcfHFF/P6668P2u5wjs8NcPfdd/O73/2O++67Lzx3r7zyCl/+8pdpbW3lBz/4Af/4j//I7beXqr3HKj73kFPoa9eupasrSzqpsXqy4PRtMQorh8wC2ysEH7K9VeiO49Df3099fb2aBAoU+ig8dOnbNcH/ewXXLiP0AQpdSnrdBDlSOIWtlE9VDVTonuep9Uj3dlI0vBjtQaH724WEPuJJ0SzocXCLIxqT53n86le/4owzzhikEt9rhX6woDw+98wzz9xjfO6MGTOGjc+94IILuO2228jlcsRiMZ555hmuu+66QdsF8bkDJ2SD+Nx58+bx9a9/vSKp8eqrr6a2tpZ58+ZVJDUuXryYU089lVQqNer43LHG448/zq233sozzzxDKpUKHy+3fL75zW9WVMsc0Pjcgw1CCIoWuEmdvhS4MYFnDZ1r3f3wWgrvjiz5d7SEHuyXTCYrCX00lktgV7ij6DJ1LeWfw2CF7tpY/rXbLlR64kMqdKcIBF76CCchncEXo6HKFuVAQh+x5ZKDlH87OoKJWsdxkFIO+fcs+PtHdehjF59bX1/PF7/4RU466SQWLlzICSecwCWXXDJou8M9Pvfaa6+lv7+f888/n4ULF3LNNdfs7pDh+zjY4nMPGOrr6/E8HTch6EuBp0tkcfCXVkpJdskOhC5IzGrgrbfeYsmSJVx99dVD3kKOltCD/JN4PI5pmghPHXtUk6IBKe6z5TJAods5LF+XW4U8qfLdhvDQscvGvtcKvZzQyxR6sAydT/gee2G5eJ4i8VQj9G8f0ZiCv+NQf88jVaHvz/hcUP76VVddtdttDvf43JEsIv3Nb36z4vexjM895BR6bW0tnmfgxQR9KYGje8jiEArdleCViGbJkiVs2bJlWI88IHTHcSobbMrgdHez4c/+DGvr1vCxYQl9VJbLvnjodkmhm8lKFWvnsVBkbxUrP+iBQtf8SF1F6AMmIPdi7FRYLmXk7pNnYMkEhD6ixqLA/knVj3hMwd95qL935KG/dyiPz42gMJbxuYccoeu6jiZNZAxluYihCV1afnSr49HX18eWLSoBcbjutfLHhyN9a/16Cm8up/D22+FjwxH6aG7nQw/dGa3lUqbQy6tTyhS6Xax8/0Mr9DJCH6nlMoT/L6WD8PNsSpZLoND930diuYSE3jjiMe2W0L0oPve9xAUXXBBloZdhLONzDzlCBzA8A0xJNgmO7uENcVstbZ9YXMnbZQQ8EkIfznbxcopIZNnzwX6JRALTNNE8dUpHpf5CD320lkvgoScrq0KcQslyGUBwQ3ro4b5iHydFXXQ/7jgoTwzuPvbKcglq0FNqfde9sVyGIvQj1XKJcPjjkCR009bA8DB0A1tzKwg2gGeX/Oi3h1DUAzEiQs8ropNWWZPMAIWue4oYRzUpui8euueUCL1qHGTbS8/Z+ZJCH/DePM8bXOUSEGayfuRli8Mo9GCFKTmgykUKX6GPpMolGE84KTpyhT7U3/JIslw8T9LXmcfzDnCcc4T3BIckoRuWRNNdTNvE0j1kcbDqDiyXbDHHpk2bwuyIfbFcpD/RIje9Cv9+BrhOBaEbpoEufULfJw99Hy2XmomQ2VXqHi2fFPUApzS28tb/4PeSxdEw8saiYMwD6tBDhR546EGVi2+5jKixqHw8MKIx7c5yOZIUul10KWRsHGvfumsjHBo45AjdsV20nEDXXdJWNbYhkEOQdGC5tOW7kVJy7LHHAvtouQSE3r4edr0F2fYKQtcNfe8VumNB1wZ13CFK/0aM8jr06okgPUXqUDkpiglWhvyKDtysPYzlUqaIR9j6P5T/rwhd1dQEVS6h5aJZ4TZ7RGi5jFyh785yCcoWPenh7mOMwEGPIMohEuhHBA45Ql+/rJ02T7UhVzvVWAZ4u1HoGZ8MJkxQqxftk+USeOh5v5wqs5NisYiu6xiGgdAFOjpCipGrvzfugR+fBsVMyUMfddmib7nU+DEI/TvU/+WToph4fb10/uxtcm+0DTMp6pN4smGvq1z2bLn4xC9GMyk6tgodDn+VLsv+35/xuffdd1/FsTVNG7b1/nCOz/3GN77B/PnzWbhwIe9///vDfJknn3ySRYsWMW/ePBYtWsTisu72Izo+N1kdQzpK9VW7SQoGQ3ro0lLE0e/kEEKE+RG7U+hBzoL12+tg8+Da3NBDD5pzMm0UCgUSCWUraLo6nbrUR67Quzcqxdm/s8xDHwPLBaBPfZicYg4P/84BE5lV7f/ScndftphqVIQ+TBln5esPVYfuhvn1gxqL9spDH1DlMkYeOhz+hF5idLlf43OvvPLK8Lj33nsvra2tLFy4cNB2h3t87g033MDy5ctZtmwZH/jAB/j2t78NQFNTE48++ihvvfUWd999d8WF6oiOz01WGeAoAq2SCYqGwPI8Hn30Uc4880zq6uoAkLZS6P12lpqaGmKxGJqm7ZbQq6uryWQy2P3tsPF5mHpqxTaBhx4QO/07KRariMfj0LUe8favgInoUh85UWT96N3MLqTrj304hf72o9B6JiTrBj9XYblMUv/7hG4XSlGtFmZ4hyEdb/dli+V137HydqTBCJX5gHAuTYsBYlCVi9wry8U/34k6VOXNnhX6nqpcDGHgSOc9IfTHHnts2NTC0WLChAmDcraBkNCHW+J2rOJzyxHE3A6Fwz0+t6amtOxlNpsNmxiPP/748PHjjjuOQqFAsVgkHo8f2fG524sZnm06mixVpGWMgiF4e8ZMli5dWlHNEip0N09tbS1CCBKJxG4tl+CPYWFC75ZB24SWS9Cck9kV/lH4/dcQ7SrpTff2QqEH1SiZnUPWcofo3wW/uAqW3Tf0ccotl1QjaKbqqkR1hwawMZF5RfDSkbsvW0z6FscIbJfgrmKgQhfCQNNig7NctFFMisaqVNPUCHz9cAUpz6vMeUcp9HTMvxs70AuRHGDIMvN8f8bnluMXv/jFsIR+JMTnfu1rX2PKlCncd999oUIvx0MPPcTxxx+veIMjPD53Ta6PR446ltNkI7XSpL9qAh0tswBoaystR+f5Cj3j5WmtVYo1Ho/vVqEHhJ6vd3B7NvkmRQnhpGjg2Wd2USw2EZcFePd/EfpsYC8tl4DQ+3chY7upcunzu1P7tlc83HHHHcRnzaK63HLRNGW79CkP3SqfH8CEQhZIwBAKfVDZIvgEWgpLGhLhpGjpf+k5CGEghFnWKTpQoe+F5WKmhkySHHKXMmVu23b4/qSUWJ7FOHMcPcWe90ShD6mk9xdChS73a3xugFdeeYVUKsXcuXOHfP5IiM+9+eabufnmm7nlllu4/fbbKy6SK1eu5Ctf+QpPPPFExT5HbHxuIqfUZZE4QnfIjTsbKQSNDQ0VhC5tDw9JViqFDsoHG4rQ7SX/jeu6VFdXE4tlsee10SbXDdquROi+yu9Xk6Lx7tWq6UUocjKkMTrLZYgI2hD9vjIKJjp9dN37M/off1yVKJYvSl09Kdy2vN3fxkD6il063jAKPauak4LM8RFYHHJAHnrHnStwMgWE0JVClyUPXSKRehCnO1LLRSh1bib3ynKBSnIPyknTplLoh7uHPhbFLXuz2PoDDzwwrDqHIyM+N8DHP/5xHnroofD3rVu3ctlll3HPPfcwY0ZlJv5YxececoQe71cr3RRJ8EZVF561g3lvvcVRU6bQ3t4e5rBIyyWPhYesIPShLJfC2+pqmTQhbqrnHat7kPEYTooGhJvZRSGfJVFsh/f9LVKox0dsuUhZQegMUSkSIiDy/l2VhygU8ArFSssFfIXuWy5l4WUWMWS/urWTnZuH99BjKUWeMKJJyHDM/rlxugpIz0ELLRc73E5qJRKVIyFUO6fUufBJfS8mRaGS3IOSxSpTXawO+/Z/OeD/MpTH5wJ7jM8Fho3PBXV39+CDD/LRj3502G2C+NyBCOJz77nnHrq6KhNSr776am688UbmzZtX8fjixYvJ5dR3crTxueUTp8G/r371qyM+xkCsWbMm/PmRRx5h9mx1197T08Mll1zCLbfcwvve976KfY7o+NzalhYALOJ4GvTnX2D2O+/SlIphWRa9vWqhYml5ZIX68gaEPpzlUuhQpVKJQgdxrSw0qrzbEpCBh+4BCGW5FArEKcLE+ci4mqzVpT6yxqJiv8r3BlXlEpCiB3JgZ98wCn1V8yR2aEZllQsohd63HaTE8uOFdV1Xk6Jrnlbvo69j+CoXM6VUOoys/d+pVOjS9pC4SqGLWKls0ZEVhD6icC4rW7q4GCNT6AMtl/BQ/oU28NBHtRDJIYRgScHhJkXHKj4X4Nlnn6WlpaWigmUgDvf43K9+9avMnTuX+fPn88QTT/Cv//qvANx+++2sXbuW73znO+GYAkfhgMbnCiHuBD4AtEkphzbG1HYnAS8DfyalHFzAOkaoapkMO1dTJE5M5CkY6pPa1K5WR2lvb6e+vh5pu2QGEHq55ZLL5UgkEmhOgUK/UgSJ3DZi/j6eDvRsgXRz+Nqh5eIJqJ+G7N1BUTrEsWDcbGQ8BRlF6CNSfuUXjMyuyuXbHA8RK3PxAyLPlBS6tG2+dfW1nNa5k5M6fz5AoU9SSrbQE+a3VFVVYffHkRlV8yqLeTzdG7oO3UyCqS5QIyH04GK0Mbud13+/nbl2NfiTokIz1eRnvhuZ7UHqZcvRjcRyCe4YQI1pLxqLoJLQg5LFUKGP0HLZvqab2uYUVbXxEW1/8EHu9/jcs88+e8hjleNwj88tt1jK8fWvf52vf/3rQz53oONz7wIu3N0GQggduBX4/RiMabfoy6gvapEEphBUuyfTWzOdxnd/DZQmRqXlDUnoxWIRy7L413/9V7VEVucaCn4XZaLtTcxAoWsCekpNDnZHHs9vVvJcAePmYHsuUkLc0CA9HjepCNDwjJEp9MBuqZuqiLrcO3c86N0Ga//gv/EdeDKOLGaUsge8YpFcIklW0wcr9LAWfUdI6Ol0GkvEwW8ykkVrmNb/fMmvhhESuroYrctt46WXXqLPziCFW/LQPQv+9wbkaz/DK7dcRlTlkgWfgDESI05bDLzfoRR6tanWbB0pof/uR8t566mte97wYMMeyhYPNKL43ME4oPG5UspngT0t+/PXwENA2x6222d0b1dX7QJxElKjJf+nbJ38R8R7tlBDhrYXf86md95kQ89WMqKAKXXiMaWq4vE4xWKRrq4uisUiW7duhfZ3KaCeT2x/iVhQTqcJVbr40o8o3n8Lu/5lKXqdup2TroBxsygG+1U3gBDIhFKRSZHcO4U+fh7kOpF26fZfuhL+79vw8z8Du4DX28mO4j3kvfcp+6VnC3LDK1imiYUAzx5suQD0b8dy1IWoqqpKeejBInS2M2hSVFW55Cotl5EEdPmEXvQJcrPWgcRl27YdeJ6mLJctSyA3UKGPxHLJlSn05JCE3t/fH9oLoEg8WAKsXK2HCj02cg9dSolddLGLh15MQFi2eJAQOkTxuQNxUMXnCiEmA5cBd4xg288JIV4TQrzW3t6+p82HRH2n+kJaxKmXJrpM4Gkm8tS/Y1xtkvW5Ku79xUP8z47n2a51k5aJsKQu6OjctUvZFh0dHT6hK+JK2N2YPtm4Zgy61uM8fQ+db85VhCUUYUoPaD42VPbxWmXLuAGha8mRKfScr9DHH6eOW9YAJC0b1jyhUhQ7VuP1Z5BU4coJitCfvBHvV3+FZZiElDRwUhR8ha7efzqdVnXojco5k9IIJ0U1TUMIMYxCL1BY14PbO3QNP5Qmiov++96sdeDisG37Tvr7cnhODno2IT0trEHXRHyElot/gYEhyxa7urr4/ve/z4YNG8LHLMsKCX0oy2VvFLr0JEhwR7M04HuNg4/PI+xHjMWk6A+Ar8gRfDOllD+RUp4opTxxYC3qSLHwmCaElBSJ0+ipKQBPi+G1nkPzsWeQoYpq2UdcCnq0LGmZCOu6A0LfsUP50R0dHci2dyikFPnFpYMp/IaURBpWPkxf/4VIYmhxD+lXpktPQPNsigGh16t2ZC/uXxiIj6zKJVToitApJ/Ttb0HevzHasQzpV9h4MqEIfceb2P3deLqOFZSVVSj0Uvu/5XrowiORSGDpKeSiz6pjYSClDCdEdV2vnBT1CV0W8nTcuYL+Fypr4MsRWC6WT5A7tG5cHKQUZDIFnHyP2g4zLFnUtaqw+qUC/Tvhl5+EnP/+rWyJ0M3UIIXe3t6OlLIiD8O2baqqqsKfAwz00Edy4Q2I3BtNxs57jPCm5WDxXCLsV4wFoZ8IPCCE2AhcAfxYCPHhMTjukDDqEiRcKHgpGnyCdTUTWbSYMWMGTU1NXDnL4kwUoVXJRBgDEHRm7digJngKhQLZ9o0UEuPRNUFH8Q6EppppvFgKCj14WhOGth1d74WQ0DWobw0tl3iTmvl3Eik8POLEFFE4Fvzmr+DhL8CTN8H9H4M/fLP0ZrIdEK+BuinquOULOK97AYSuasvXLUb6ryVJQOda6FpPQarHbM2fPC0ndCOubJfuDViOJKZJTNPEtm08/1iub70EdkuJ0HMVCt3qEOBKZFHZI5s3b+Z3v/sdUkqklDz7wOqwkasobepqavGEBOExZUorrifI5HqDgYVNRbpWNbTl8u5jsOphFXXgFNX7rferK8zBCj0g8vKJsD0RelDlMhLLJSBydzQpmAcJIj4/MrDPhC6lnC6lbJVStgK/Aj4vpXx4X487HPRqk6QrKcoU1f6NpKebSMti5syZXHvttTR97MccVXs8p9uzONZtQXarCZiEn8G9c1epUqSjq48udzwJN47HODTdV/2+7+4lJ6GlkmB1IXSfVKUO8RqKmiKFePNMACwziaM5xDy/ymXbUnjz54qYXvw3Ffj1wg9LyjPbDlVNkFZJkLKsASjz3PPIKafAuNmw7qkSoWtpWPd/gKQg/UhcX2GjDyhaajoaOlZje5KYBrGY2j5Y5ML17zACha5pWqXlYgSE7k+i+tbNypUree211ygWi9hFl7ee3houKFLEZsaU6SSkiSYkU6e0kkikyVk2XqoZSSycFNVFamhC3/6G+n/dYnXO7BzM+GP12BBliz09PUAloQ9nuQR3TntT5eIG66COJjTtvUbE5GMOx3bJZw7OyIg9EroQ4n7gJWCWEGKrEOIzQohrhBDX7P/hDTEeXSMpwSKB7t+6e5qJO6C+XFoex3otNMg07FSKPLHql4DqMp3oz9+2UceGfskkGjCNLei6si+KmsnjnIVrNiKq6xBOH8JXwJ6ngRAUEso2SjSpCR7bTOIKVxG6Z8PmF9Vg/uYN+EYHfPyXIF1FVOAT+rhSaWRnKT+m/SWbvL4QmudAoQfpk7c0amGrqnnNU1LoUlKp0MEn9DVYriCmlxF6MZj4Vb8PrdBTypMXGlZXyXqBEoHmcrmQ5ISnOkAt6ZAwE5xvzUdoHppmUFvbiBQe3eNORsbqwklRXQyj0ANCX/+0mkfQDGg9Qz1mJgZluQwkdM/zcBwn7LwbalJ0bzpFPV+Zu4ew5SKl3K/xubZt88lPfpJ58+YxZ84cbrnllmGPfajH537h81+gv3PoXogbbriB2bNnM3/+fC677LLwswlwyy23MHPmTGbNmsXvf18qCDyg8blSyo9JKSdKKU0pZYuU8r+klHdIKQdNgkopP7U/a9ADJBFYMokWTGBqJjc++AYvry+F20jbRUv6FknbaujeSHzlL8Lnp9WbmNgsZw4Fz2FqvBljxgw0n9z6pMnLnEC7ZyPqx4FXBCOG0IWyXIBiXK1xGfe9ecuI4woXwxNKCW5+GZpmQVWjyleZfIKKCFj9uBpEtlMRum5CqhGZLfujagbeuBNhvFqYI1Donl4LSEg2UIyr3AfbMNRE7SBCPwaKfViuR8wQmGbluqIDFXqlh570OzNTWL2K/OQOFX4WfEiz2WyJ5CRYOCAgYcRoln7qnNCJGXGE8MjWzkKaNWFjkU4Kb2Bjj12AtlXQcBQUeuD1e2DKqRBXk5gYSVXRU7YwxUBCdxx1zFgsFtpMAQY2Fu2VQj8UJ0UDSPZrfO6DDz5IsVjkrbfeYunSpfzHf/zHkBeMwyE+t/wiORDnn38+K1asYPny5RxzzDHhhW3VqlU88MADrFy5kscff5zPf/7zYWjcER2fC5ASGhYJhG4h8ZTSLBRZ357l1KMUyUnLQ6+J4eVc5K61sPhmEpoDPg80nHYlTa+/ztadiuSmJJrR6hvR+tQGlu/Tdti9TKlqxTMMhB5HT5S4pHj0B2DJ8tCbt41YSOie5WFtfo3YvEtLA9d0OOYCeOd/VPZKth1aTlTPpScge8r+HJqBp1VBs0/omrIPpFBExIR5FPLB6xqqlNL3vLdu3YqUkimNvhVEjJihhwrdsiwSgOvPCeiauitJJBIU8nlV0+5PQrraBNyi/9rZPqTnhQT6wpL/pHbLcwi+jgCsIMsmn0cKNRYhdUzPQdNcsulpVJkxPF1NSg9puexaqSp73ve38OjfQbEPZpxTer682SmuzsVAQg8U+VCEPkihj8RDH2OFvnr1d+jPvL3nDfcC1ek5HHPMNwY9vifHZazic4UQZLNZHMchn88Ti8UqomQDHFbxuRIYEHNTPp5TTz01vMv57W9/y0c/+lHi8TjTp09n5syZLFmyhNNOO+3Ijs8FSOoaReJoukVvog1PNzFdh5ylyEFKibQ9RMr3frevgLd+SfzUq8Nj1NfX0+RX2jTH6kklUmgpAw11DNu/re90+hAxDarqQY+hm25Y0VHUqzBNE03T2Nqd476lW3GFg+4KFm0+gdutP2FreiGu65YiB465QCnPzS+pssUqv9qncQYyVk+/VsDBRWgGXjZXIvSEsmUComTCPApJdYfg6IZqdppyCsuWLePOO+/kF7/4BV6jSsizMDENrUyh+3c2nvo0aoUeQH1os/7iF+GEqFSvL8ghbUlhxzthHs7iLa/xK1MLP0RW3O8WXdIGmvpZvPME5uYX0YRHJjERaaSRmjoXuhzCctmuOn6ZeR5MXOD/XGq6cIwEb8Vi4cRoPp8Pz21A6AGBm6ZJLBbbPaEf9gq91Pq/P+Nzr7jiCqqqqpg4cSJTp07l+uuvp6FhcELnYRGfuxuFXo4777wzTNbctm0bU6ZMCZ9raWkJm6uO6PhcgJSh0e7E0QyL9qotNGTnE/Mcsn7jRzB5pyUN/3cHqhsxzrwO45Uf4jgOdXV1eCm13WS9ERHT0ZImmqYIRvhqs1P2QUzjUdnJlKTGMaaNdDSklKUsdGDl9j7aMjk8TeLlE1S7Jlkc/uvZzYjnbg7XNT379JMYp5nwxNdVQXtA6B/+d9zud/j1zsdIewnOTsRV1EBtC8RrkDFF3hJfoU6YTzG2HICiGUPWz2b1jj4efvhhampq6OvrY1s/TDGSWI5JzCc3ANt26Baltmp9x+vA+6mqqqK7y6+N9wm96M4EbGL6ejwvRs87pTS7ooxRSKQJqiZtmQEBmleNFP5tzLY3iU2ahtB2kvViSF0HTZVnatvfQTYU4H+uhwtuVpU525epc1IzGeb9qSLuCQvC1/y/3GaunzyB3/duZFJVU5jdE4/HhyR00zSH9tD3wnIZa4U+lJLeXygvW9yf8blLlixB13W2b99Od3c3Z555Juedd96gXJfDKT53d3x+8803YxgGV155pb/t4I3LUyyP2PhcgCpTp0Ac3bDoi3fhaQMU+gBCBwPO+iokasJa9Lq6OnJJpcInUo8wNbSUgdAUEWmaS11dHV0iQ6fdx2ann+Wx7YiYp67QjlOx/FzR8UA4CKkhXaWE/yL1B0477TROP/10TjnlFNasWcP9Dz0CH/gX6FKTQqT9D3c8TY+Tx8alW8vy++OnkM30Kx/7uA8jG+ao9+aXKjL5BAqGuqUtxON4k05l3bp1mKbJ5z73OTRN451334WmmViYxEwjJPT+QobfxJawQleTsNqGp8Fz8TrXk+31K3BiyrN23AkYYhtabS1Sq6Jn4/Lw7+DKJFnHLSl0R10M4jIBfvKkmPtxjFkXoWke2WwWtCRSz4OnoWX6kALkqz+Fx/9eHWT76zDpePW+T78WvvCKmn/w0eH/3FZQ4wzslokTJ4bJe3uyXDShEdNiaEIbIaEfwgp9DBqLRhKf+/Of/5wLL7wQ0zRpbm7mfe97XxhYVY4jIT737rvv5ne/+x333XdfeO5aWlrYsqVU9LB161YmTZoU/n7ExucCpGIGRRGDpIOjeSA0Yp5LNiR0n5QDhX7+LXCyaq9NJBJUV1djmiaySfLE5Cdo8tK+QjdCha5pDvPnzMUSDsv9Kpl+rUBbk19iaFkVCr1guyBc0kV1he2Kd1E/cwHvf//7Oe+887jwwgs566yz6OrqIjvrT+CvX4eL/hlmlVRHt6XsjkX2UeTiBjv6ffvj0n9DTlM+skcC/upFaDqafsNPDDQM5IQTQ5WTTqdpbW3l3XffhcajfUKPhZbL9mwbnpDs1HrUe813wEOfYcL232NJA/uPvgazL1HvkwQaeUR1PdKooWenqkKIUcT04hQtK/wQFVHqNy6NkkKvm4nQYspDz2aQIo7U8wjPRDT6dtLp18Jr/wU/OlVNiE49bdi/fX/tZOJOnF5TnfegOmDixIk4joNt24MU+sBJ0bgeRwiBqZkj8tADZX4oVrmE2M/xuVOnTmXx4sVIKclms7z88sthdGw5Dof43NJNz+CT+vjjj3PrrbfyyCOPhGWzoC5KDzzwAMVikQ0bNrBmzRpOPvnk8DhHbHwuQCphUMRE14s4vhKMebJkuVgDLJf6mQS+QFII6pPqRPdavfTH+sGSaDEdLWWAT+i67jF9cisAK7a/S6OexJQ6a8YfA4BbLLJr165wAkkpdBfNUxON25M7sM6tnOQIrsg7duxQyvyUz5Xa64EeWxH4Ud54APrKstuDuw5peWFnaa/mNwhpGoXUVHbt2sX48WrfWbNm0dHRQXtqppoUjcdChb4j3+Hvr74MeqIWVv6Gbai7hewJnwsnHNukZIfWj6gZh9RS9NgGMWyq6SHuxtGkgRZYLlV+9AFmqNCRGppQF5Jsth8pNaRuoXkxqJmuNjnnH5Rn7hbVRe60ylXVLdcKlXTP2h4u3nIx27Yr/7GnpwfTNEO/Np/P75bQi26RmF8NZGpmhULvzHeSG2J5O+8Q9tDD+NxhNPpYxed+4QtfIJPJMHfuXE466SQ+/elPDzlJeTjE597/wM9YeOqcIeNzr732Wvr7+zn//PNZuHAh11yjqruPO+44PvKRj3Dsscdy4YUX8qMf/SgsFz6g8bkHI9JJk4JmotGP7V+TTCRZv5NRWpUKnbKGkBOXvIoWUwTTU+wB1EJDIqahpUyEHih0l51L1Zfb9TxmJGrpKWqsq7c5zniD9l1tZDIZpk9XpFS0XYRwENIALNoT7VjBij8+Jk5U3avbt2+nZdp0/uHXb/HhqRYdO7byoQ99iB6nn5SWoEYm0T1Jn1WWShgSuouUEiEEPVK9dyk01u5qI5/Ph4Q+e/ZsHnvsMZb31wHtxGKJkNC7/QtHAO34j0P/NO5efjanaOvJZrPKburq4rdsIW5IPpOuQ0qLnupZ1FkSEo3E8n3onlFS6KkaRHE7CaGHi30IT/MXioZcrg8cjw2xPEnPY0P7NsxGkELCVUPHjgJ8/v8+z7TqaXxl0VcorC6gobF12VY4RRF6XV1dqIby+XyF5RKLxUKfHXyF7l8IY3qsgtA/+8RnOWXiKXz15EqF5h7Cdegh5NBxtGMVn5tOp3nwwQf3OIzDIT63e2cWu+hSP0F9v8vjc3e3iPTXvva1IStZDnR87kGHlKnjCB1Pc5FFteBFXO8jZw0zKVr2RUx3dFDVpjJUeou9IEF3tNBywa+RFsJjw6ttVHtKQbdqCY5xJ+IIjS1TprBhs7IegkmfwHKRXhXxfDNFMXhF+UQiQUNDA28tWcPzizex7a0XWfz7/2X58uXs2LGDHjdLfawagaDK8uh3y9IXfRuphyyP/e9jOI5Dr1d6X8u3q1LA5mZVDVNbW8u0adN4baNa4SnWOCW0XAAMWcpa12eejbz8v+hwFNFls1ksy+IXv/gFFi79wiMvbKQj6UlNp27aXGiaRNyLo8sSoVvCIYZBTIiS5eJqCH9pvHy+n6JjYZHD8ww2d6uO3T0lLq7tXsvGvo0sWbIELNie2k5uR45NmzbR0dFBXV1d6D8OpdAHTooGCt3QSksFSinZ0r+Frf2DI3JDhX4IEnqpZvq9HUeAwyk+d09VLiPFAY3PPRiR8ifGiiQwpJq8i5ldZPyVeQYq9PKFI7xMBrdPkVxvsRdTGmhSKIWeNEKFDmDoNs2yhrrqWupdyXhZS0M8ydqjZ7Jxyxbq6+upq6tj63XXUbXqTRAOulNLTe9sTDl0QNfEiRPp6mtnw4q3mWO0UT1ZVQ9s3LiRXi9DfVJlt1dZUK5PpO2RpcjjsWUseXUJmzdvpr+sCHad/54ChQ5w8sknky+ocxKrbsQwjLCJaLpbWrhD0zRsV5KXgTWS5c0332TXrl3M19QdSHuxG+m4oSJ2DIe4G0f3dDTfzipKm7g0MAWlSVFPQ/MVcdHK0mn3oWkuSTcVWjG7I3TXc+kudtNf6OeFF16gWF/k1XGvggn//d//TWdnJ62trbsl9IGWS8JQE9nlHnreyVN0i3QXBnfshQr9ELRcDkYc6vG5pcqhsTneQRWf+14gqQeEHiOZVPaBKaHLWwaUFLoYQqF7mQyefwveU+wh7rfUC1NHGBqUEbpp2Jxuz+LPL/0Y2AUEgvkNk+huaGDdtm1Mnz4dL5ul/7HHqXv7DYRwMTzfn3WHJ3RXK9CWfZs+L058xkk0NTXx9ttvU8CmPlmDlC5VNmTKqjtcy+GJ2JsU/LDc7du3kxGl5x0E1dXVFRMxs2fPDps7ArslUOmTZQMpv2JG13XytktBqvOVzWZpb28nFoux0FOE3pbvwsKhWCxSV1eHpVsY0kD3zJJClzYxDMxyhe4JNBF0pLrscLrQdBfdS4QRtrtbhq672I0nPWSPJJ/P0z2uG0dzyM3IMX/+fD796U9z+umnVxD6nqpchvLQu/yqmeD/cgTK/NBU6LLi/wj7joP5nB6ShJ7SSwo9GVfKVJMmWTYDhCsLhR66r7Ck5+Fls3i5HNK26Sn2kPAUqWn+cm9St0AqxanrNnFMahtqw+Cs2fWTMWwbT0qOOuooPL8SRctlQTgYfsmi6caHLIkLfHTby7DSnUB/waW1tTW8BW1I1oLnkHYEeV0PyWhHpoNOrZ/T7VnU19axbds2snrJNnE1LbRbAui6zoknqk7UgNCD/xvNWho9RaiaplGwXRx0XDQymQwdHR00NTURszVq42naMp30CjWnUFdXR15T5yPhxsNJ0aJnEZcmpiD00HE1dF2Rra657HS70DQX00uQ92Nwnd2sEdqZV80WZr86rx1xNaHbVtfGn/zJnzBt2jSEEEMqdMMwwsai4MtXdIvE/ZA1Uy8ReqDMg3mVcgTK/JBU6GOsJiNwUGfMH+KEHqfeJ3TdTWBrqost9NCDTtHAA82VKhjc/n76in0kfEUtYuqYnm6je2qyw/DVuojpeEXVDBM3ErRu3IgQgtbWVtyA0PM5EC56SOiJIbO2m5uUJSIwWOc20leww4lVgPoqRehVjiLrYEJvc3YHQsI0r4mJjRPYunUrubJZcVfTKuyWACeddBKnnXZa2KUWi8XQ0KiP19Dk21W6rqs5ANRdTzabpbOzk8aGRnAlzekm2jKdrNV3ous6ra2tZIU6H2mtKjR+Cq7lK3QgJoOBoesp/3VsdsluTF0ipAk+57e3l9IvByIg9HQuTUNDA32yZJeVIxaLoWlaSOiBvRTckQQkb7nWkAq9u6gIPWNnBt1ZHcoKPcLYY6wtl7HEoUnovhVhuVWMiytCNWQS1/An2YKyxYQOomS5eGWz5vmudgpuoYzQfYUuLHRXEXqQ5ijiemk1IWEw/83lfPykk0in0+Ex9XxOWS4+oceGsFz6rD56rF5ihQbS7lE46PTlnbAUTJOC2lQN0rVJlxF6R8dT5MY9zMxJGzEMi4kNzfT39+OUKXRPaBXBRQGSySQXXHBBWC9vmib1Io2ZjDHZrcfQddLpNHmf0AsY9PT00NvbS2O9KgUcX9tET66PNfoOZs+YRSqVolcqQq0SVaUqF9ciLg00IQj6n4RXInRNdygKB9OQ4BmYfpHVzl2llu0dO35DPl+aMOsodICEhkID4yeNJ2Op8z1QSQcqPbBcBlpMAaFn7AxJ/46h3EMvt1oGHjto/Zey1DV6qOBgmxQ9PBBZLmOKwEO3nQYaEkqxGTKGMNvJ21Y4KSpMDXQtnBQtJ/TeDkUaTYbfamtqSOkhNRvN8QndsFT+jqEhC8G+OqbjMCGRrDimUcgpy8VfRcl0E4OaVr7/2ve5fvFXqO2ZS7KgqnN68zbpdJpx48ZRLZNomgDXJu35pZU9PaxZexuNLa8y4ejn6Jv4MhOCJe9EidDPTaWYM2dOxet993erKhIoAc444wwWMQOR0Jkg6/m7D/0l1dXV5P1zlpdmmInRUKtq7MfXq/p0W7gcP0fVFne5igATUlkuEknRLhILFqA2AoUuyiyXoMbfBWli+O+xzSd0z7NY9fb17NhRCuzszHeSclIkvAR14+vI2D6hF3oGfaECQrdtOyTyckK3PZuNvRuZXqvuiGJ6LLyLKp8MHTgxWr6wxaFnu5QYfX/G51qWxac//WnmzZvHggULhq01h0M/PvcrX/+SenCIj8Jw8bnl+197bWWfxQGNzz0YEVgujlNPja/QTRFHaC5ruzYry0UTCF1DGAKGUOiZrl20mB6Xt76KnWjH0m08T1WE6JZvEWg26AKhCbycv29Q+x0sEuFbLmY+B7ghSZlufJDlsqlvEx39ygMObKG+giL9C8+/gFOdo8FzkJ5DSsYRUtLb20ux2Et7u6oK8Iw8zVUNav3PsknThOuFFSyg1MN/vbCBJ1ZW2hlz585lmjsOLaEuPH6GFgV/PFlPD2M9G9J1AIxv9EshvRRTmlRzVIfrt/ljsj21hp2iB9fziPsTqzJI8i2zXAzTv3PSPKRnoPtVNe0daoyuq7x028mwbds2nnvuObav2E5TQeXY6PU6EkljohFHOmTt0pJ9MDShl/JrbDb1bsL2bI5pUM1hFZZLOaEXK79c5QtbHGq2iyzze/dnfO5Pf/pTAN566y2efPJJvvSlL6kFxwfgcIjPZTd3PcPF51bsPwBRfG6g0KkPJ0V1vwTu3a61TLGPDj1xYWjIoOwsUyKAXFcbUxMupmaTbVyJyfGkfPtFKwQKXQVxAXi5oBnHt2b8xEKvXxF9rJjHlKU6b9MbbLl05Duw7aBWXkIC+vKKUKZPbSXu7UA6NngOrmmQzOXo6e6mpi6LZ9eC1PD0Ioan/HK3rMrFciorRYqOh5TQV8hyx5t38IljP0HKj8SVjqfsKEoXlsBDz5e9h/qqWrrZQjqd5rjW2TSvNsCVuJ5Lu9WuokMLBTqSWZ7zFAnG/I+Up/tfZkeEhJ7y8+mFZuN5Orp/8evt6WTDhg3U1ys3/rXXXmTN6tLdzfHieBzhkImpc91S3UJnoZOeYk8YsgWKsPr6+nAcp8JiAkXoq/tXA3BMfRmhD2G57Fahj8GqRd9Ys5UVmbFtfJmbTvKdo1sGP7EHv3es4nNXrVoV1lI3NzdTV1fHa6+9Fra3Bzic4nOHslyGi88dMn7XxxEfnxt46I5ejxFTXq7wiWRdzzqk5SFMnzx0DelIntj4BD98rnQFL3R3UKurP0i+bg19sh/XUwpRs1P+vg6ev4KRl8uodEQ/cjZQ6F7WJ3QrjylLp3OoKpe2XFuo4IUrQUJfQRFxNrgDcC3wHBxTJ5XLsXnTZjwvT9KtQZNxpF5EFl1mzpyJ4ZYWeSg6lWt0B01WGwov8KNlP+L/Nv+fGrcnwZOIRFCjr8hKeeil0sWamprQ4xYxnUvPvogZ3nik7dFT7EEKiR7XkZ6L7un0+VUvMf+CIIP43DKFnogLlDlTwHUNdN+eqqur4Ze//CUPPngfAOPG1XD55Zdz/fXX0zO9B13qdMW72JFXzVMt1Yq4BnrdyWSS9vZ2tmzZwuzZs9mR2RFcf7Esi3e738XQjNByGTgpOqFK5fQMLF2sUOiHmoce/i/3a3zuggUL+O1vf4vjOGzYsIGlS5dWhFEF2F187mOPPcZ5Z19IMVf63lz+4SsOqvjcChLfw7W9PD53dzji43MDD90x60DLIISDlBqeXcPGvo14tosWKnSBdDz+b/P/kW9fHx6j2NNF7bSA0Nfiyn48V9Vs63YwKWoh/Zo8L58D4SGHsVwSxTyGLEVfDpwUzdpZck6OGm9C+JiJUuhSSp654VMsHPcl1nS8zTjXwU2YVGWybOrrRtddJtrNFOQ6PM3Csz3OPfdc/uMHP4UpMwCwBhB6MMm5y30dBCzdtZQPzvgg6zrWkoAyha7OQcF2SbX+O07vHMjX0NTUFJZ/ClNTNfooRR8QXjwZJ1fIcUxmHpuqV5ETFvFAoQdejit4ccdS9X5jHnG/6ch19dByOfe8c3jg/tfp71cf6IkTGsMgpk11m6ibVcc72XdozKjz25IentBd16WqqooTTjqB8359Hh+b8TGuvPJKmpubWb12NTNqZ2D6naumMIhJdSHqLnTTWtPKruyuwZOiY6zQh1TS+wtlnsv+jM+9+uqrefvttznxxBOZNm0ap59++pDZJHuKz330l1/BsTzifjvFtIlHH7zxubth9IHxuXvCER2fG3ro8ToQkqpEH1LqeFYzTnsf1oa+cHELdA1cj9Xdq0mWsq5wentDhW5X7aLX3lry0H1C13Q7EOTIrE/oQb+MH5y1ZsubABieQ9IuV+iJCoXenmv3tytZGjEJjifJ2y7p7erC8OzGP4DnoMeTNHZ0kq5SxJuyq3ELJp5eDCd9bd1A88mm4DhIKXlx+4v81R/+iu8t/Q4Imz5WAorQPelx/WI1oTNQoW/PbkFPbsWKqXE2NjaWyj9juppgRtk1AaFPnjGZ2tQkatw65jmqUicpg7wY37ZwBL9a+xtcCVU1BrOE+sBajhaei+rqFJ/97Gf5kz/5IACuV7IjugpdTGiZQMbMKMVNSaEPtEaCWvQzzjiDnYWdZOwMr3W9xtFHH00qlWJ112pmNcwKt2/Wuvhs9RoKhR10FbpoTDZSG68ddNxDVaGPVRXGSOJzDcMI0wt/+9vf0tPTE14EyrG7+Nxj5xzLrd//x9K4pboeHUzxuRWndJiPwlDxuXvCWMXnHpIKPSYEugAnXgMOVKf68NCY0X8MX956HjLlUfcBNekiDIFru2zo3cACXzDrTU3Ivn7qDYEh63FEN9n8ClxPxX0GhC50G1cIpGXh5XIIXYZL2EnL5r6376N/0ysEgaPpYul0lneKSumxs0cRv15G6KZUFkRPziKRV5+OGhLgOZhmiqPXrqXrM2pMmhtHOjE8o4i0PNq7t2EbJglbktMh5xR5fOPjfPnZL5M0kuSdPPHmTqSwOHnCySzZuYQ/bPoDXVmlgrV4pYf+bp9KiyvGFJk1NTVVVAuVK/Rtq7v54zV/zimXnsKrm7eiAXPcKVS/bzYNz6p5irbCLuoAy3J5YduLXDARqqo8jmEiGwDH1Un6tY3Ss2lqakLTVUu+6/oNR55Dd6GbluoWDM1ge1bdUgcKfWAt+owZM2hra+PEE09k8Ta1EPeKjhUU3SI5O0dbvi30zwGqKKIJKFptdBe6qY/XU5+o3+8e+oGGEGJIci+Pzz3zzDP3GJ87Y8aMYeNzc7kcUkqqqqp48sknMQyDY489dtB2QXzuwAnZZDLJ9/75+xx/wgL+/u//gXS9mnyXUvLpT3+a2tpa5s2bV1E9s3jxYk499VRSqdSo43P3HnKIn0oI4nOfeeaZiq7t3R7xSI/PFUKQ0jRsf+HgVKoXT4txQWYeQgq8T08gPk3ZJ8LQyBYyuNIlVZTYcQOjvg7Zn6FWl9S6p4Br4BVW4/lVFkHZoiJ0cIKVuw0RKvQ7n3qXh1Y/xARK6yamLd9z1iqrXNrbnyCz7npqNBmWNUKp92ZrbzvpoiLYSxvORHo2pj+B+crGJ9Ux3QTSjeEZqizzxfVPYZkmcX8uNOc6vLj9RRoSDTz1kadoTkwm1vAieDGuWaAiPL/32vcwfY9cxRyIsIt2XUYReia5g2MXnc7cuXNLEQqmFs5JSMeja63FMR0nUqvXYxBDAzQE9enxeP57Ct776rbV2J5N0RNkir14ujrHjmuQQL3Hok/gwfn33JINIpE0JZqoidWwI6sU+sT0RDShDbJGWlpa+NM//VNM02Rdj8rvtj2bVZ2rWN1dOSEKEPO7WfPFbnJOjoZEA/Xx+iGqXMqiIw4pha7+F7v5lo9VfG5bWxsnnHACc+bM4dZbb+Xee+8dcrvdxedOGD+BD196BT/9z8r15w+m+Nzrr7+eB371cxaeOoe33xl5fG6w/xe/+EXuuusuWlpawvjdIz4+F5SPbvukl0r1k9VNjrebWVG1FqNYoIVWtaGuugdJQYOXpBC3qampRc92YGgecWsCZmEaprkZz58U1e2gEcbGleB299BbM51qQ0faHp5ukM3m2Ny/hUY3DSilmLKU+k6kTU6VE9DfzcNcKBS2I/Co1iVJUarKiKEU+uZda5nn56g7u3aC52IaCfKAYStrRyn0OF68SEdPO/+19MdYseuJ+R54VsZ4u3M5cxrnUGVW8aGpf8lPV98I+VksbF5I0kiyI7uDFm88Eo938zdRU38GaXsiBafA9sIKpGcidIvxc2ZRVVVFxvYnnGM6wp8clrZHJpfFJE2VSGNIE01YeFJSLLikUPOQQZZLfz5HurYJS25BWv14hl+a6GkkSVEAspZ6ncBqCf7v8HPbG5ON1MRqQqunJlZDTaxmyDb9AOt61oXk/EbbG+h+zX45oZs+ofcWVNlkfUIp9E19myqOVa7KDymF7jO6uu2X9PX2DdpkrOJzwwVV9oDdxedKKbnlW/9Mokp9j7aub8MqOEgZLmfwnsfnurZH53ZVwBCMc6TxucPV/R/x8bmgfPSif8ueTmYwYilaSbKiaj3L2pYB6gMidEGxmCdpJJmiNZExXfTaGnRdxQAYdgN6fwtJrzOsctG1GpACodm4gNvTw5vz/oqcpSEtD1dXk2nNWpZYvYUTV9fFlKX840R1jFlaDRM2+8u4OeqLVGuYNMdK7flJ/1Pavn0d6OoY9o6t4DkIn4BSPn9oThzpxvG0Im9uf4MmrQbLjJHwCb2q5VyS2wTHNqjb3JlVp1Bsu5BC+9kYwmDBuAUAnDHhfbixDN3OH8g1rkK6ktd2vYaLhdOnyr52Zio7bkWsTKHbHj1Z9X5cW4bxuR5QzDmhQveE+sH0TCYYJ2N5Bq6bwzMCO0UnLpVnmLHU8QJlHtSjdxaUPdSUVAo9QJVZRV28bo+EvqB5AdNqpvHy9pe5/537mVU/i8ZkadLJ8Am9v6DmDeoT9dTF6wZ76GWq/FCrQwfClekPhsbG3cXnel5lB2bJSz8IBu6jfCJ0qGE5touV330c9EAc8fG5oEoX8xJ0UY1M9NDSpG4FN9dZIaGf+/+eYWtfAdu2OKb+GGodk2zMw66KY8T8iNViPVi16LhYRfXFjtVVg2eCbtNn5Xhi2a9wzCocoSEtF0c3iJHhw/U2hXM6ccbVAZCw/QCsKoMEGvGcT9KOUqDNiTTVeg3x2q3o8T6aEv4an7s2ITR/221bkJ6D9APCavzHNTeB58Rw9QJxL8ZtJ38Xy4yR9BWjo+tMKo7jWH9Zt4LjYXWejZ2fTNHxOG/qeUxOT+a8yeeGtodnFrAti7tW3IWGid17PAC7cgGh+x66oYMRKHSXTFZdDB3LRTr4naJg5Zxwnsjzf2pJTKHROZ+ia4IshK9tezox/4Kc9Qk9IHJvoEJPNFLt22tVZhWa0HZL6LZrs6lvEzPrZrJw3EJe2vES2zLb+MrJX6nYzvQnRLJF9ToNiQYaEg30FHvw5NC+ubsPlsuBbhUPLZcRTswdKAwXnxuc8oE8fhDxeaVxPsTAcr0WfZ3Dh80NheHic0fzedkjoQsh7hRCtAkhVgzz/IeEEMuFEMuEEK8JIc7Y61GMAildI+d6pKqmUUhvY3xNE1npkknXs6ZnDV35PtZ3ZOm1HVzbZVb9LKosQS4u6I97mAn1ZdaL9eDUApDLbQDAqKtGc03QLXqsDC+segoAF4G0PRzdJEaWGk3i1ToIP+UwIPR4QmWEJwvqlixQ6OPiVaRFDS1/9AOajv0d9TFF1sWuHSD8cr9cBqGJcAb9A1PVWqKaG8dzY0ityASnhrQ0sQyTSf52liaocatCQg/q0AH6Cw5/NvvPePzyx2mOjQtVsmvkeWnzi7y661Vmm5/As1RHZodvQUjbU52yulCkYGj05XrBUQThWJ5axUfz8CQU8yWFHuShT4hPpC9bRdGNoWGHloskFgaZ5fx2/sDyCiZFg2CuwHLRPJ0qQ81v1MXr6Cn0DPnZ2Ny/GUc6zKibwfHN6iJ1YeuFnDThpIrtDJ/QM0X1OvVxpdBd6dJvlVZ18lwvvOX3Rmm5JBIJOjs735P8j8BDPxizR8ohQ4Xu/34QxtRWlKEPMSzpyTEZr5SSzs7OcBH6kWIkHvpdwO3AcGEI/wc8IqWUQoj5wC+BwavDjjECQv9vPsn4usf5jHBZ5xWoEjPxpMcr294AIOsVSHmCWQ2ziBdeJh+DDqNATZU66UauHjyf0PMb1WN1NWi2idRsCo5DOh8DDWwpkJaLrRuYMk9al3hp0CeNh9dXEfdX/En4FSEx2+CXL25keqIHgPpYArQURqIPI9lLremr3u520PySJc/1J1/V+FL+NVe4cTwnjtQtmttc8qtWYaenUOcTelFIJtLAxCoVzxt0fgJkig7jqtXY6oxa2n1StbQM+WKW75/1fX79fD0xtiOloLPQjufZ5J2NiFjpAyVMja5MV5j5blsunivRNOlbLnao0MMYAhs6CkWK4+KkhBsqdF2vQrhqm7y/JJ4bWi55pJSs711PdayalJmiRtTxyddu5u35qkGqtbaV57c9z7td71aUIgKs7VE+5ozaGYyvGs9ru17jukXXDfoMmUFTlW+xBB46qAnZ2rj6XLiOxIzrWAV31Aq9paWFrVu30t7ePqr9RwPP9cj2WBgxDcfyaO+PoekH7015MWdj5V10Q5DqipPpLiI9SVt/DP0gGbdre+T61IS/bmqkumIVz+f6LFzHoyOzd0Q8FBKJBC0te9ezsEdCl1I+K4Ro3c3z5QvrVHGAQiWTusbz3Rle4ygatI/wsfQWNvVWEXemIxC8vusN4Gj6ZSeTZIwF4+YicgXscQZPdr3Eh+skkjiaFcc0xlEANnQsoUZANiERRRNPs3E9QXUxCUlVM+7ZHpZmEBNZkv5nTJuqSMB0Y3hCYpadgn99ZBVfu7CDOFBrxHB0gRASPZZhh/sIqdqp6Ju7EbrvEXuOmoD0Cd1xVBmg5iawXQF6EWEkyL/xMtYfH0XcA8OVFISgRZsY3l6XK/Rs0SHXZ9G1I0sjcTzd97G1HAninDP1HO6zl1KXSpBxqukutrFr16OsSn2VGckfsrF3I621rQhTozfbQ8zPkHeKLq7joevqOlTMOcGwMbSgzFHQnilSdBLo8R48I4+UYOpphKM+fnn/PQZzGODRV+ziyU1PcvF01UxSYzegu0nqC2oO4jNzP8Mj6x7hxhdv5L6L78PQDHqLvbzV8RbL2pahCY3ptdNJGAluOfOWIT9D8aIHurorMoRBTawmJPRyO8dzvZDQR6vQTdOsiEk+EOjakeX+219hxgnNrHu9kz/7+sk0taT3vON7hKfufZtVL3TQNCXNn31tIXfe8Bz5fps//fsTaZ5Ws+cDHABsfbebZ372BpomaG6t5vIvL6h4/sFbXqVtUz+f//dz3hOra0wue0KIy4QQ7wD/A1y9m+0+59syr+2rUklpGh4w3tToEk38pqmNt+mmaMc4uv5olrWr7sQMO0gQ55j6Y/CyWVK1TVgpE7dOkjLHIy2X1pp5SKAK5Q1/9c2bEV4MqdtIqTHDbAUga1nYhSJFTRJPlHwytx6KBsTcGLZww2YfgL9d9QS63xCTNjSSfgelFs+guwbxujdIZDK4foiU9BxVUihBJJK4rk/oTpyMZoPmIQ2NwltvYRsGcU9iepKiBs1OacIvb1daLm89vZVHf7hMVen4Ct3Rc9ToNWhCI2+51KdiSKeWXruDYrENhEu7uZpPPv5J8k4eYWhk8v2k/Eodx/JwbQ9dF3hAPlsMJ430kNDV6xedlGrUMgrYUiceTyJ866bgh2wFk6IAv1//CHknz58eozoXq6T6Qic99dp1iTr+4ZR/YFXnKr709Jf45bu/5LLfXsZf/eGv+NnbP2NyenK41Nxw0IO2f3cXDUkVeBYQ+pqeNaW/ryMx/UasffHQDzQ8/+pqxv08ooN87MW8+sw6/mS8YweLcx88lkswKW4m9SHHZRXUe3Dt9+ZcjwmhSyl/I6WcDXwY+M5utvuJlPJEKeWJA9t/9xbNMZMaQ+O3i2ZRI/t4avJkEppHznK4sPVC3uldhln/AgW9m4RQitLLZKg+4c+48Nx/wq2DGHVIy8WIJYnHmlGVeTp6TRXCNZGaBdKkGTXWou1iSJ2ikSORLFt4OJknb+oYXgxbeBhlX5zjs53ELOXRpjRBPIiQjWUwvThu4i3SOQvPb0JoT1dh+1UzWlW1KuGTAuHFyAq/USkmKG7ciG0YmB6Y0qMgoNYuqZj8AIVeyNp4rsQpOKHt4Wo5qjVFkAXHZZzuoBXS9NkdOK5vg7CN855o59drfo0wNfL5HEmpfGzbUgrd1HU8oJCzg76r0HKR/mkq2GlF6HqBogc1ydrQcimECr1E6P+7/mFmN8wO5wRSPpEn3FKzxvunvZ/Pzf8cr+58le+8/B3qEnX84Owf8IWFX+BLJ35pN58ef4z+4DJOJx855iMAHFV7FNNrp/Odl77D95d+H8u1QoUOo/fQ3wsEBG74Wf/eGEX/9uzKseqF7XvecC9h+blGji9GXJ/Y3TJx8l7D9Qk9ljDCn8sRVLgEF6UDjTE1pqSUzwIzhBBNY3ncofDloybw7MlzaE3G+aPi27yVOhqR0MkWXT553CdpiE0iMeFRbOFgSgNZKIDr8sNpc7k93oRXJzGdajzLQ8Q0EnGVsaLrSS5ovRjpKg8dz4DQCfDb5RM2ZqL0B7PNLLmYieHGEZ5NcvNmXH9ipKduIk5aneZEPoup+fECsSw1cjxSK1CTA5FOU9TgU1/+Og/MUhU7IlWtKj68OAJBwZ808uIS21ATinEPYgKKmiBmlRy0ckLPFB2KvX5lSsENJ0U9rUBKJMPtP/PQP/Pp5zrJup04jr9wh97BB1+Fu5bfSY48OBIzsFx8D93UNKSU2HkvnBQNFo727OC2s1Y1apk5LFfjqMajQCqiKThqbEFjEcDm3rVccfQV4W1rwlNEHnNK7dFCCP76+L9m8UcWc+9F9/LAJQ9w7rRzuWbBNZw7dQRlYD6h15pxPnncJwFIGkkeuOQBLj/mcn7xzi9oy7WFHjow5Jf4YEVA4AGhj9XY335xB0/97J1wEnOsEJCha3u4rheWMTrvkdodCoEqjyWMIVW4VfTvMt6ji9A+E7oQYqbwv3VCiBOAGLDvsWF7QJWuMyGuSO2Pslk8odM+0SRbdNA1kzMb/hKAol2rIl/9EK0uM0aH0HBrwbBSSMtFi+nEE4rQNS3OGeP/CM818XQbz9XDD1oR+MmMGJmqasx4UHANRiZD4+yPohGjqpilqrOLrAeea7NtWgrN8JWSU8DwUwk13WWy2Yom49TkJHq6hjXVGtlkkvVpv4PSTOLKAtJWBJp01TJyGDZWTBGb5kriAizhIcpUQc52SccNNOHiZh4is0ZNFNp9+dBywbBIomwJy3ZoatvC7J1ZbJmnYKkmHhnvIm5JjC27WN23hpRIhNUpQZVLoNClC3bDarqmPR4SuvDzbWr9+m831ockQWNVE8K/QFqOOieZYinl8EPTL+RDMz8U/m46Cf//+KDPQlyPE1vdjObqg54LkF26i467V1ZWIAh1cW1NT6iwZ1JmiptOu4lHL3uUluoWPKdMoR9CC1yUCF2r+H1fYRddkCXyGiuUq1u37LN8MF1ESwpdHzQuz5M4xUrb6EBjJGWL9wMvAbOEEFuFEJ8RQlwjhAh6Wi8HVgghlgE/Av5MHuA6o6nyKAxpY9dkyVkuX129lT8YM8lv/1MKuRnkq9ezccsd9F/s0q3pdLhF0MH91XJwJV6un3io0BPESOD6Ct3xoFhUb2dtvc5PZsZ5a+YpiCpFqLG+8TiJTpomnk6DWUfCzqPHUhQ9iWPnKDSXSEbzCkApkz1pWIzTF1Kbg1i6jlU1atv2hG8RxVMUhASfxLrbfVLRi9hJP57AJ3QbB80rlX7lLZdx1XGOrltHnf2vkFYhXcXtbaHlInQrjLs1e3vQPZeWngzCk+zKqG5JJ9UDwMflSTTXjGd+3Xw8v5nJtlzloQsN1/fOC61/oGPmQ2GZn+apvpamtPKmnVgvKaPBz4ZRG1m+d96eK93Gf/LYj1WQbEDkulVZVQDQuS3LUz97hw3LO8LHpOPR9Yt36Xp2K7+9eQndD6+l8HYXbm8poU36d0tpY+gLQXPKXxmqzHI5mMhlTwgsF3OMLRfHv/vb2waaPSEkdNurUOUH0zkPz+kQlotdKJ2PYPxWYWzP0Z4wkiqXwRFnlc/fCtw6ZiMaBVKp+Yxz19DVpOOt7+Wlngw78aB3Ean6TWw+6f9Br6D4AZO80MjLGPE1dVR3T4NGyL32CokTA4WewLFcbNfE1CwsCUU/QbAnrgios+EEMqkMce9JErkZ9I9/h3yxj7m1LSzrexeqWyg4YBo66SAu1wHXyyJFP73UkKCAqfUzJ3kJNdkXFaHXqi9eRzIGSOxYiqKuIdw4EjD8xTA8vYiVqPKPK4lpAgcHgY6bs8GVHN1l0SoN3o35E45+6JbV1ok3VRGo0Gx2dheI9RdI9yoyjLkuE7p1Nna/zcwEOOk+hGlyfn46xrRpOD3FkBjsvhyuK9EkeD6hu9VbkbqNphcR6AgEJjCupg4scOK9pGNT1WpSCDw0bN9q6S20+cFrsqziRUH3a/w1e/BH1vLPSznB9D21hdwbbfAGzHIlUhcIwNqSwahLIG0Xzyd018kOOmY5vDLL5WCfWCzH/rJcQkIfY7Iq+hOK0pMVx36vJhiHQmi5JPVB4womREGdo2xvkXu+9iKX/vVCJs+qXDRkf+HgKO7cR5imQX1nnB36BC6c8GvW54oUNJACxk96Ec1OctzmfyOx4lPhPq0f/x9a/uu/WV6rkX/zdYycUoO6lsDOFcnaJkUvgyXBMtVkY19MEXpPdQNGMo9uV6G1OXh6N8u3v0i1GacxkcDU4hQ8SWdVNXV+V4fRq+OIPFL0cyO38ms+gq71M9OchulJtEQVq2rUtp1JNRbHTGAZGppM4GiQzCoilnoRt17Vp0rXJ3SpvgD9b29mzR++zwXpX/KpTsl5MfW4SCnSsrv6Swpd8zCEw9pdGWr6Sy7ZtI444xJ+bEG6n8QJx5Nf/hbC1MLuUYD81h24jodArfshdAtZpZqShNFLsLrEuIRJjb+ykDQKpPRG/BloQMf1LF7c9iKWk0Xq6kLlubmKv3HM9S0Xe3DlSvBFsv3bXWt7hv6ntpBcMA5nYhVpXeDObQJdYG9T1pvVnQXNvz12d0/oruthmBoI9YXOdBdY93rbbvc5GLDfLBffTrDyY2e5BHaF6ef0F7MHK6GXT4pWns9yQeHYHtmeIp4j6e0Y+1yZ4XBYELoR06jritMmJzJp2o6wuSVWJRk//g3SbSfibU3h9ZeaWPtFLX/o7OfqU6tYX5+m8MSrAGh6nMLGLXh+pyiAFVPk1u9/MXrTSdLJfnS7BrF+CwLJFn0zrvQYV1WHhqAgod+TVPt+tZlL4ekWvYZDh2hmFxPR9AyN/oRgfyLJxrRGUhP0xQwcAZaRxI2BKVIUgeqMP3loWMgZftejC3Fdw0Wp1HU3/oAe/QXaJ75K1skwSaguVS2tJjmdvhyuWVK/hl5gZ1+B+v6Sf31K+0VMSKimGqm7mMfPoPDuu6CBlytZFvntHaq8EpXdEqvZAX6GizB7ET6hj0/Fwg5PddCUWusVMESMtJnkp3c9TI2TJhlXFUWuW6nQ7aCkrTCYlEIi94m97w+b0ZIG9R+aQe+xTTzf71A4qhZzQhXWVnUeLH9RXk0kcN3sbrv7PEeiGRq6ruG5Hiue3cbjP11x0JcwhmWLgeUyxBqfo8H+UOgBGaaq1Z1Y+apFB1PZYkDopu+hl39u7GKlQg9+t8d4rmF3OCwIXTc1GvtdHM1gWa60huGCadsxjQI1O07Dy2j0xEqF/p22wwafnHqPn0f+kecBZbnkN25BuibCVH8sK1aDppUsl3xNgkQiA8UUWpufQ1Ln0mk5NFSryb+iJ+nzPExTkbDp1IIG2/165j5q0LV+Gv0a7JVVKTwhOKtBXTw64oKCOQHNsDC1FHnpUdfbA4DXAG7tTPVGZEDovv+YmoCj9SKNDLG2NdRqSpHqVX4Alu0hjTJCNwps6cozLt+Dk0jSVdNEfdsWHKcPI98AgJjTDLaNl+nDK5TKNfNd6thCSqQQJGq3hs9pZm+4LOD4VIxkGaF7TgLhd/5pmskfTzmb1p7jSKKTjqvGofISRlCxAqC+UAMrCOxAofsEY+/MEp9Ri5YyKRZdOl2JVfSItaSxtvYjPYndp/J1YuY4pHTwBizoXQ7PleiGQDMEriOxco6aFBzCQ/Y8Oeae7yuPrGfV83tfJhhccIwxLrncHx56SOi1itALZYT+XlWMDAWvrMql/HeoPB+u7UWEPloYMY3GfvXhfbO/lNdxzIS3yBdqSXWpJIKusqbWzUu2s6VN/Z6ddTTaLj8LXYuT37oD6ZrgV6dYsRrS1Tq9/gWhM6lDvJ9CVscs+pOT9TbttoeuqS+PbWj0Ox6uoQg9LtQE23bfeuilDk3vp85ShP5WSn2Q39+olPGOuCCVmoJmFKGjn+pMF029SlU6tRLLD+0SQpBIpZANdQDoDa24ZgbNyOJld6H5mTVGyl8MQo+pTlGfc3S9wKbODM35HqyGZtqbWmhs34Lt9BPvVwFKcqqqurE2b0CWfYADkhUS0ATxckKP9YaJkc2pGCm9VD/uOUnw4xGEp5PshNb4URi6ixlTFxF3gOVS/mUp5iqJJFCKVtFFOh5udwGjKelvq4jBLjrEWqqRBRenqxASejwRTHxmGApSSlzXQ9N9he544Z3AwHEALH1sIw/e8tqQxxotVi/ZydpRWDz733IZQ0L3/4apGl+hH8yWi2DISfIKD72M0J2I0PcOhqnT0K9O2tpJ02nMKTWa10zWbj8V4b/Njs63wn12rOtm606lMPsnT0AzU+hWAl1LUNy+S1kumgN42GYVVXVxcn7HXXdcI2cWyPZpxF1FwEatxU63dDq9mEaf4+GZirCNmMpY2W6qEv1eatHNfqpzagyrkgYTipK51YqIXol7NCbq0YwCQlRhS5ein6HiVDn462EgNI2YriPHqeMmasbhmhmEJrFkG57pL96c6ubUKg1hxHC1LFrGz5EximzrzDEu143T1ExXcwuN2V2ASzyjfHo7mSN5/PEU3nozJGkAx/AX05YSXTeI127D9QO+9Fgm3LYpYaJ7Je/bs+KlfPWCpLi1h6QFQi9imorQvQGWS7GMPAYSSaiEfLJGUkboTriNOVldTO2t/dgZn9DjAaEP7aNLT4KkpNBdGY5lKELr3pmje+fuLZy9hZV3w/yQvcEgy2WMLKKS5TJ2RBUq9BpVzVTIHpyWi+d66LqG7guSSkIv89AtNzxPkULfSximRqooqfZr5cbFa4kXC+SWtPDOugsA8Ao9ZCZVo0mJkJLCCePoaFIfnp64TtXpp1P9dJIG63jsbAHpLxUndAeERqI2QT5ZOl2dsQR6xkBP1WLLOmLVNhkpyPrt5F5MJ2N7uGZWXRziakmtLSjVmxdVuLECPHAf3fE0W2MarXnJhJh63aVxSAsdzbSwE81sTDfyxF98FwBbt3D8cH1NF8Q0geU33ScTKv0QoGNqLa5v+QijSFOyQKqmGWkUSTaqxaU9o0Bu6y5lucxIkp3aiIj5qr5Yh/BqKBS3Me2+n1F3+YcRmo7wX9c2fRvFk2iGTrxuK+Tnlv1lFJE0Jk3csnJD1y5ZLsLVQbjU2i5Csyi+mgUErpcnv7KDrl+8i5QSK+8QT/nplIMUeslycfwJqEGEXnAxx1eBoWFt6cfOqgtpzPfsnWEqXVyfFMsVemDtDKXQrbyD58ox/RJbBYd8fyWh97bn2Lmhd5g9FAZ2io4VMTr7Q6H7cySpGvW5riD0g0mh2xLNEOj+HFAFoZdPilpllosVEfpewYhpCGCa3z3p9jtQ8OiOVXHtS2oNRJndhnXOH9NgGtQbBr31MdrS6oPerUP1OWeTejhL7rp7IF0Lfqmi0NUHK14VIxcX1Phrf3bShFOsoeaiiyjKBuI1artNmke/BvGGBMIRdMdzmHYVxqaJeAi2MYWEq7z7fFLiuYJ/OP1zdOnQ7EBjzAApWRMHD0ctslE0wdCY3FSN5xrYTg6mKa89YejENEHRk8iYjhYvWQc9RzWEdwgATqKbhJHAMy2SNerC4ukFrmxrZ9y8Symc/RyNC5YhfTGtOSlcZxyFwjZ1JzBlsnocSKZNkok0aU0l5XrxPoxEP1gzQPoVLT6hN8QNnDJCd4rxMF9daAYkoEl3EZqErIbmJXDdPJlXdpJ7ow1rQx/FvEN1oxpYoJCdrgK7fvg6k9/YxelVOmRtnE5F6OYgy8VF6IL49Bqyr7dh+8sKxmNKoTvDWC5BdkfW+AZVk1/AdWV4ARmK0ILHyglpX+DaHp4ryffbFZ2Zr/x2PX/471W73Xd/WS77Y1K0OEChl1suzkFUh+66HrqhqaonKrtYKyZF7WhSdNTQ/dV0qnYpouzekcG2NbYdt5B3Jqslx2ouOoVuTachZtIYN2i3HHZa6kvXaTuk/cVxnbY2Eu/7IzShyEMLqlQSOtmYYEKX+qB10ciaxBwaPvVJCm4jsWr12s81JLmlQZIcn6TBE+yoL9LpJDCyVXTSREEkmdW1EYBMXGfC//sBHc1T6TYVoetCoFke+bhGu585UJuPoyUMaqpjSCeGZefQj1fKMqFrxDUNS0pI6LhmKcc7e/R4XCOLllVll068CykcpGYT860Gz8jzvsbZWCclwSxipvM8cubl6rw6SXJWU5gTL/wPsS4gh8cp1UnelzbA9fDSyj/XvOloUtlQjqtIe1ptEidfqh+3CzGMugRa2kRPJxFpjfq4+lsIN4ZwTFwnh7VJWWeZJTuw8i41jYqkrZyDvTNL278vw+kukkkZjDM16rI2TkceLWWgpdTFPSDYgITrPjQTXA/HUgQeKHTXGZrQXUciNBtLvEB62m/xnNKKNMUhCD14rJyQ9gUBaUpPVkwUZnutPV409l+VS9A0sz8sl8pJUU0T+6Wx6J2XdozqoqvSRQXaUJZL3gkvno7tlULGIkLfOwRXy+Q2X521FaHo0u6ZbG88h806rPfSbNjRT6Op02gavJPNh1GvnZaDMW4cNZd+kMZr/hKtaTxuURFerEo13LhJA1cTTPQJvZMmKKQpOh45t4GaeA8Ab0+M8fyMJEZDHB1BtZan3U7iJmrYgspomd2t0heLCQOpN1BbH8cTgvGOqpKQBRcZ19nsTwwuxeD1mWnqUjFcN47j5gg+iroQCAm2J9GrTNxYiZhiNeDG8sSzKra13ewM2/5j/lJ4nl4A16Zn8tMApOni8joVMaA5Sdr6p5DPb8Zx+v3uTvWhabAcEpogoanX91Jt/nOTEUJdQGyf0Cel49DlhK3+diGGXhNj4tdOQU/EkUmBZihLQYtXoTlxrI4eZNFFr4uTX9GBISXVDb5C77fouGcVIGi+Zj6b6pL0OJJaS1kugd0ClR46KOVe96GZeLq6AAcKfTgP3XM99Li6SBqpHXjmypBkh7NcAAqZsVHo5aSZ7ysdM99vYeWc3ZdbDlDoY2G5lFfx7JdJ0dpgUjS4Mx46M2Vf0NeR5//ufpu1r+3a6309R6KbJQ+9osql4BJLGuimyp+3C5FCHxXSDQnqJ1bxkfH1nL08R1OfSzzv0h8XeK7kjU6bl/+whbasRcqSNMUMNuQVgaR1jba8zcrntjHp1ltp/ru/w7E9pKXshViNIt9cws8kyXmkbItOGtGLNWSLDhmngZSZRfz/9t48SpKrvvP93Ngycq+srLWrl+p9kVrdagkJSYCExCYsBBjMIgwcFvPw2DPj8bPHZvxscwaP55kZ5jE+Yxvw4BmPwQYzhjHGGCNACIEQktDS2npfq5faq3LPjOW+P25EZGZ1VS9StbrVxPecPp0VmRl582bE937v9/5+v6u32N8nqfWY1HOKvCxRpeammFnRH/nn62tB7Llh4fzdfu5Cqcl+X1BuuIimh27rTKFI559bAqMvyW/OT/OwuAHPr9MI1NbTY3M8cWSGpi8xshaeWeZHvIJv8XMktDK+UcWuDYMUzKfnolronggWH40GlVNfol7cg/BMEmI2CmvU3CQHJpX3Xyo/HSn0hAbXWQbjjs9YoEJ8exrpaxh6P7pQCr0ZELopwTpeQnhqOu3U1P9CCIQw8E0fJ8jaZHQA4Vs0J1VcfM9bN4ArGbW0yHJJ7J7Em21QvGcL5mAap+ky6frkfHBO1zCKbUJvRISu/n/uuY9xqucLJG9WmXuWFXjoSxC658qI0AG0/HfOarmEJN+ppl8IOm2NWoePXq84SHl2sggVuW5oCLE8i6Juhx+83GGLmi6idZJGMMNJpMxlJ/TyjLq+F5thnQueqyKeQhG5cFHUsg0MU8NreZF3HhP6BSKRNLjn92/krjdv5JXPNej1NTI1idQER3dm+c6ApPn6QWoJDX+iQdFsT/+vziSZajh8/4t7+f5f71UZa46PJvvQtBRW9jQANVuRU6op6XGqzNCHUc9Ra3mUWz0ANHJlxoN9Qo8wRwuJToUxuZJfHdH5Cu+mX46zxVORIHN6inJGsCqIjlm9tkCp4SCaPtg6IlCRDS+BSBuUfJ9nta34sk4z8FPLdZfJ+SYt6WPmLFyrwr3cyd/wXppyHoSP0cohmjlEbp56kFRUdzO0PJPDBZfxlQ+DhPyJVyKNOsctRaaam2T/tCL0cgehb7Z1kkKwp+HzbMNDGgLPnsKtFxivuIyXgkiFgNOqj02QnKoj3dAfNaP+F8LA911OBesKXjKNRgLfraP32iQ396KtyrItqZM/NMd1aZ3k6SrZW1eSWKsGDqfhMeFKNAF+1YkUuuf50XTXaXr4vsvp8X9gZuZ+tKB0fCKyXLoJ3XXLTE59F9/zMQJC9+qrMXIPIlGzoIUK3ffbi6HLpdA764PUg0gX35eRXbDYLCFqT7SgqyyC5YhD7yw6tbyWixeQYZApWnOi8MDltlwqs83gM58foetGW6F3eujqO+gYlt4VthgT+vOEZRuYaYMeX1AIFi/dYoJ9OHzz8BR1S+CeqEXp+ABXZ5PUdNBsnWcfOMkj3ziM2/IxTJ10am1E6FUzJHSfXjnHNP0YrQylaov5gNAPrWwnLj0z+VMmdB8hKuy3tnJc+LzN/Tq/wR+yvtaD6buUyHP/xDjfC3bHXX/jCPN1B9H0cEwN31Q3cNNL4CXVhT6mrwQatMJSur5kptJU9lHawLNKTNGPK0we9pT1oTlpZL0XMz3HAVNdzDXHoulZ0A8TG1L44yaJpkpWejitdmTX3CSzTgZhDFEuPR3Fjg+bGgdMwZwnqftw/PWrcdMzONUiz4yXORgUEat7guc2Z2kemkf3JJ4XEnp7QNWEgee57A8qLrotE8NM42utiLDFa9dwuOlhHJxj0NCYKybJvWZNdA6n6THjyqhkcUjorQ6ycxoe1doBfL9OvT6G59UQwsQw1G+3UKGfOPkldu/+CI3GBLqtCN2Z+jmE3iLVv099j7paqPzBl/Yxeby8IFZ++S2XUKE3q060L9jZSCkkdKEJNF0sy6LoxVLozbqLldTRA9HQqLoYpqa2z1tmhV6ZDbZgfB6lCzxXJZnpiyh0p+liBgq9i9DjKJfnj56BFD2eoK8WFMfPGVRbHvtnq0hNkKx5+CcVediaYENSkczwTYMMrctzYt8snuOp/QLT60nkFKFXAg5KNSV9+imm6QepUZpvMNvoAWD/YBoTddPV5RgThofQa8xofSQlvN29l5WM8b2BPnS3RYk8t/zCICVbQ0ifk3t+jenTnyMZqMVaSt2ATc+iGUSFnNCHkaKpLBcpcWl7ml7KpGHWmEPZCfe7iqB1J4VTL6CZM8wHvny5adFwbXpsh+agxhNsIfXqnQBk0uo7626SBpIGG7ssl6YvearQVtmnmi5Sn8Cp9TJdb1FzgnosUidxywhDv34dxwdSeEH4TLPSjngRmoHvO5GH7jRMdDuNrzcjQm+1fHbXffR3buahhMGJgh35+aBIzwem3G5CD9WrYWm0mh6l0pMAuO48zeY4up5C0ww0LXFGYlG1qsoNN5un2pZLQ203ZmWV99qqqa39nvr+GIefmOwiuEbl+ZPd3ESNL/3Bw9RKrS7LJVTo9XJ7sDi7QvfRgg2+w7IFLxQhOSVSxvKm/jdcrKQR+f3SlxiWjm5oy265RAr9ebTf97oVureoQte6Uv/d5osXpXPFEXpxMEURjVVB5rgbrPDLYCqX1AT1wyp6Yjhhkg18XtmXoHc4xdx4DdfxMSyddGodRmoGoTcpBfk0aafFkHWQmkhStwTzcy1mmz14aOwr9HKjfBAhfRKZFl6+hBCSqtlL1oMJX4UantYzmK7LPD3YuTrlpEZOzjM7cx/u/Gd4VeEhAGbTwfTTTVAKxH9Ds5nRUjR9H8ND7RAUqHV9Rx/HcyZSaAy5YxxmFcdYzf11k0q9APpkRFylpknDS5A0GvSnphmvD5DpU+sGQ+kJPM8E3aSuCSbqo9TrR5ApdSM81vCw8u1EoROlCmjTOLUik7UW1ZYidOlrbB3OYfTaTBk6SBukjee0lY2yXJwoPNRp6Jj5HKQ87K3K5w+JMjGUxkiZXcpbvUepuVOOD5Z+BqFnCjZO06M0/0T0nmp1H7quXqfrmTMsl1rtkDpH6zRGoozARPgDuI0sVkYRerPuUg3K8dbLTpcne6ERFLvvG2P3fSpSaPzQPNNjFaZPVqKFNaGJSKHXK20vvRW04X/82x8yNVbuOqfnSbQggUvTRRRT/0IQklMqZ5235eJ7PqVzFKhq1ZX/rBtaWFUZw9TQTe2ys1xUHPrSHrpu6kGUS2y5vGDk+pOkPcFIXZD04EHZxOtLMDKgshpdAV4QDbMiYWGVgxohBYv8YIp62aE631TJSun1CCGxMhOUhMQEstmjrBLHAJjM6VTnm0zJBJ/x/xV1LcEuHiFPgzmtl7tf/imkFMwbPaQcSbmRwGslmai66I6q56IlZqikJUUxRbb3Q5THruW1me9h+pInBpTX7kibKc+NChSeNPqYr45h4iBMLayHhZcymEipGceN1R+iS4cfcDuz5JgvDYJWJ5lXNUFm6iYN18ZrHcbUXCZqfWSSKvKlaM9ScW36/u31DPSnODCnMkbr9iF+Opxmr+vRk2mr7OnKSRA+TrVIzfPJpoJsUc2gP6va02p4CJKIYIekUB0JYSB9F80IS+DqmHYGkfXRg+SpkCgTSYNEyugiTimVb53qSXC0JUl96Gq0IC27GZTVzQ7O4DY9SqXdUSZqtXoAXU8rJWikz7BcwlDNVmsc3S6jawV0Q6dVHsTKjmMlDZo1l+pcSOitroHmQhdFn/3hSZ57UP021XlF2I2KE9kC2aIdKfMuhV53mT1VpVZqMXmse5bhexItrJmji2VdFE3lLdymd17n3P/IOF/8+ENnHeSaNRc7bSKEwAjI0rB0DONiEHpguTyPNQBluWjo5iKJRQ1XKXSzW6F7rv+ilV2+4gg9P6AII+3Cv6snsYSGc10fbFDT99mmg1VSN95wwsSYCyoqZnUKg4r0KzMBoafWAWDlTjOPTx6NVPEQq1CbP0z06MxVWuzbmOFR7QZeJ/+R63iEQSvNhBwgm5jm6GO/RN1KICsOs9Usbr2HfVMVZMuiJHpouU9RTvv0MkOlOkrl1Hb6UyfZWanyZHGEFiZZO8NY0+FlOaV8TxhDTJWewdKrDPQ26AvqwLR8ybSuCLRQn+NX+TR38nXWZvuZmVGec2pgDwBPjLVo+TaNxtGgXwZI2kUkOpqQtPwkyZzNlqEc9x1UJFguPcV8U9V1LOTbOwfNN5WydGpFXAG7RkcBSOhtW8ZpugiZjSJgQqLSgkVRKxnEi9cMND2J17FhdKikrKRBIiDSEG7LR0pIB+FuTocIbdZcUv17SW/5lxQ2fZtKdR8DA3cC4PtNvJbF5/7NDxCkuuLQTx46iuOoujmOqxS6YfSiGSIi9GxvIlDHoWpuK3Q7bV7womh1vhkNDmGaf6PiRANfvs/uON6xn23NpR58Vqdyh5DQA4VuaMvioYeWS5gAdD6kWJpu4Lsy+n6LoVFxsNPK1wwzW3VTQzMuhof+/C2XMMploeWitmD0MJMGhqV3FeeCdv2bi40rj9D720WgXtmX4ytb12LONDmsqw49XqmTDqaNvZqOmFI/btUS9Ay236tbOkl7DVIKrOwp5qRPTmgkew+Rc3UymsZEXueg4+AZgo/MfZn38xckzTybe3Icddby3YmPUbJuB2DidJUfPHc3Yz/6FWYbLglfUCLPXOkRKrZOgRlmp1dRObUdgJuqj9IwLB7nevLpHMcbLbZmkhScEoeN1TzurKCfCTaufJyRXLCNnC+ZFIr07brHDTxEkRlsmUW6a3E9g2RRKc8fHqjh0w7vm3MGEUJDBOEfnlR98Z4bV3OilMARGzh1+qvUGy0cISnm2oTebKnQTqfai4tkVVHVrRnMtfvTaXqI8nsZzKo9xLsUunQxk4FCr2nomt1F6M26i9AEhqVhLVDo4U2TDgaYzqiQZs0lNficasvOrwA+xeKt6EGhsHpZx216SC8ZKfS58Rrf+vw/t8/vTqInyhh6L7qu0aoMYiTnyfT5Zyr0oF25Pvus3vZCeI5Po+JQLzt4nk8tsHEaVUeVLLB1UrlE20PvGCxadScqC7BwEAk9dABdF8sShx5GuYTx4udjW4TtWli+IISUKmkqEczIQh/dMFV44HJ66G7Li9rzfCwXP4xyiRZFg41dXLUHauShB5aL0FT/v1jJRVcgobdJqmcwxfr+NI/ddW1UI2XG9Ui1JCsP1bj3u4eZPVwGKflvDx7BylvRD+BIybv+/HEatSKJ3GnGak10zydZPITQtrElYzOe1zkcbJKwuqJ8+XR6I6uTCZxEilddfSfNVYpgvZJDq5XDqQziCrAleOiM1aapGQkyTp3ZKRuv0UN9Zg1Xm/9I3i1xP7eTy2aZdz1W2RaDzjw/FTcwIYZ4q/tVRvp+wsq8+s6zjTpTMkfOqUEz9LgFzYrJlpVFDG0DQlO7Mb1nIsFAVb3Gx2SooJKJhKHsEhkMDDes7eXa1T18/eBtVKv7SWQfxRVQ7PDQLX0SALdWRDc1+vIqWcc22rZMq+FhGSvIZFTly/BmElpA6EFVyGZFR9dT+H49Sppp1V0SSSOoLGl0WRvhwBASeqdibNYcUn370VmJ21DlCPK5Hdh2YCHNBwtwrh2tLcycqmIFC+GGPoDjjaMnyphGAc3QaJWVLZUuTuM0vSimuVZuRQNNrj95QQq92rEtXm2+dYZCtxI6yZxFrdxCSlUGIJFS0RTNmtu2Ys4g9G4PfVksFydU6AGhn4dCD62Whe2Lztny8V2JHRB6SJaGtfweeiUYgM2E/jyjXHwV5bLAQw/PFcahuy0Pp+GRzKrv9GL56FccodtpM0pO6Al88/6ExV9ds5Z/MdiLJ2FG87l9d43KRI29+9UmyFMth88/eIRckLyyZ7LMY2NzjDk72b/C4Hi9RKOyHzM9w6aNt7Atk2Qyr3PMhkLJxfAVYWTSm1hpW3jArk39lPrUD1qoeGTD2FUBKalutCOoLM5kRac228AXUD55DeniIW7V72U3O6GgyEoRulr42i6fYmTPCtL2Hlbn1EV6YGKcKfopNOvIYGHSMLK0GhI7ZZJPKfXveUkyUqAHpJ+yVvGVj6rNP3Qj9L+DssBC8NFb1/Otg1fhaysorvkHNFNgJ9uhh4XUDFIWkL5Jf97GtoPttmT78gqVphW8LyQCIQzAxbDUzd6oaGjBYqXvtxevrKSOlBIraXTVRG/WqiA8Uj2B5dJx4zRqNeziYdKJV3Dyxx9loPBhLKuPZEDoXkv1q+ckcJw5fL9FaaqOlT2N9A3KJ9fhehMYiTKmWUTXRUTodo/KjJ09VSU1+CxOqxSReK5o06x11145GzqtiOp8s+2hV50o+zCZNaNpfL3Sws6YWCmDVt09i0Lv9NA1/PNsz9ngLpgRnY9tERH6Ego9fD68b8NYdMNc/iiX0G4pDKdpNc6eabsYVG38My2XsB9CD91periOHw18MaG/AOT7k9hpEzvT9nC3Z1N8bPNKLF1jXPNZo5v81QdvoCg1ejWNwf40f/r9A9hFdaE+YDg0bx/m44Vf5r+Yv0HDSHJ99qfYyQ0MDbyGrZkkTUvjSE5jzZSHawfKLb2RkYT63BONFtNpjWzNZ0VLMJJTROUiyQRL+cfERvW+uRSteYdmQnBy/OU0ZleROtiPFBoH0uq1q2yLdc48CdngHe7jlI6+HIABczcAe8ZPM0U/+UYLw1ERNYaRxwlCwtIBoeOpdpTy6jX4K9qd5yoyNhvtmc5rtw6yqjfLQ+NvINVzmIHhPZHPCdBrz+B4KkFnsJDEMNXiLzKo8uf5eK6PZevRxgCRQhcGEg8j4YI0aFZ9dM0O3qdCLJt1l0S2xoM/fjWe/Q11rOYipcfeY29nYMf/Xtxycfeg6Q6Z1LXUJjdTzKh9ze2kInRNS5JIGbj1FTQaJ3jwx69mdv772D0TmPoqarN5PH8czWxiWkU0Q8OpDCClQLeVzVSp7WH1rf8fvZvuZX6yjpHQSWYtpDz/TMRKB6HX5roVutNQsc0hMdRKLeplh2TGUusJ9Q4PvbzQQ1d1RyBQ6M9D6c5P1pk51V4wdl6Q5bK4Qg8JPbxfOy0XfZktl3BBtHdFGt+78M1IVJSLFs18wveH0UimrTz0MNM13IHpxSL0c24S/VLE+l0DVGYaZxw3dY11/WkqbgvmPVago0noM02MHoODEvZW6mhJwU+2phjQdN50GpIn6+x6S4Zr+36ZgbyyJram1RTd0wUTpTra+rXgQya7hZW6+hGPN1qM4VGoegy5GkOZBODgCigg0AV8Xb4FgPRUASoOVVPg6Cs4cu/vUR3REcMuB4Mqtatsi82yyud4H7Ozv8R0tR/LvJHG3DeBa3j21GmmB9axsTmJ0VJkbZo5WnWPRFInm70GpoFWAg+JzKjEI68+GPWRX82DCVq9balomuDuHSv47Pev4rqX97Fhy1fQjPcyuOsLaEYTLzPJ2Pw6fCTDwxlVy6KRgyBrNrrYE0ak0EPi1YQBeOimAyRoNTw0LVToYQKIS3r4IRqN4zT4Y+zib1KbfxlN71Ecd4zcmjlSwX6srYbH0aOfo9WawhUtdCCXvR44FM0KLFMNYLneAvWCTX3s7dz4zjs4eOCTNHKfJOklsBPX4tYLIIL3WL3oukD6Jm69iEyoheDc6LcBSPbtZ/5IjdzIs7iJZ0BsoFF1IhvhbOhU6POT9a6KjZousGw9IoZ6qUWj0iLXlwQkzZobkcriCr3Tcrlwhf7t//40AL/wMbVxTBTlkg0tlwtQ6EtYLmHdFjsoqBam1euW8tB9X+L7Ek1rJ+7NTdTwXUnvivSZJzwLQoXeO6Te16p70YzgfBAmFgkhuuygzoV7w9Ki2VkyVOgvUnLRFanQd71+Da969+ZFn/t/33YNH/w5VYHxgS/vB9QmxhXp84FbRvnJTJm/vzGDr8GnN67kX9+6jvffvZnXr78qInOALek24Tmez103vJVrr/0C+dwuVgZEdqLpcLjepNiCIU/QH0SjuKgF2S/vWE+P7mNIB3t8gETVp6T5uEHSjpEy0MbV4mBK1+g1dUR6I7KW4+AzStmvW/G7UTLTqVYVV5ikG1CohrXKM3iuj2kbZLPr8FpJ/KbNjCZJJBTpN+b6o+/ilYPSt2Wrazr6ph0raPkmJ598O+nMGHsPv5vChvvJrX6YXnuGfeUcf5JrsH40j25onPrJh0jK9wPtm960daxwE+AODx3hoplOVOHSd4N+csv4vkOj4mD1PUA6vRHLHGLkps8yPX6a0+P/oPopUcEzngQBDedZDhz8JMeOfx6t8GW8+jDJtPp+oUrym+rvTE+eTCFBda5FX/E2rrnmc0gp0aw5stn1OLX2Tu2JQKEDePVhXDmGniiRW/0w0leLzXOTFXJr76PqfRGkft4VF6vzLXRDQ9MEk8dKQb8I6pXAcrGNiBjqZSdQ6CZWMrRczuahB+T4PKJc5idrTBwtRxYQKL9bM0Q0UJ2PDx2q1YUziHCLvKhuS+ShB5ZLkFgEbSUspWT3fcf50r9/mG997ikuFJXZJnbaPOcMozzT4MnvHT/juO+qDS5A9WlE6M3QQ9ej9kOHQl/GMglnwxVJ6GfDzlU93HjdMJommDhW4qpXjTBaTHG80eKuG1cztjHNkUGTqw7UuXVlL8UVGVZs7DnjPD2mgeX44Pj89ivX05NK0Fu4CSEEWUMnZ2j8rxNTzDgeA5rOoKfRmzARQt2stqHzikKW79+4nT/P+Zg1ZcIcazqwMsWr3rUJ2Z9AP60IfZVtIYQgPbCLPd/4I8xJRcbpzBpGV94DwJaVQey0kWBGBHuTHm3vgWglTeaP3Ex1Yiv1pMZwIQhHnGgT19zJIGKmlmBuvL0N3KbBLJsHs9ROXEutuo1afS9Tz93J2A8+Tn/fa9k6ehcNDbYN59BNjcbsWnCVEm4rdJXaremivZgmDRAeutFCBITuOerGfviRu/nhj27GMx9Asw+wYvgXuHrbH2PYJcZn/5DJyW9ha7fjOQlK1XsxE4KG9Wksq5+VK9+H0FrIxrZou7CwHa1KsLtTOke6kIim4QlrBeOPqb7sKW7DbbR/94TdF21qIJvDNN0DjNz8Z2i6i9l8N5rRQk/tI9HzFLn0rYA47+Si6lyTdI9FKm8xcUytkeT7k4GH7mLaOplgHWX6ZEWF+GWtKIQzDFds1d2ujas7o1w0/cLL0B74qVonqFda0eDutjxMq2Mt5ByWi+/50Ws6CX32dJXP/av7mTxejsok2ItEuSz0qg8+NskDX96PbghKU40L9sArsw3ShUQkLJaaYTz7o5P88G/3n7FTlOf60aKtboioXeEsw0oa0QwD2grdjRX6xYOdNnnbb13H+/7Dzdx2z2b+r1X92JrGv9h/jPHNWdadaHF76txTuVVNGCx7vOtlq894bkc2xazr8taBHu5Z1YeJoHKghG7p/PrrNnH3TkV2hUSK6we3Re+b13zyaYvtt60klzIRZYdR22JDkDD0uu1DmEWbdLCoalgaqwZVbPUP3DsA+NGYS21XsDNSUCjLSupYCYOJJ97F9LN38bbbRnnFtlsRznZmDq9Q9barDvOnApXs2JzYN9f1nd509RA6GqXpf8OWLf+Zqafeil9fzTXXfIYP3v5mHvrYHWwczJ6xm4sTqZcgUiVtRjeK9DWE8BF6Cz2wWgy2UizeysjIPSB1Vtz0GUBjcPBNFIo7KR1+M67xA1y3jOm+gcrJncyWvsPwDZ9FGgfYtPF32LTx95h97pcQ5XuimzdsR32uiNdK0tM7SqYnocIFHZ/yTJP5Iy+naH6GoaE3YukD0Xe37GKkdt2528mmd2H3HKd0fBf9xbcA0LftGwi9RbFX/Q4XRugJ0j0J5ifUAF5ckcZpeDSqKvswmbEYXp/n2R+dxPelUugpk0bVoVl123XEO1R6t+Vy4YuiBx9T0Uu+K6PB0G15UY0VIc5tuTQ6ZimdbZs4Wsb3JFPHK20PPYxDD6NcTP2MmikTR0pohuCGN63Dc/0uX372dJVHv3nkrCRfmWmQLSTaazlLKOcws7XTDvN9iZS0Q0E7FHq4DpLuSUQDEnD5LYoKIf5CCDEhhHh6ieffI4TYHfx7UAixY/mbufwYWJOLFtLWJBP8ybY1HKg1yZs6N2WT3HPXxnOe4/tv3MlP7t6F3uHthfjyjvU8e8t2/uyqUV57yyqKKzOUJusYhsavvHoDt2zoi16b6WnHdN9w1QB3bFWedk/KwtIFf7dzA5/cpOyenG2y/er2ew1LZ1XSZkvapmT0QNPjLRsH+b27X4am2Ri6UuEqJbm9mFMYTpNKrWUw9Se0ajbl2QbjR0o0y8MkreuQza2c3D/H8T0z7L7vOFNjFe6+Wg1CK4trGFnxVjStraAAhoJQxnBKeuaCUbDH6KosE0dKwWs0hKZq3ui6ev/Y05LHvvABBvO/SZ/1adxmhlz6ldH+n3r1HbiVdSSsQWjuoHz8elx3nuTAE3jT72Fg4OcQQjB/6BYSieFo1/uwhG5lUuPYdz7FyKq7I+VbnW8yP1kDBP2D16NpJqnMENIPau13KHSDTezY/pfs+z9/zMkff5S+FetwagXSQ88i/RTF/huBMwm9UXW6QhRDRITekawVesNu04v6bePLBqnMqPcnOxR6+HvC0oR+oXHo85M1Jo+VKY6o84Z2jtNSZTGEEMryOYeVELYnkTK6yv/OTajZX2W2QaPqoptatNBudIYtLlDos+M1egZSUW38TsLd8+NT/OTrh6h1WESV2Sb/+Ke7aVQcfF8yN16nZzC16AzDddqZr6VJNWvr/L3C6zlsk/LQVZ9WZ5sk0gampXcFDLzYi6Lno9D/J/CGszx/GLhVSnkN8Angc8vQrhcddxRz/I+r1/I3O9fzqTdvZ03x3Ard1DXsJRZUNCEwAqLXNMEr36EGiM7RO4SdMdECsvidd27nhrWKhN9/8yif+cXrGElaamu6AP3B9nPh+bKGzvdv2MKem6/iL0aG+fQv7MAydHZd+0Wu2vnLANENEJJDSBiFIRXaOXe6xvjhEng211//1/QPX83Bxyb4+qef4IEv7+fLf/Awz/6DsnT6etS5jITeReghoup+kb/YDukCGBzNMnOqSqvh4geE3vR/Sia9E4DHvn2Metnh6NPTlMb7OfxPf8g1O/5rdP7CYI6xB/5vrrvuKzgNqE/uZPPmTzC/+1M0T/88QgiadZdmzcHOmNGmviH5zE/VyfX2omk6meC7VGablCaVKgtzGTK9KdxGDt+1MMx0pNAtW8dM6MHm44Jsr40zr35frXk9yUxArh2EfmLvLH/98Yf4xn97squvpJQdhB5seyigMNS+/sJ+W79rIMqTSGba4bkAvQGhd9oa3gtI/T/69DQAV71S1fcJbR235UUDpGUb57Rcwj4oDKVpVt2oDeFMpDLbpFl1sDu+i96RKbpwq7e58Ro9gykyvWrwK3cEP5Sn1ePZ0+2onGPPTnNk9xTH98xQmqzjuT69K9JYyTMtl6/8x0d5+BvqGg8Veufg4C8k9AUKPbyWOi0XO2OCUIT+wN/u45//fFFdvGw4J6FLKX8AzJzl+QellLPBnw8BK5epbS863tCfZ0c2de4XPg+MbCqw+cahIDqhG0II0vkERkLviooY6UlGar0T/atzwRvpItSsbfLG7SuiaIB8ficbrt3IBz75CvpXq0HAShgITUQx+j2Dighmx2uMH55XF7ttMHp1Ed+X7Hr9an7xEzex9ZbhaAoeKSlLixYKF0KFm0l8z+fYs+ryCae5g2vzIGHyaBnfVW1NGBtZO/rrgKq0pxsaY3tnmTlZJddbJGG3B7H8YIpG2UI6/Sok0zZZOXIPuhiOZgOHHp9ESlhztcp8NW09Uknzk3VyfermSwcKvTLXYH6yjm5qkVLO9tq49QJeM6uiGoJB10yqPrSSBpquLCS/oRKmTHkzmqY2aggXRU/un+Xv/+sTNKou02OVKIYelEJ0HZ9MT4JUMFNLZq0oIaWz31I5i5VbCtFrrGQnoQfZr10K3X/eqf+lqQaGpTGwRl1rjcDaUB56MLAl9fMn9KB9oQUTrs8ohe50hRgvZbl4nk9pUinsTOFMhV6KCL299jMfzASmjpeZOamIvndFpiN8NrCSHI+Zk1VO7p/DaXqRJdit0Nv15UHVFgpnINW5ZjTb64yaMRM6pqXjtDxO7J3l1IG5s/bXC8Vyhy1+CPinpZ4UQnwE+AjA6tVn+s5XOu54/1aWuqUyhYRSfeJM+2YhCsMptQtNUBr1XAh9PFA3YY+VjAaCZFYpvX0PjzN5rMw1r1bj8aYbhxi9po9EEEr2qndu4tSBeebGa9Eio4pCWPzzdUOjVm7xtU89zulD82y9ZTjacWhwVJHE+JESRn4It5lh85r/TCqTBQErNvSQH0hy8LFJEikjIpUQYYmGufEaTtOL2mPZBqUpdVPvf3ScXJ8dfZaZ0HEaHr4vKU83WB/syRrehJXZZkD0yUgFZ3ttxp7ZjJWZB+hQ6Oq2SaSMaF1ANG5jZt9J1o6+MuhXK1psPfj4JLoueMU7NvL9L+5lbrxG30o1QEXeaz4RqdBU3sLuKH4WKnSAq16xglMH5sgW7a5F6yUtF629KHohceiV2QaZgh0NLG2F7kcDerrH7lLIiyEi9MH2DCKZNSOiDaNOwusMlrZcylMNfF9SGEyRzJhouoj6GDoUeke/hOQ+ebwSXSeFoVRkC4YKPbSypscqXZUhOweMyHIJ2pfvT3L8uZmov0LRpHfMwk1bxwiuvfnJOq6jBqbw85cby0boQohXowj9FUu9Rkr5OQJL5vrrr1+eLchfQhCaYCn6ffmb1+E559cluq5RXJmhPH32kqSLYdXW3ujCBjU76BlMMX64RK4/yQ13rY2Od91kls4d79/KP332qUjdm9bilgsoQt//yDiaLnjtB7ex6Yah6Dk7Y5LvTzJ+uMToNXdw4OtD3PSJ9eimxus+eBVD6/Oc3D/Hcz86RavusvXm4a5zh58/N1Gj1fAwA4JVKlzVKB/bM8u1r1sdDXhWoNArsw18T0YzJcs2sGydymyT2dO1rno+2V6byafeRiJYrAu/a0iwnRENyWQfxx9+J1u3qrDPwdEcx56bQUrJ+OES/WuyDK1ThclmTlYjQq92LKa10+oTXTO18PuBsl1Gt/ehm6quTYjQoqmXWxzZPYXn+Uj/+WeKVmaV4gyVc7j46LS8KLywMJzixL7ZM2LEOxEOMKG1Vy+3qJdV6V3d0KJ8kfA3Bbq89EihO35E1D2DKYQmyBQSlAMidp22qp7rsFzmAmtn8lgZO2WQLdrRgKwbWjTDCAeDVsNjbI8yHIQmukI2I0IPFHp+IMmeh9Rm3fWy06HQOwjdUvbc/GQ9qoNTnWtGG54vN5aF0IUQ1wD/HbhTSjm9HOf8WcOKjYVzv6gD63b2cerg/AV/zi1vP3Oxt7gizeSxMq//8FVd0/iFGFqX5wN/1B6vOxXUQoTK/fb3be0i8xADozlO7puldyQNUo/84I0vUxbTys3t/iiuyHS9N1u00QwRKHS3TbAJtUh38LEJpC/Z9LK2XWUmFNmHCj7XUfMnXbDZ+9BpWnWXHXe0cw0yvd2LvOFUOySEXa9b0zHTUYo67L/hDXn2/uQ0s6dqTB2vsP3VK+kZTKFpIpr6A1SDap/pnkQU2pbOW9iZ9u/QqdChrRATwWcJTShPPW1Qrzg88Lf7kD4IXXQtirotn/2PjNO7Ik1xpLtPF6Iy02DVVUUVampoETErha4+v3c4rZTzdKOrhlInGlUHzRBkA4urXnEidT60Ps+JvbOUpxsMrm3PwvQOy6Vz7865021CD/ssHBBDha2bWqTKfV8yP1kjkVLWyNje2WjGBoFlFFh0pQ5xdPhJZS32r8p0R7mElkvwm+eDQSi0UdKBZda5KGoElktnrfrKzGVM6EKI1cBXgfdKKfe98CbFOB9c94bRZTvXjW9ez9W3roymjOffhjWRPbEQW29ZgZ022XzjmWQOMLg2x/5Hxnn0m0dYsbHnjIEk3ZOgZ1BtOLIwG1DTBPl+9ZzT8CIVado6rZrLT791lOJIN2mZCXXzRgufHWsZmUKC2VNVVm0tcNUr2mUQQosoXLCOFHqye/ABImsifG5ovVLjT90/huf6DI7m0A2N/ECS6YDQpZQcfXoKTROk81bbcslZiswSqhrkUoNsOAjaGTMgdYvTh+ajQcuwtEhNGpaaoXz788+Q7klwz+/fuOR5PdenWmqRKSQQQpDMmt2LogFhhQuxs6eqZyV0O222M13LrWjgWrm5wIm9szhNr2tG0pkp2rl359x4lWTWjF6bKdiMH1aiJiTkkY09HHt2hlZDJVz5rmTdDf089+Ap6mWn61oyOxZ1yzMNhFA7+53cP4dp6xRHMhx9pq1PF0a5hLOKMLx3oULXTZUsZia6k8w6baLlxvmELf4N8GNgsxBiTAjxISHER4UQHw1e8ntAEfhTIcQTQohHL1prY1wUpHLWBZM5wNod/Yxu71v0uevvHOXqV40s+d6RTT0gYP3Ofu76lzsWXQtYtbUXy9a71HSIwmCKkwfmKE01MBOKmCxbx/clnuPzmg9c1fV60zZwmh7zU3U0TUTqG5TiS6QMbn/ftq4BKpFUdkyk0ANiDyMkOhEq9FA19w6lSaQM9jyoar6ECrR3RTqqjfLEvcc5+NgkL3vTWgxLLYjf/LYNbLlJWUzJgLg6LbJOhIScDAa0ZMZk6ni7rrvbai+Kbr9thFe/dwuv+/BVVOeb/Pj/HDzjfOWZhqrxPtcECdlg4dHOmB1hiyqxCNo2ykyHxbEQqs65qWwaoaybuQn1GwwHexQA3YQenN/s9NBdZbl0W2IJKrNNZLAuArD6KrUIPj9Rj9YY1l83EO2C1Nsx20sk29volWfUmkG+L4mUkOtLku5RJYtDqypM2grbFA5iJ/YpiyaKcglmMOHvZibU3+ElHpYfuBg4p0KXUr77HM9/GPjwsrUoxs8E+lZmee8f3ES2YC+p8l/+5nVsv21kUX/2+jeOMvP5KnPjNRIBwRZHMmR6E7zxl6+hb2W3pRAuipYm68qy6TjnTW9dz/V3jnYtHofI9NqEeSqhysx2DAYhBkdz5PqTEeEITTC8Ps+Rp6ZJ561IvfWuyHDw8UlO7Jvlx187wPpd/Vz3hvaG19e+th0sYGdMyjONcyr0cHYQzlRyfTaVuSa+2/bQMwWbbbeo2cf4oRJPfu84m28cinz9o89M880/282Wlw9Hs6owNDCZtSIPvdNySaRUCv3sqbMQeqDQNU1FA9XLynPO9Se7Ir46QzDbClfv8tDnxmuMXtMWEOkeG9+T1CsO5ekGmiYYCay62dPVqM39q7L0DASzveHucNBODz1btLEzJvOTdfIBoUup6uc8/p1jUahle2BXVTCnxipBH3dHuYQDXyg4sn1JmlVn0TpTy4WfyUzRGJcHcsXkkmQO6obpjMfuRP/qLO/63Rt49Xu3sOM1igTX7ujnff/hZvpXnTnbsBJqu8AjT09HESEhTEtflMxBKepQARdHMrzvD28+I+omfO69n7gpUuoAwxt6ABWmGc5AeofTIOHezz9DMmtx+/u2LhmpFFlJSyh0w9TRDBF9ZtjONdv7GAhmXKFC78QNd68lkTaiWiVje2b4pz97Ct+VnDowF1kCYWhgMmPSqLSQweyn0yMuDKWZOVU74zNCNKpu9D2SWYt6RSn0/ECSdN6KVGtn2OLIpgLbb1tJ30gmIvewymSnQm9HKDUoTTfI9CYoDKYQQkW3zI0r/zyZNelflQni+9vvN+12YlRI6KEQyPXZUV7AiX2zPPmd41Fsfrpjc5eegRRI9RuFA284CIU5H0airegzhQTlS6nQY8S4XKEbWqQ6QyxFjqm8he9JVm3riZK8zge3vntzV/z2Yup8KQwHPnrngl/o4VbnW9z+vq3RAutisAObYilCB7VgHJJQGOq4epuqDHn6UGlRQrdsg803DPH0Ayeozje57wt7yPXZrN5W5MnvHY88/pAwkxlFxKHH35kc1zucZs9Dp5BSLtr3nRUnkxmTI7un8D3J6NWqlEIqrxY27Y6IKjtj8qp3qQJ6ob1x+pDyyvs61kXC36Iy21Qp/UUb3dTI9SWZOFrCc30VESMEO16zmsF1+a7BKJE0mGmo+jfVuSbZXjtadwktF4DnAtvsnt+/MRgg2oN2vj/JqYPzUV9BW5kbCxR6vj+JpomL6qHHhB7jZwLX3L6KtTv6zxndsRDnU/52KQyuy3PTW9d3hV3mB1QOQO+KNFtevviCcYhcn02mJ3HWXIN3/LuXRY8H1mTJ9ScZ2VQIUuWPR5bLQmy9ZQW77xvjm3+6m9JUg5/7lWvQdMGT3zvO4Scmoxh7UASr6sooC8PsIMXe4RROwwsSa2xcx8Nt+tgZEyklzUqb0Ec2F6iXW2y5aZjtQb6DqnbZjEIhFyJUuyf3zwHdg2NIuKFCX7VV2S1rd/bzxL1qI/fQPhoczXVFuICyXJp1l+psEynVIviKjT0Mb8izamtvRMhje2fJDyS7ZgchwkiXdEf5Ds0QXQNxmIiV708ifcl4UPbiYiAm9Bg/E7Bs44LJ/IVC0wS7Xr+m65iua9z50e0UhlJntZsArrtzlO23nn/i9fpdA6zfperdhN64tkTiV9/KDANrskwcLTO8Ic+aq4tRXZjZ07Wohgu0PfowiahToYeW2MypKpmCzX1/tYexPbP84h/chPRUHfOQ0G+4a22U5xAiU0gwfrhdmGshwvDXZs2lMJTqyo1IZk10Q+Pwk1NU55tkg1DAm39+PZmeBA9+9UDXALAQZtLAqXvRgmq2aGOnTX7+N64DVKYtApCweltx0XOEm9J3KnQhBIapdSyK6sFrU9Gepp3RQsuJmNBjxHiREZYjOBdMS+9SwxeCdE+CW9+9iZVbepd8zVWvGmHir/bw8jevj6pg5vuTzE/WI/8clOUC7eSbrt2qAgvp2DMz5PtT7H9kHClh749PMRAo4k5/fCHCz1lKoWu6htAE0pdnKGwhBDfcvZYff+2gisoJLBghBDvuWMXWW4bP2n9hVFSYsLTQTtN0jVTWolZqsXrb4v0Yhi529heo9Y1QmYe1b/L9yajMbmW2uajif6GICT1GjCsUV59D3W+9eZiRTT3k+9vEMjCaCwi9rTjtQKGH3m8nSSazFltvHmb3fWPMnKwgdEFPf4rHv3NcbQOZNs86gG29eZhk1jwr8eqmhtv0GFyXP+O5Xa9bw+BojifuPRZZLiHOtj4B7RDTcLEzWzhzfSTdk6BRc1ixqWfRc/QMpcj1J8+YCRRH0lGI5MrNBdbv6ic/kKQW1IapzDZiQo8RI8byQQjRReagvOb9j4x3xemH0TMh8S0Mo7z5bRs48tQUx5+bZestw6zeVuSf//xpSpN1Xvfhq5aMIAIVHXQuK8wwAkIfXdw+GdlUYGTThWVah5+tGxpHdk+R7klEfn33uXsoBgXrFoNp6bz3Ezedcfwtv74rejywJscbPqL28w2V/MWKRY8JPUaMGBFCpZkrdhB6ENVx6sA8q6/qZWhdN7HaaZPb7tnCA3+7j2tfu5r8QIr+1VmKI2k2Xn9mtdALhW4oT7rT118ODG/o4YP/6RUcfWa6K3KlE4uVyngh6Ay1vBiICT1GjBgRBtfmeP0vXc3oNW2bJBEUIesZSvH6X7p60ciZddf2s3ZnXxSR8/bfvn7Jgl0XCt3U6F+TXTJi54XAShrLMuicLwxLZ832IqmOWPblhLjQPfmWC9dff7189NG4SkCMGC8FjB8pke9PvqAwzueL5x48RaaQYNXWpRd4f5YghPiplPL6xZ6LFXqMGDHOiaX86xcDC8snx1gacep/jBgxYlwhiAk9RowYMa4QxIQeI0aMGFcIYkKPESNGjCsEMaHHiBEjxhWCmNBjxIgR4wpBTOgxYsSIcYUgJvQYMWLEuEJwyTJFhRCTwNHn8dY+YGqZm3OxELf14uCl1FZ4abU3buvFwXK2dY2Usn+xJy4ZoT9fCCEeXSrt9XJD3NaLg5dSW+Gl1d64rRcHL1ZbY8slRowYMa4QxIQeI0aMGFcIXoqE/rlL3YALQNzWi4OXUlvhpdXeuK0XBy9KW19yHnqMGDFixFgcL0WFHiNGjBgxFkFM6DFixIhxheAlQ+hCiDcIIfYKIQ4IIX77UrenE0KIVUKI+4QQzwkhnhFC/Ovg+MeFECeEEE8E/954qdsaQghxRAjxVNCuR4NjvUKIe4UQ+4P/L3zn3eVv5+aO/ntCCFESQvza5dK3Qoi/EEJMCCGe7ji2ZD8KIT4WXMN7hRCvvwza+p+EEHuEELuFEF8TQvQEx0eFEPWO/v3Mi9nWs7R3yd/9MuzbL3e084gQ4ong+MXrWynlZf8P0IGDwDrAAp4Etl3qdnW0bxjYFTzOAvuAbcDHgd+41O1bos1HgL4Fxz4J/Hbw+LeBP7rU7VzkOjgNrLlc+hZ4FbALePpc/RhcE08CCWBtcE3rl7itrwOM4PEfdbR1tPN1l1HfLvq7X459u+D5TwG/d7H79qWi0G8ADkgpD0kpW8CXgDdf4jZFkFKeklI+FjwuA88BI5e2Vc8Lbwb+Mnj8l8BbLl1TFsUdwEEp5fPJML4okFL+AJhZcHipfnwz8CUpZVNKeRg4gLq2XxQs1lYp5bellG7w50PAyherPefCEn27FC67vg0h1M7Z7wD+5mK346VC6CPA8Y6/x7hMCVMIMQpcC/wkOPSrwXT2Ly4HC6MDEvi2EOKnQoiPBMcGpZSnQA1SwMAla93ieBfdN8Xl2rdL9ePlfh1/EPinjr/XCiEeF0LcL4R45aVq1CJY7He/nPv2lcC4lHJ/x7GL0rcvFUIXixy77OIthRAZ4O+AX5NSloA/A9YDO4FTqGnX5YJbpJS7gDuBXxFCvOpSN+hsEEJYwN3AV4JDl3PfLoXL9joWQvwO4AJfDA6dAlZLKa8Ffh34ayHEpdspuo2lfvfLtm+Bd9MtRC5a375UCH0MWNXx90rg5CVqy6IQQpgoMv+ilPKrAFLKcSmlJ6X0gT/nRZwCngtSypPB/xPA11BtGxdCDAME/09cuhaegTuBx6SU43B59y1L9+NleR0LId4P3AW8RwYmb2BdTAePf4rypDddulYqnOV3v1z71gB+HvhyeOxi9u1LhdAfATYKIdYGSu1dwNcvcZsiBB7Z54HnpJT/peP4cMfL3go8vfC9lwJCiLQQIhs+Ri2MPY3q0/cHL3s/8PeXpoWLokvlXK59G2Cpfvw68C4hREIIsRbYCDx8CdoXQQjxBuC3gLullLWO4/1CCD14vA7V1kOXppVtnOV3v+z6NsBrgD1SyrHwwEXt2xdrFXgZVpHfiIoeOQj8zqVuz4K2vQI1vdsNPBH8eyPwV8BTwfGvA8OXuq1Be9ehIgKeBJ4J+xMoAt8F9gf/917qtgbtSgHTQL7j2GXRt6hB5hTgoFTih87Wj8DvBNfwXuDOy6CtB1Dec3jdfiZ47duCa+NJ4DHgTZdJ3y75u19ufRsc/5/ARxe89qL1bZz6HyNGjBhXCF4qlkuMGDFixDgHYkKPESNGjCsEMaHHiBEjxhWCmNBjxIgR4wpBTOgxYsSIcYUgJvQYMZ4HhBC3CSG+canbESNGJ2JCjxEjRowrBDGhx7iiIYT4RSHEw0Hd6c8KIXQhREUI8SkhxGNCiO8KIfqD1+4UQjzUURu8EBzfIIT4jhDiyeA964PTZ4QQ/zuoJ/7FIGM4RoxLhpjQY1yxEEJsBd6JKkS2E/CA9wBpVF2YXcD9wO8Hb/lfwG9JKa9BZSOGx78I/ImUcgdwMyojEFRVzV9D1eJeB9xykb9SjBhnhXGpGxAjxkXEHcB1wCOBeE6iCmX5tIslfQH4qhAiD/RIKe8Pjv8l8JWg5s2IlPJrAFLKBkBwvodlUKMj2I1mFPjhRf9WMWIsgZjQY1zJEMBfSik/1nVQiN9d8Lqz1b84m43S7HjsEd9PMS4xYsslxpWM7wJvF0IMQLTX5xrUdf/24DX3AD+UUs4Dsx2bDbwXuF+quvZjQoi3BOdICCFSL+aXiBHjfBErihhXLKSUzwoh/h/UzkwaqhLerwBV4CohxE+BeZTPDqrU7WcCwj4EfCA4/l7gs0KIfx+c4xdexK8RI8Z5I662GONnDkKIipQyc6nbESPGciO2XGLEiBHjCkGs0GPEiBHjCkGs0GPEiBHjCkFM6DFixIhxhSAm9BgxYsS4QhATeowYMWJcIYgJPUaMGDGuEPz/dsGAweHZ4YUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "folds = 10\n",
    "for fold in range(folds):\n",
    "    train_loss_arr = []\n",
    "    test_loss_arr = []\n",
    "    for res in results[fold]:\n",
    "        train_loss_arr.append(res[1])\n",
    "        test_loss_arr.append(res[2])\n",
    "    \n",
    "    print(len(train_loss_arr))\n",
    "    print(len(test_loss_arr))\n",
    "    ax = plt.subplot(1,1,1)\n",
    "    \n",
    "    ax.WindowState = 'maximized';\n",
    "\n",
    "    format_mae = \"{:.2f}\".format(best_rmse_arr[fold])\n",
    "    \n",
    "  #  ax.plot([e for e in range(1,len(train_loss_arr) + 1)], train_loss_arr, label=\"train_loss\")\n",
    "    ax.plot([e for e in range(1,len(test_loss_arr) + 1)],\n",
    "            test_loss_arr, label=\"Fold \" + str(fold) + \" (RMSE = \" + format_mae + \")\")\n",
    "    plt.xlabel(\"epoch\")\n",
    "    ax.title.set_text('10-Fold Validation')\n",
    "    ax.legend()\n",
    "    ax.figure.savefig('Visualization/'+str(fold)+'.png')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# 10 fold cross validation set results. Calculating pearson relations.\n",
    "from sklearn import model_selection, preprocessing, metrics, decomposition\n",
    "import matplotlib.pyplot as plt\n",
    "folds = 10\n",
    "results = []\n",
    "best_rmse_arr = []\n",
    "bestrmsesum = 0\n",
    "scores = []\n",
    "true_val = []\n",
    "pred_val = []\n",
    "# fig = plt.figure()\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "fig.suptitle('R2 and RMSE')\n",
    "# ax1.plot(x, y)\n",
    "# ax2.plot(x, -y)\n",
    "for fold in tqdm(range(folds)):\n",
    "    val_losses = []\n",
    "    train_losses = []\n",
    "    mae_arr = []\n",
    "    patience = 30\n",
    "    trigger_times = 0\n",
    "    the_last_loss = 100\n",
    "    test_data = Molecule_data(root='data', dataset='test_data_set_fold_'+str(fold),y=None,smile_graph=None,smiles=None)\n",
    "    \n",
    "    TRAIN_BATCH_SIZE = 40\n",
    "    test_loader  = DataLoader(test_data,batch_size=TRAIN_BATCH_SIZE,shuffle=True)\n",
    "    model = AttentionConvNet().to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=10**-2.5,\n",
    "                             weight_decay=10**-5)\n",
    "    model_file_name = 'saved_models/model_' +  str(fold) +  '.model'\n",
    "#     result_file_name = 'novelresult_' + str(fold) +  '.csv'\n",
    "    checkpoint = torch.load(model_file_name, map_location=torch.device(device))\n",
    "    model.load_state_dict(checkpoint)\n",
    "#     model.load_state_dict(torch.load(model_file_name))\n",
    "    \n",
    "    test_loss,test_rmse, true, prediction = predicting(test_loader, model)\n",
    "    \n",
    "    best_ret = []\n",
    "    bestrmsesum = bestrmsesum + test_rmse\n",
    "    results.append(best_ret)\n",
    "    best_rmse_arr.append(best_rmse)\n",
    "    true_val.append(true)\n",
    "    pred_val.append(prediction)\n",
    "    score = metrics.r2_score(true, prediction)\n",
    "    scores.append(score)\n",
    "    print('Test R2: ', score)\n",
    "    print('Test RMSE: ', test_rmse)\n",
    "    ax1.scatter(prediction, true, lw=2, alpha=0.5, \n",
    "                label='Fold %d (R2 = %0.2f)' % (fold+1,score))\n",
    "ax1.plot([min(prediction),max(true)], [min(prediction),max(true)], \n",
    "         linestyle='--', lw=2, color='black')\n",
    "ax1.xlabel('True')\n",
    "ax1.ylabel('Predicted')\n",
    "ax1.title('10-Fold Validation')\n",
    "ax1.legend()\n",
    "ax1.savefig('TestR2.png')\n",
    "# plt.show()\n",
    "# avg = bestrmsesum/10\n",
    "# print('10 fold avg is : ', avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# whole data set as training dataset\n",
    "def createTestData(path,filename,datasetname):\n",
    "    iy = 0\n",
    "#     folds = 10\n",
    "#     for fold in tqdm(range(folds)):\n",
    "#     df_train = pd.read_csv('New_fold/fold_'+str(iy)+'_'+'x_train.csv')\n",
    "#     df_test  = pd.read_csv('New_fold/fold_'+str(iy)+'_'+'x_test.csv')\n",
    "#     smiles = df_train['SMILES']\n",
    "#         codIds = df_train['CODID']\n",
    "#     solubility = df_train['logS']\n",
    "#     solubility = solubility.to_numpy()\n",
    "    df_test = pd.read_csv(path + '/' + filename)\n",
    "#     df_test  = pd.read_csv('New_fold/testset_novel.csv')\n",
    "    smiles_test = df_test['SMILES']\n",
    "#         codIds_test = df_test['CODID']\n",
    "    solubility_test = df_test['logS']\n",
    "    solubility_test = solubility_test.to_numpy()\n",
    "\n",
    "\n",
    "#     smile_graph = {}\n",
    "#     solubility_arr = []\n",
    "#     smiles_array = []\n",
    "    smile_graph_test = {}\n",
    "    solubility_arr_test = []\n",
    "    smiles_array_test = []\n",
    "\n",
    "    for i,smile in enumerate(smiles_test):\n",
    "        g = gd.smile_to_graph(smile)\n",
    "        if g != None:\n",
    "            smile_graph_test[smile] = g\n",
    "            solubility_arr_test.append(smiles_test[i])\n",
    "            smiles_array_test.append(smile)\n",
    "\n",
    "#     train_data = Molecule_data(root='data', dataset='train_data_set_fold_'+str(iy),y=band_gap_arr,\n",
    "#                                smile_graph=smile_graph,smiles=smiles_array)\n",
    "\n",
    "    noveltest_data = Molecule_data(root='data', dataset=datasetname,y=solubility_test,\n",
    "                               smile_graph=smile_graph_test,smiles=smiles_array_test)\n",
    "    return noveltest_data\n",
    "#     iy+=1"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "noveltest_data = createTestData('New_fold','testset_novel.csv','testset_novel')\n",
    "# noveltest_data = Molecule_data(root='data', dataset='testset_novel',y=None,smile_graph=None,smiles=None)\n",
    "noveltest_loader  = DataLoader(noveltest_data,batch_size=TRAIN_BATCH_SIZE,shuffle=True)\n",
    "#     model = AttentiveFP(in_channels=112, hidden_channels=279, out_channels=1,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def predicting(loader, model):\n",
    "    total_preds = torch.Tensor()\n",
    "    total_labels = torch.Tensor()\n",
    "    total_loss = total_examples = 0\n",
    "    for data in loader:\n",
    "        data = data.to(device)\n",
    "        out = model(data)\n",
    "        # out = model(data)\n",
    "        # mse.append(F.mse_loss(out, data.y, reduction='none').cpu())\n",
    "        # return float(torch.cat(mse, dim=0).mean().sqrt())\n",
    "        y = data.y.view([-1])\n",
    "        out1 = out.view([-1])\n",
    "        # print(\"test : \", y.shape)\n",
    "        test_loss = F.mse_loss(out1, y)\n",
    "        # print(\"no of graphs: \", data.num_graphs)\n",
    "        total_loss += float(test_loss) * data.num_graphs\n",
    "        total_examples += data.num_graphs\n",
    "        total_preds = torch.cat((total_preds, out.view(-1, 1).cpu()), 0)\n",
    "        total_labels = torch.cat((total_labels, data.y.view(-1, 1).cpu()), 0)\n",
    "#         print(\"total_labels : \", total_labels.shape)\n",
    "#         print(\"total_preds : \", total_preds.shape)\n",
    "        # mse.append(test_loss).cpu()\n",
    "    # return test_loss,float(torch.cat(mse, dim=0).mean().sqrt())\n",
    "    return total_loss,sqrt(total_loss / total_examples),total_labels.numpy().flatten(),total_preds.numpy().flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35281e23fce84bee9262a83232ab0428",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test R2:  0.6574429672822961\n",
      "Test RMSE:  1.303948737260316\n",
      "Test R2:  0.6015885744767353\n",
      "Test RMSE:  1.4046734405309862\n",
      "Test R2:  0.6455395478824696\n",
      "Test RMSE:  1.301445075731461\n",
      "Test R2:  0.6293370043046664\n",
      "Test RMSE:  1.2980245217580573\n",
      "Test R2:  0.7054230536687284\n",
      "Test RMSE:  1.1758533456368179\n",
      "Test R2:  0.5285370028568857\n",
      "Test RMSE:  1.4954343260041718\n",
      "Test R2:  0.6425186935951372\n",
      "Test RMSE:  1.3198057209459249\n",
      "Test R2:  0.6359658219169131\n",
      "Test RMSE:  1.3612499651639005\n",
      "Test R2:  0.6950136096852224\n",
      "Test RMSE:  1.200597803169813\n",
      "Test R2:  0.6978540125148618\n",
      "Test RMSE:  1.2663308520184056\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 10 fold cross validation set results. Calculating pearson correlations.\n",
    "from sklearn import model_selection, preprocessing, metrics, decomposition\n",
    "import matplotlib.pyplot as plt\n",
    "folds = 10\n",
    "results = []\n",
    "best_rmse_arr = []\n",
    "bestrmsesum = 0\n",
    "scores = []\n",
    "true_val = []\n",
    "pred_val = []\n",
    "fig = plt.figure()\n",
    "for fold in tqdm(range(folds)):\n",
    "    val_losses = []\n",
    "    train_losses = []\n",
    "    mae_arr = []\n",
    "    patience = 30\n",
    "    trigger_times = 0\n",
    "    the_last_loss = 100\n",
    "    test_data = Molecule_data(root='data', dataset='test_data_set_fold_'+str(fold),y=None,smile_graph=None,smiles=None)\n",
    "    \n",
    "#     TRAIN_BATCH_SIZE = 40\n",
    "    test_loader  = DataLoader(test_data,batch_size=TRAIN_BATCH_SIZE,shuffle=True)\n",
    "    model = AttentionConvNet().to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate,\n",
    "                             weight_decay=weight_decay)\n",
    "    model_file_name = 'saved_models/model_' +  str(fold) +  '.model'\n",
    "#     result_file_name = 'novelresult_' + str(fold) +  '.csv'\n",
    "    checkpoint = torch.load(model_file_name, map_location=torch.device(device))\n",
    "    model.load_state_dict(checkpoint)\n",
    "#     model.load_state_dict(torch.load(model_file_name))\n",
    "    \n",
    "    test_loss,test_rmse, true, prediction = predicting(test_loader, model)\n",
    "    \n",
    "    best_ret = []\n",
    "    bestrmsesum = bestrmsesum + test_rmse\n",
    "    results.append(best_ret)\n",
    "    best_rmse_arr.append(best_rmse)\n",
    "    true_val.append(true)\n",
    "    pred_val.append(prediction)\n",
    "    score = metrics.r2_score(true, prediction)\n",
    "    scores.append(score)\n",
    "    print('Test R2: ', score)\n",
    "    print('Test RMSE: ', test_rmse)\n",
    "    plt.scatter(prediction, true, lw=2, alpha=0.5, \n",
    "                label='Fold %d (R2 = %0.2f)' % (fold+1,score))\n",
    "plt.plot([min(prediction),max(true)], [min(prediction),max(true)], \n",
    "         linestyle='--', lw=2, color='black')\n",
    "plt.xlabel('True')\n",
    "plt.ylabel('Predicted')\n",
    "plt.title('10-Fold Validation')\n",
    "plt.legend()\n",
    "plt.savefig('TestR2.png')\n",
    "plt.show()\n",
    "# avg = bestrmsesum/10\n",
    "# print('10 fold avg is : ', avg)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Train whole dataset\n",
    "wholemodel_file_name = 'saved_models/wholemodel.model'\n",
    "wholetrain_data = createTestData('Data_Prep','solubility_1.csv','solubility_1')\n",
    "# noveltest_data = Molecule_data(root='data', dataset='testset_novel',y=None,smile_graph=None,smiles=None)\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "        wholetrain_loader  = DataLoader(wholetrain_data,batch_size=TRAIN_BATCH_SIZE,shuffle=True)\n",
    "#     model = AttentiveFP(in_channels=112, hidden_channels=279, out_channels=1,\n",
    "        model = AttentionConvNet().to(device)\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=10**-2.5,\n",
    "                                     weight_decay=10**-5)\n",
    "        model_file_name = 'saved_models/model_' +  str(5) +  '.model'\n",
    "        result_file_name = 'wholeresult.csv'\n",
    "        checkpoint = torch.load(model_file_name, map_location=torch.device(device))\n",
    "        model.load_state_dict(checkpoint)\n",
    "        scores = []\n",
    "        true_val = []\n",
    "        pred_val = []\n",
    "        the_last_loss = 100\n",
    "        train_loss,train_rmse=train(model, optimizer,wholetrain_loader)\n",
    "#         test_loss,test_rmse, true, prediction = predicting(noveltest_loader, model)\n",
    "#         true_val.append(true)\n",
    "#         pred_val.append(prediction)\n",
    "#         score = metrics.r2_score(true, prediction)\n",
    "        print(f'Epoch: {epoch:03d}, Loss: {train_rmse:.4f} ') # f'Test: {test_rmse:.4f} ' f'R2: {score:.4f}'\n",
    "        \n",
    "#         ret = [epoch,train_rmse,test_rmse,score]\n",
    "        \n",
    "        train_losses.append(train_rmse)\n",
    "#         val_losses.append(test_rmse)\n",
    "        # Early Stopping\n",
    "        the_current_loss = train_rmse   #.item()\n",
    "#         best_ret.append(ret)\n",
    "        if the_current_loss > the_last_loss:\n",
    "            trigger_times += 1\n",
    "            print('trigger times:', trigger_times)\n",
    "    \n",
    "            if trigger_times >= patience:\n",
    "                print('Early stopping!\\nStart to test process.')\n",
    "                break\n",
    "        else:\n",
    "#             ret = [epoch,train_rmse,test_rmse]\n",
    "            trigger_times = 0\n",
    "            the_last_loss = the_current_loss\n",
    "            best_rmse = the_current_loss\n",
    "            \n",
    "torch.save(model.state_dict(), wholemodel_file_name)            "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# testing on whole dataset trained model \n",
    "from sklearn import model_selection, preprocessing, metrics, decomposition\n",
    "import matplotlib.pyplot as plt\n",
    "folds = 10\n",
    "results = []\n",
    "best_rmse_arr = []\n",
    "bestrmsesum = 0\n",
    "scores = []\n",
    "true_val = []\n",
    "pred_val = []\n",
    "# fig = plt.figure()\n",
    "# for fold in tqdm(range(folds)):\n",
    "# val_losses = []\n",
    "# train_losses = []\n",
    "# mae_arr = []\n",
    "# patience = 30\n",
    "# trigger_times = 0\n",
    "# the_last_loss = 100\n",
    "model = AttentionConvNet().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=10**-2.5,\n",
    "                             weight_decay=10**-5)\n",
    "model_file_name = 'saved_models/wholemodel.model'\n",
    "result_file_name = 'wholetrained_novelresult_' + str(fold) +  '.csv'\n",
    "checkpoint = torch.load(model_file_name, map_location=torch.device(device))\n",
    "model.load_state_dict(checkpoint)\n",
    "#     model.load_state_dict(torch.load(model_file_name))\n",
    "\n",
    "test_loss,test_rmse, true, prediction = predicting(noveltest_loader, model)\n",
    "\n",
    "best_ret = []\n",
    "bestrmsesum = bestrmsesum + test_rmse\n",
    "results.append(best_ret)\n",
    "best_rmse_arr.append(best_rmse)\n",
    "true_val.append(true)\n",
    "pred_val.append(prediction)\n",
    "score = metrics.r2_score(true, prediction)\n",
    "scores.append(score)\n",
    "print('Test R2: ', score)\n",
    "print('Test RMSE:', test_rmse)\n",
    "#     plt.scatter(prediction, true, lw=2, alpha=0.5, \n",
    "#                 label='Fold %d (R2 = %0.2f)' % (fold+1,score))\n",
    "# plt.plot([min(prediction),max(true)], [min(prediction),max(true)], \n",
    "#          linestyle='--', lw=2, color='black')\n",
    "# plt.xlabel('True')\n",
    "# plt.ylabel('Predicted')\n",
    "# plt.title('Model Validation')\n",
    "# plt.legend()\n",
    "# plt.savefig('WholeTestR2.png')\n",
    "# plt.show()\n",
    "# avg = bestrmsesum/10\n",
    "# print('10 fold avg is : ', avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "858b70d7143e491fbc6f57083e14befc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 1.3986 \n",
      "Epoch: 001, Loss: 1.3735 \n",
      "Epoch: 002, Loss: 1.3771 \n",
      "trigger times: 1\n",
      "Epoch: 003, Loss: 1.3858 \n",
      "trigger times: 2\n",
      "Epoch: 004, Loss: 1.3917 \n",
      "trigger times: 3\n",
      "Epoch: 005, Loss: 1.3790 \n",
      "trigger times: 4\n",
      "Epoch: 006, Loss: 1.3566 \n",
      "Epoch: 007, Loss: 1.3635 \n",
      "trigger times: 1\n",
      "Epoch: 008, Loss: 1.3841 \n",
      "trigger times: 2\n",
      "Epoch: 009, Loss: 1.3653 \n",
      "trigger times: 3\n",
      "Epoch: 010, Loss: 1.3878 \n",
      "trigger times: 4\n",
      "Epoch: 011, Loss: 1.3732 \n",
      "trigger times: 5\n",
      "Epoch: 012, Loss: 1.3607 \n",
      "trigger times: 6\n",
      "Epoch: 013, Loss: 1.3641 \n",
      "trigger times: 7\n",
      "Epoch: 014, Loss: 1.3682 \n",
      "trigger times: 8\n",
      "Epoch: 015, Loss: 1.3875 \n",
      "trigger times: 9\n",
      "Epoch: 016, Loss: 1.3755 \n",
      "trigger times: 10\n",
      "Epoch: 017, Loss: 1.3715 \n",
      "trigger times: 11\n",
      "Epoch: 018, Loss: 1.3591 \n",
      "trigger times: 12\n",
      "Epoch: 019, Loss: 1.3742 \n",
      "trigger times: 13\n",
      "Epoch: 020, Loss: 1.3645 \n",
      "trigger times: 14\n",
      "Epoch: 021, Loss: 1.3696 \n",
      "trigger times: 15\n",
      "Epoch: 022, Loss: 1.3608 \n",
      "trigger times: 16\n",
      "Epoch: 023, Loss: 1.3681 \n",
      "trigger times: 17\n",
      "Epoch: 024, Loss: 1.3697 \n",
      "trigger times: 18\n",
      "Epoch: 025, Loss: 1.3634 \n",
      "trigger times: 19\n",
      "Epoch: 026, Loss: 1.3674 \n",
      "trigger times: 20\n",
      "Epoch: 027, Loss: 1.3797 \n",
      "trigger times: 21\n",
      "Epoch: 028, Loss: 1.3611 \n",
      "trigger times: 22\n",
      "Epoch: 029, Loss: 1.3832 \n",
      "trigger times: 23\n",
      "Epoch: 030, Loss: 1.3589 \n",
      "trigger times: 24\n",
      "Epoch: 031, Loss: 1.3757 \n",
      "trigger times: 25\n",
      "Epoch: 032, Loss: 1.3792 \n",
      "trigger times: 26\n",
      "Epoch: 033, Loss: 1.3720 \n",
      "trigger times: 27\n",
      "Epoch: 034, Loss: 1.3695 \n",
      "trigger times: 28\n",
      "Epoch: 035, Loss: 1.3677 \n",
      "trigger times: 29\n",
      "Epoch: 036, Loss: 1.3629 \n",
      "trigger times: 30\n",
      "Epoch: 037, Loss: 1.3516 \n",
      "Epoch: 038, Loss: 1.3759 \n",
      "trigger times: 1\n",
      "Epoch: 039, Loss: 1.3578 \n",
      "trigger times: 2\n",
      "Epoch: 040, Loss: 1.3603 \n",
      "trigger times: 3\n",
      "Epoch: 041, Loss: 1.3614 \n",
      "trigger times: 4\n",
      "Epoch: 042, Loss: 1.3616 \n",
      "trigger times: 5\n",
      "Epoch: 043, Loss: 1.3691 \n",
      "trigger times: 6\n",
      "Epoch: 044, Loss: 1.3615 \n",
      "trigger times: 7\n",
      "Epoch: 045, Loss: 1.3917 \n",
      "trigger times: 8\n",
      "Epoch: 046, Loss: 1.3612 \n",
      "trigger times: 9\n",
      "Epoch: 047, Loss: 1.3619 \n",
      "trigger times: 10\n",
      "Epoch: 048, Loss: 1.3627 \n",
      "trigger times: 11\n",
      "Epoch: 049, Loss: 1.3714 \n",
      "trigger times: 12\n",
      "Epoch: 050, Loss: 1.3696 \n",
      "trigger times: 13\n",
      "Epoch: 051, Loss: 1.3727 \n",
      "trigger times: 14\n",
      "Epoch: 052, Loss: 1.3622 \n",
      "trigger times: 15\n",
      "Epoch: 053, Loss: 1.3857 \n",
      "trigger times: 16\n",
      "Epoch: 054, Loss: 1.3706 \n",
      "trigger times: 17\n",
      "Epoch: 055, Loss: 1.3663 \n",
      "trigger times: 18\n",
      "Epoch: 056, Loss: 1.3904 \n",
      "trigger times: 19\n",
      "Epoch: 057, Loss: 1.3880 \n",
      "trigger times: 20\n",
      "Epoch: 058, Loss: 1.3849 \n",
      "trigger times: 21\n",
      "Epoch: 059, Loss: 1.3454 \n",
      "Epoch: 060, Loss: 1.3736 \n",
      "trigger times: 1\n",
      "Epoch: 061, Loss: 1.3618 \n",
      "trigger times: 2\n",
      "Epoch: 062, Loss: 1.3720 \n",
      "trigger times: 3\n",
      "Epoch: 063, Loss: 1.3520 \n",
      "trigger times: 4\n",
      "Epoch: 064, Loss: 1.3724 \n",
      "trigger times: 5\n",
      "Epoch: 065, Loss: 1.3727 \n",
      "trigger times: 6\n",
      "Epoch: 066, Loss: 1.3813 \n",
      "trigger times: 7\n",
      "Epoch: 067, Loss: 1.3728 \n",
      "trigger times: 8\n",
      "Epoch: 068, Loss: 1.3426 \n",
      "Epoch: 069, Loss: 1.3476 \n",
      "trigger times: 1\n",
      "Epoch: 070, Loss: 1.3722 \n",
      "trigger times: 2\n",
      "Epoch: 071, Loss: 1.3775 \n",
      "trigger times: 3\n",
      "Epoch: 072, Loss: 1.3966 \n",
      "trigger times: 4\n",
      "Epoch: 073, Loss: 1.3480 \n",
      "trigger times: 5\n",
      "Epoch: 074, Loss: 1.3492 \n",
      "trigger times: 6\n",
      "Epoch: 075, Loss: 1.3609 \n",
      "trigger times: 7\n",
      "Epoch: 076, Loss: 1.3583 \n",
      "trigger times: 8\n",
      "Epoch: 077, Loss: 1.3820 \n",
      "trigger times: 9\n",
      "Epoch: 078, Loss: 1.3379 \n",
      "Epoch: 079, Loss: 1.3685 \n",
      "trigger times: 1\n",
      "Epoch: 080, Loss: 1.3578 \n",
      "trigger times: 2\n",
      "Epoch: 081, Loss: 1.3647 \n",
      "trigger times: 3\n",
      "Epoch: 082, Loss: 1.3533 \n",
      "trigger times: 4\n",
      "Epoch: 083, Loss: 1.3723 \n",
      "trigger times: 5\n",
      "Epoch: 084, Loss: 1.3609 \n",
      "trigger times: 6\n",
      "Epoch: 085, Loss: 1.3526 \n",
      "trigger times: 7\n",
      "Epoch: 086, Loss: 1.4018 \n",
      "trigger times: 8\n",
      "Epoch: 087, Loss: 1.3571 \n",
      "trigger times: 9\n",
      "Epoch: 088, Loss: 1.3619 \n",
      "trigger times: 10\n",
      "Epoch: 089, Loss: 1.3507 \n",
      "trigger times: 11\n",
      "Epoch: 090, Loss: 1.3605 \n",
      "trigger times: 12\n",
      "Epoch: 091, Loss: 1.3761 \n",
      "trigger times: 13\n",
      "Epoch: 092, Loss: 1.3711 \n",
      "trigger times: 14\n",
      "Epoch: 093, Loss: 1.3523 \n",
      "trigger times: 15\n",
      "Epoch: 094, Loss: 1.3833 \n",
      "trigger times: 16\n",
      "Epoch: 095, Loss: 1.3580 \n",
      "trigger times: 17\n",
      "Epoch: 096, Loss: 1.3590 \n",
      "trigger times: 18\n",
      "Epoch: 097, Loss: 1.3625 \n",
      "trigger times: 19\n",
      "Epoch: 098, Loss: 1.3750 \n",
      "trigger times: 20\n",
      "Epoch: 099, Loss: 1.3845 \n",
      "trigger times: 21\n",
      "Epoch: 100, Loss: 1.3627 \n",
      "trigger times: 22\n",
      "Epoch: 101, Loss: 1.3831 \n",
      "trigger times: 23\n",
      "Epoch: 102, Loss: 1.3734 \n",
      "trigger times: 24\n",
      "Epoch: 103, Loss: 1.3761 \n",
      "trigger times: 25\n",
      "Epoch: 104, Loss: 1.3582 \n",
      "trigger times: 26\n",
      "Epoch: 105, Loss: 1.3780 \n",
      "trigger times: 27\n",
      "Epoch: 106, Loss: 1.3635 \n",
      "trigger times: 28\n",
      "Epoch: 107, Loss: 1.3644 \n",
      "trigger times: 29\n",
      "Epoch: 108, Loss: 1.3433 \n",
      "trigger times: 30\n",
      "Epoch: 109, Loss: 1.3583 \n",
      "trigger times: 31\n",
      "Epoch: 110, Loss: 1.3486 \n",
      "trigger times: 32\n",
      "Epoch: 111, Loss: 1.3749 \n",
      "trigger times: 33\n",
      "Epoch: 112, Loss: 1.3851 \n",
      "trigger times: 34\n",
      "Epoch: 113, Loss: 1.3546 \n",
      "trigger times: 35\n",
      "Epoch: 114, Loss: 1.3664 \n",
      "trigger times: 36\n",
      "Epoch: 115, Loss: 1.3875 \n",
      "trigger times: 37\n",
      "Epoch: 116, Loss: 1.3670 \n",
      "trigger times: 38\n",
      "Epoch: 117, Loss: 1.3490 \n",
      "trigger times: 39\n",
      "Epoch: 118, Loss: 1.3678 \n",
      "trigger times: 40\n",
      "Epoch: 119, Loss: 1.3610 \n",
      "trigger times: 41\n",
      "Epoch: 120, Loss: 1.3613 \n",
      "trigger times: 42\n",
      "Epoch: 121, Loss: 1.3735 \n",
      "trigger times: 43\n",
      "Epoch: 122, Loss: 1.3795 \n",
      "trigger times: 44\n",
      "Epoch: 123, Loss: 1.3599 \n",
      "trigger times: 45\n",
      "Epoch: 124, Loss: 1.3699 \n",
      "trigger times: 46\n",
      "Epoch: 125, Loss: 1.3744 \n",
      "trigger times: 47\n",
      "Epoch: 126, Loss: 1.3802 \n",
      "trigger times: 48\n",
      "Epoch: 127, Loss: 1.3545 \n",
      "trigger times: 49\n",
      "Epoch: 128, Loss: 1.3621 \n",
      "trigger times: 50\n",
      "Epoch: 129, Loss: 1.3697 \n",
      "trigger times: 51\n",
      "Epoch: 130, Loss: 1.3517 \n",
      "trigger times: 52\n",
      "Epoch: 131, Loss: 1.3635 \n",
      "trigger times: 53\n",
      "Epoch: 132, Loss: 1.3615 \n",
      "trigger times: 54\n",
      "Epoch: 133, Loss: 1.3738 \n",
      "trigger times: 55\n",
      "Epoch: 134, Loss: 1.3972 \n",
      "trigger times: 56\n",
      "Epoch: 135, Loss: 1.3700 \n",
      "trigger times: 57\n",
      "Epoch: 136, Loss: 1.3562 \n",
      "trigger times: 58\n",
      "Epoch: 137, Loss: 1.3737 \n",
      "trigger times: 59\n",
      "Epoch: 138, Loss: 1.3734 \n",
      "trigger times: 60\n",
      "Epoch: 139, Loss: 1.3462 \n",
      "trigger times: 61\n",
      "Epoch: 140, Loss: 1.3557 \n",
      "trigger times: 62\n",
      "Epoch: 141, Loss: 1.3462 \n",
      "trigger times: 63\n",
      "Epoch: 142, Loss: 1.3734 \n",
      "trigger times: 64\n",
      "Epoch: 143, Loss: 1.3501 \n",
      "trigger times: 65\n",
      "Epoch: 144, Loss: 1.3445 \n",
      "trigger times: 66\n",
      "Epoch: 145, Loss: 1.3588 \n",
      "trigger times: 67\n",
      "Epoch: 146, Loss: 1.3486 \n",
      "trigger times: 68\n",
      "Epoch: 147, Loss: 1.3741 \n",
      "trigger times: 69\n",
      "Epoch: 148, Loss: 1.3914 \n",
      "trigger times: 70\n",
      "Epoch: 149, Loss: 1.3667 \n",
      "trigger times: 71\n",
      "Epoch: 150, Loss: 1.3581 \n",
      "trigger times: 72\n",
      "Epoch: 151, Loss: 1.3601 \n",
      "trigger times: 73\n",
      "Epoch: 152, Loss: 1.3601 \n",
      "trigger times: 74\n",
      "Epoch: 153, Loss: 1.3951 \n",
      "trigger times: 75\n",
      "Epoch: 154, Loss: 1.3816 \n",
      "trigger times: 76\n",
      "Epoch: 155, Loss: 1.3631 \n",
      "trigger times: 77\n",
      "Epoch: 156, Loss: 1.3630 \n",
      "trigger times: 78\n",
      "Epoch: 157, Loss: 1.3727 \n",
      "trigger times: 79\n",
      "Epoch: 158, Loss: 1.3689 \n",
      "trigger times: 80\n",
      "Epoch: 159, Loss: 1.3711 \n",
      "trigger times: 81\n",
      "Epoch: 160, Loss: 1.3482 \n",
      "trigger times: 82\n",
      "Epoch: 161, Loss: 1.3562 \n",
      "trigger times: 83\n",
      "Epoch: 162, Loss: 1.3684 \n",
      "trigger times: 84\n",
      "Epoch: 163, Loss: 1.3588 \n",
      "trigger times: 85\n",
      "Epoch: 164, Loss: 1.3746 \n",
      "trigger times: 86\n",
      "Epoch: 165, Loss: 1.3563 \n",
      "trigger times: 87\n",
      "Epoch: 166, Loss: 1.4057 \n",
      "trigger times: 88\n",
      "Epoch: 167, Loss: 1.3675 \n",
      "trigger times: 89\n",
      "Epoch: 168, Loss: 1.3507 \n",
      "trigger times: 90\n",
      "Epoch: 169, Loss: 1.3576 \n",
      "trigger times: 91\n",
      "Epoch: 170, Loss: 1.3689 \n",
      "trigger times: 92\n",
      "Epoch: 171, Loss: 1.3774 \n",
      "trigger times: 93\n",
      "Epoch: 172, Loss: 1.3544 \n",
      "trigger times: 94\n",
      "Epoch: 173, Loss: 1.3761 \n",
      "trigger times: 95\n",
      "Epoch: 174, Loss: 1.3785 \n",
      "trigger times: 96\n",
      "Epoch: 175, Loss: 1.3747 \n",
      "trigger times: 97\n",
      "Epoch: 176, Loss: 1.3828 \n",
      "trigger times: 98\n",
      "Epoch: 177, Loss: 1.3586 \n",
      "trigger times: 99\n",
      "Epoch: 178, Loss: 1.3576 \n",
      "trigger times: 100\n",
      "Epoch: 179, Loss: 1.3896 \n",
      "trigger times: 101\n",
      "Epoch: 180, Loss: 1.3566 \n",
      "trigger times: 102\n",
      "Epoch: 181, Loss: 1.3652 \n",
      "trigger times: 103\n",
      "Epoch: 182, Loss: 1.3617 \n",
      "trigger times: 104\n",
      "Epoch: 183, Loss: 1.3432 \n",
      "trigger times: 105\n",
      "Epoch: 184, Loss: 1.3852 \n",
      "trigger times: 106\n",
      "Epoch: 185, Loss: 1.3849 \n",
      "trigger times: 107\n",
      "Epoch: 186, Loss: 1.3600 \n",
      "trigger times: 108\n",
      "Epoch: 187, Loss: 1.3552 \n",
      "trigger times: 109\n",
      "Epoch: 188, Loss: 1.3780 \n",
      "trigger times: 110\n",
      "Epoch: 189, Loss: 1.3495 \n",
      "trigger times: 111\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 190, Loss: 1.3557 \n",
      "trigger times: 112\n",
      "Epoch: 191, Loss: 1.3932 \n",
      "trigger times: 113\n",
      "Epoch: 192, Loss: 1.3570 \n",
      "trigger times: 114\n",
      "Epoch: 193, Loss: 1.3897 \n",
      "trigger times: 115\n",
      "Epoch: 194, Loss: 1.3758 \n",
      "trigger times: 116\n",
      "Epoch: 195, Loss: 1.3596 \n",
      "trigger times: 117\n",
      "Epoch: 196, Loss: 1.3641 \n",
      "trigger times: 118\n",
      "Epoch: 197, Loss: 1.3732 \n",
      "trigger times: 119\n",
      "Epoch: 198, Loss: 1.3604 \n",
      "trigger times: 120\n",
      "Epoch: 199, Loss: 1.3485 \n",
      "trigger times: 121\n",
      "Epoch: 000, Loss: 1.4065 \n",
      "Epoch: 001, Loss: 1.4049 \n",
      "Epoch: 002, Loss: 1.3778 \n",
      "Epoch: 003, Loss: 1.3877 \n",
      "trigger times: 1\n",
      "Epoch: 004, Loss: 1.3869 \n",
      "trigger times: 2\n",
      "Epoch: 005, Loss: 1.3841 \n",
      "trigger times: 3\n",
      "Epoch: 006, Loss: 1.3782 \n",
      "trigger times: 4\n",
      "Epoch: 007, Loss: 1.3873 \n",
      "trigger times: 5\n",
      "Epoch: 008, Loss: 1.3806 \n",
      "trigger times: 6\n",
      "Epoch: 009, Loss: 1.4065 \n",
      "trigger times: 7\n",
      "Epoch: 010, Loss: 1.3763 \n",
      "Epoch: 011, Loss: 1.3768 \n",
      "trigger times: 1\n",
      "Epoch: 012, Loss: 1.3628 \n",
      "Epoch: 013, Loss: 1.3821 \n",
      "trigger times: 1\n",
      "Epoch: 014, Loss: 1.3965 \n",
      "trigger times: 2\n",
      "Epoch: 015, Loss: 1.3890 \n",
      "trigger times: 3\n",
      "Epoch: 016, Loss: 1.3772 \n",
      "trigger times: 4\n",
      "Epoch: 017, Loss: 1.3847 \n",
      "trigger times: 5\n",
      "Epoch: 018, Loss: 1.4006 \n",
      "trigger times: 6\n",
      "Epoch: 019, Loss: 1.4225 \n",
      "trigger times: 7\n",
      "Epoch: 020, Loss: 1.3733 \n",
      "trigger times: 8\n",
      "Epoch: 021, Loss: 1.3971 \n",
      "trigger times: 9\n",
      "Epoch: 022, Loss: 1.3729 \n",
      "trigger times: 10\n",
      "Epoch: 023, Loss: 1.3807 \n",
      "trigger times: 11\n",
      "Epoch: 024, Loss: 1.3849 \n",
      "trigger times: 12\n",
      "Epoch: 025, Loss: 1.3869 \n",
      "trigger times: 13\n",
      "Epoch: 026, Loss: 1.3812 \n",
      "trigger times: 14\n",
      "Epoch: 027, Loss: 1.3851 \n",
      "trigger times: 15\n",
      "Epoch: 028, Loss: 1.3771 \n",
      "trigger times: 16\n",
      "Epoch: 029, Loss: 1.4040 \n",
      "trigger times: 17\n",
      "Epoch: 030, Loss: 1.3802 \n",
      "trigger times: 18\n",
      "Epoch: 031, Loss: 1.3936 \n",
      "trigger times: 19\n",
      "Epoch: 032, Loss: 1.3726 \n",
      "trigger times: 20\n",
      "Epoch: 033, Loss: 1.3790 \n",
      "trigger times: 21\n",
      "Epoch: 034, Loss: 1.3901 \n",
      "trigger times: 22\n",
      "Epoch: 035, Loss: 1.4063 \n",
      "trigger times: 23\n",
      "Epoch: 036, Loss: 1.3863 \n",
      "trigger times: 24\n",
      "Epoch: 037, Loss: 1.3866 \n",
      "trigger times: 25\n",
      "Epoch: 038, Loss: 1.3863 \n",
      "trigger times: 26\n",
      "Epoch: 039, Loss: 1.3966 \n",
      "trigger times: 27\n",
      "Epoch: 040, Loss: 1.4019 \n",
      "trigger times: 28\n",
      "Epoch: 041, Loss: 1.3767 \n",
      "trigger times: 29\n",
      "Epoch: 042, Loss: 1.3912 \n",
      "trigger times: 30\n",
      "Epoch: 043, Loss: 1.3886 \n",
      "trigger times: 31\n",
      "Epoch: 044, Loss: 1.3633 \n",
      "trigger times: 32\n",
      "Epoch: 045, Loss: 1.3889 \n",
      "trigger times: 33\n",
      "Epoch: 046, Loss: 1.4019 \n",
      "trigger times: 34\n",
      "Epoch: 047, Loss: 1.3918 \n",
      "trigger times: 35\n",
      "Epoch: 048, Loss: 1.3707 \n",
      "trigger times: 36\n",
      "Epoch: 049, Loss: 1.3798 \n",
      "trigger times: 37\n",
      "Epoch: 050, Loss: 1.3925 \n",
      "trigger times: 38\n",
      "Epoch: 051, Loss: 1.3957 \n",
      "trigger times: 39\n",
      "Epoch: 052, Loss: 1.4118 \n",
      "trigger times: 40\n",
      "Epoch: 053, Loss: 1.3778 \n",
      "trigger times: 41\n",
      "Epoch: 054, Loss: 1.3764 \n",
      "trigger times: 42\n",
      "Epoch: 055, Loss: 1.3891 \n",
      "trigger times: 43\n",
      "Epoch: 056, Loss: 1.3915 \n",
      "trigger times: 44\n",
      "Epoch: 057, Loss: 1.3889 \n",
      "trigger times: 45\n",
      "Epoch: 058, Loss: 1.3937 \n",
      "trigger times: 46\n",
      "Epoch: 059, Loss: 1.3954 \n",
      "trigger times: 47\n",
      "Epoch: 060, Loss: 1.3681 \n",
      "trigger times: 48\n",
      "Epoch: 061, Loss: 1.3754 \n",
      "trigger times: 49\n",
      "Epoch: 062, Loss: 1.3725 \n",
      "trigger times: 50\n",
      "Epoch: 063, Loss: 1.3718 \n",
      "trigger times: 51\n",
      "Epoch: 064, Loss: 1.3853 \n",
      "trigger times: 52\n",
      "Epoch: 065, Loss: 1.3782 \n",
      "trigger times: 53\n",
      "Epoch: 066, Loss: 1.3867 \n",
      "trigger times: 54\n",
      "Epoch: 067, Loss: 1.3770 \n",
      "trigger times: 55\n",
      "Epoch: 068, Loss: 1.3860 \n",
      "trigger times: 56\n",
      "Epoch: 069, Loss: 1.3922 \n",
      "trigger times: 57\n",
      "Epoch: 070, Loss: 1.4067 \n",
      "trigger times: 58\n",
      "Epoch: 071, Loss: 1.3829 \n",
      "trigger times: 59\n",
      "Epoch: 072, Loss: 1.4157 \n",
      "trigger times: 60\n",
      "Epoch: 073, Loss: 1.3894 \n",
      "trigger times: 61\n",
      "Epoch: 074, Loss: 1.4002 \n",
      "trigger times: 62\n",
      "Epoch: 075, Loss: 1.3768 \n",
      "trigger times: 63\n",
      "Epoch: 076, Loss: 1.3973 \n",
      "trigger times: 64\n",
      "Epoch: 077, Loss: 1.3999 \n",
      "trigger times: 65\n",
      "Epoch: 078, Loss: 1.3929 \n",
      "trigger times: 66\n",
      "Epoch: 079, Loss: 1.3766 \n",
      "trigger times: 67\n",
      "Epoch: 080, Loss: 1.3666 \n",
      "trigger times: 68\n",
      "Epoch: 081, Loss: 1.3870 \n",
      "trigger times: 69\n",
      "Epoch: 082, Loss: 1.3861 \n",
      "trigger times: 70\n",
      "Epoch: 083, Loss: 1.3775 \n",
      "trigger times: 71\n",
      "Epoch: 084, Loss: 1.3769 \n",
      "trigger times: 72\n",
      "Epoch: 085, Loss: 1.3834 \n",
      "trigger times: 73\n",
      "Epoch: 086, Loss: 1.3691 \n",
      "trigger times: 74\n",
      "Epoch: 087, Loss: 1.3909 \n",
      "trigger times: 75\n",
      "Epoch: 088, Loss: 1.3929 \n",
      "trigger times: 76\n",
      "Epoch: 089, Loss: 1.3879 \n",
      "trigger times: 77\n",
      "Epoch: 090, Loss: 1.3775 \n",
      "trigger times: 78\n",
      "Epoch: 091, Loss: 1.4041 \n",
      "trigger times: 79\n",
      "Epoch: 092, Loss: 1.3695 \n",
      "trigger times: 80\n",
      "Epoch: 093, Loss: 1.3777 \n",
      "trigger times: 81\n",
      "Epoch: 094, Loss: 1.3886 \n",
      "trigger times: 82\n",
      "Epoch: 095, Loss: 1.3771 \n",
      "trigger times: 83\n",
      "Epoch: 096, Loss: 1.3868 \n",
      "trigger times: 84\n",
      "Epoch: 097, Loss: 1.3822 \n",
      "trigger times: 85\n",
      "Epoch: 098, Loss: 1.3833 \n",
      "trigger times: 86\n",
      "Epoch: 099, Loss: 1.3943 \n",
      "trigger times: 87\n",
      "Epoch: 100, Loss: 1.3729 \n",
      "trigger times: 88\n",
      "Epoch: 101, Loss: 1.4071 \n",
      "trigger times: 89\n",
      "Epoch: 102, Loss: 1.3952 \n",
      "trigger times: 90\n",
      "Epoch: 103, Loss: 1.3885 \n",
      "trigger times: 91\n",
      "Epoch: 104, Loss: 1.3843 \n",
      "trigger times: 92\n",
      "Epoch: 105, Loss: 1.3723 \n",
      "trigger times: 93\n",
      "Epoch: 106, Loss: 1.3696 \n",
      "trigger times: 94\n",
      "Epoch: 107, Loss: 1.3766 \n",
      "trigger times: 95\n",
      "Epoch: 108, Loss: 1.4165 \n",
      "trigger times: 96\n",
      "Epoch: 109, Loss: 1.3967 \n",
      "trigger times: 97\n",
      "Epoch: 110, Loss: 1.3768 \n",
      "trigger times: 98\n",
      "Epoch: 111, Loss: 1.3585 \n",
      "Epoch: 112, Loss: 1.3904 \n",
      "trigger times: 1\n",
      "Epoch: 113, Loss: 1.3744 \n",
      "trigger times: 2\n",
      "Epoch: 114, Loss: 1.3792 \n",
      "trigger times: 3\n",
      "Epoch: 115, Loss: 1.3755 \n",
      "trigger times: 4\n",
      "Epoch: 116, Loss: 1.3791 \n",
      "trigger times: 5\n",
      "Epoch: 117, Loss: 1.3995 \n",
      "trigger times: 6\n",
      "Epoch: 118, Loss: 1.3884 \n",
      "trigger times: 7\n",
      "Epoch: 119, Loss: 1.4028 \n",
      "trigger times: 8\n",
      "Epoch: 120, Loss: 1.3843 \n",
      "trigger times: 9\n",
      "Epoch: 121, Loss: 1.3900 \n",
      "trigger times: 10\n",
      "Epoch: 122, Loss: 1.4050 \n",
      "trigger times: 11\n",
      "Epoch: 123, Loss: 1.3681 \n",
      "trigger times: 12\n",
      "Epoch: 124, Loss: 1.3843 \n",
      "trigger times: 13\n",
      "Epoch: 125, Loss: 1.4036 \n",
      "trigger times: 14\n",
      "Epoch: 126, Loss: 1.3797 \n",
      "trigger times: 15\n",
      "Epoch: 127, Loss: 1.3859 \n",
      "trigger times: 16\n",
      "Epoch: 128, Loss: 1.3895 \n",
      "trigger times: 17\n",
      "Epoch: 129, Loss: 1.3807 \n",
      "trigger times: 18\n",
      "Epoch: 130, Loss: 1.4008 \n",
      "trigger times: 19\n",
      "Epoch: 131, Loss: 1.3825 \n",
      "trigger times: 20\n",
      "Epoch: 132, Loss: 1.3722 \n",
      "trigger times: 21\n",
      "Epoch: 133, Loss: 1.3878 \n",
      "trigger times: 22\n",
      "Epoch: 134, Loss: 1.3972 \n",
      "trigger times: 23\n",
      "Epoch: 135, Loss: 1.3791 \n",
      "trigger times: 24\n",
      "Epoch: 136, Loss: 1.3983 \n",
      "trigger times: 25\n",
      "Epoch: 137, Loss: 1.3828 \n",
      "trigger times: 26\n",
      "Epoch: 138, Loss: 1.3662 \n",
      "trigger times: 27\n",
      "Epoch: 139, Loss: 1.3807 \n",
      "trigger times: 28\n",
      "Epoch: 140, Loss: 1.3911 \n",
      "trigger times: 29\n",
      "Epoch: 141, Loss: 1.3878 \n",
      "trigger times: 30\n",
      "Epoch: 142, Loss: 1.3756 \n",
      "trigger times: 31\n",
      "Epoch: 143, Loss: 1.3833 \n",
      "trigger times: 32\n",
      "Epoch: 144, Loss: 1.3897 \n",
      "trigger times: 33\n",
      "Epoch: 145, Loss: 1.3802 \n",
      "trigger times: 34\n",
      "Epoch: 146, Loss: 1.3753 \n",
      "trigger times: 35\n",
      "Epoch: 147, Loss: 1.3904 \n",
      "trigger times: 36\n",
      "Epoch: 148, Loss: 1.3893 \n",
      "trigger times: 37\n",
      "Epoch: 149, Loss: 1.3746 \n",
      "trigger times: 38\n",
      "Epoch: 150, Loss: 1.3907 \n",
      "trigger times: 39\n",
      "Epoch: 151, Loss: 1.3798 \n",
      "trigger times: 40\n",
      "Epoch: 152, Loss: 1.3794 \n",
      "trigger times: 41\n",
      "Epoch: 153, Loss: 1.3841 \n",
      "trigger times: 42\n",
      "Epoch: 154, Loss: 1.3694 \n",
      "trigger times: 43\n",
      "Epoch: 155, Loss: 1.4205 \n",
      "trigger times: 44\n",
      "Epoch: 156, Loss: 1.3698 \n",
      "trigger times: 45\n",
      "Epoch: 157, Loss: 1.3713 \n",
      "trigger times: 46\n",
      "Epoch: 158, Loss: 1.3808 \n",
      "trigger times: 47\n",
      "Epoch: 159, Loss: 1.4050 \n",
      "trigger times: 48\n",
      "Epoch: 160, Loss: 1.3946 \n",
      "trigger times: 49\n",
      "Epoch: 161, Loss: 1.3735 \n",
      "trigger times: 50\n",
      "Epoch: 162, Loss: 1.3910 \n",
      "trigger times: 51\n",
      "Epoch: 163, Loss: 1.3967 \n",
      "trigger times: 52\n",
      "Epoch: 164, Loss: 1.3753 \n",
      "trigger times: 53\n",
      "Epoch: 165, Loss: 1.3750 \n",
      "trigger times: 54\n",
      "Epoch: 166, Loss: 1.3885 \n",
      "trigger times: 55\n",
      "Epoch: 167, Loss: 1.3889 \n",
      "trigger times: 56\n",
      "Epoch: 168, Loss: 1.3867 \n",
      "trigger times: 57\n",
      "Epoch: 169, Loss: 1.4010 \n",
      "trigger times: 58\n",
      "Epoch: 170, Loss: 1.3705 \n",
      "trigger times: 59\n",
      "Epoch: 171, Loss: 1.3984 \n",
      "trigger times: 60\n",
      "Epoch: 172, Loss: 1.4003 \n",
      "trigger times: 61\n",
      "Epoch: 173, Loss: 1.3944 \n",
      "trigger times: 62\n",
      "Epoch: 174, Loss: 1.4026 \n",
      "trigger times: 63\n",
      "Epoch: 175, Loss: 1.3872 \n",
      "trigger times: 64\n",
      "Epoch: 176, Loss: 1.3762 \n",
      "trigger times: 65\n",
      "Epoch: 177, Loss: 1.3758 \n",
      "trigger times: 66\n",
      "Epoch: 178, Loss: 1.3762 \n",
      "trigger times: 67\n",
      "Epoch: 179, Loss: 1.3875 \n",
      "trigger times: 68\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 180, Loss: 1.3750 \n",
      "trigger times: 69\n",
      "Epoch: 181, Loss: 1.3844 \n",
      "trigger times: 70\n",
      "Epoch: 182, Loss: 1.3815 \n",
      "trigger times: 71\n",
      "Epoch: 183, Loss: 1.3788 \n",
      "trigger times: 72\n",
      "Epoch: 184, Loss: 1.3789 \n",
      "trigger times: 73\n",
      "Epoch: 185, Loss: 1.3769 \n",
      "trigger times: 74\n",
      "Epoch: 186, Loss: 1.3749 \n",
      "trigger times: 75\n",
      "Epoch: 187, Loss: 1.4289 \n",
      "trigger times: 76\n",
      "Epoch: 188, Loss: 1.4236 \n",
      "trigger times: 77\n",
      "Epoch: 189, Loss: 1.4128 \n",
      "trigger times: 78\n",
      "Epoch: 190, Loss: 1.3693 \n",
      "trigger times: 79\n",
      "Epoch: 191, Loss: 1.3828 \n",
      "trigger times: 80\n",
      "Epoch: 192, Loss: 1.3740 \n",
      "trigger times: 81\n",
      "Epoch: 193, Loss: 1.3751 \n",
      "trigger times: 82\n",
      "Epoch: 194, Loss: 1.3828 \n",
      "trigger times: 83\n",
      "Epoch: 195, Loss: 1.3895 \n",
      "trigger times: 84\n",
      "Epoch: 196, Loss: 1.3948 \n",
      "trigger times: 85\n",
      "Epoch: 197, Loss: 1.3838 \n",
      "trigger times: 86\n",
      "Epoch: 198, Loss: 1.3829 \n",
      "trigger times: 87\n",
      "Epoch: 199, Loss: 1.3795 \n",
      "trigger times: 88\n",
      "Epoch: 000, Loss: 1.3150 \n",
      "Epoch: 001, Loss: 1.2927 \n",
      "Epoch: 002, Loss: 1.2978 \n",
      "trigger times: 1\n",
      "Epoch: 003, Loss: 1.2877 \n",
      "Epoch: 004, Loss: 1.3033 \n",
      "trigger times: 1\n",
      "Epoch: 005, Loss: 1.2991 \n",
      "trigger times: 2\n",
      "Epoch: 006, Loss: 1.3042 \n",
      "trigger times: 3\n",
      "Epoch: 007, Loss: 1.3016 \n",
      "trigger times: 4\n",
      "Epoch: 008, Loss: 1.2990 \n",
      "trigger times: 5\n",
      "Epoch: 009, Loss: 1.2990 \n",
      "trigger times: 6\n",
      "Epoch: 010, Loss: 1.3099 \n",
      "trigger times: 7\n",
      "Epoch: 011, Loss: 1.2931 \n",
      "trigger times: 8\n",
      "Epoch: 012, Loss: 1.3118 \n",
      "trigger times: 9\n",
      "Epoch: 013, Loss: 1.3122 \n",
      "trigger times: 10\n",
      "Epoch: 014, Loss: 1.3250 \n",
      "trigger times: 11\n",
      "Epoch: 015, Loss: 1.3161 \n",
      "trigger times: 12\n",
      "Epoch: 016, Loss: 1.3051 \n",
      "trigger times: 13\n",
      "Epoch: 017, Loss: 1.3032 \n",
      "trigger times: 14\n",
      "Epoch: 018, Loss: 1.3068 \n",
      "trigger times: 15\n",
      "Epoch: 019, Loss: 1.2998 \n",
      "trigger times: 16\n",
      "Epoch: 020, Loss: 1.3193 \n",
      "trigger times: 17\n",
      "Epoch: 021, Loss: 1.3237 \n",
      "trigger times: 18\n",
      "Epoch: 022, Loss: 1.3001 \n",
      "trigger times: 19\n",
      "Epoch: 023, Loss: 1.3141 \n",
      "trigger times: 20\n",
      "Epoch: 024, Loss: 1.2900 \n",
      "trigger times: 21\n",
      "Epoch: 025, Loss: 1.3160 \n",
      "trigger times: 22\n",
      "Epoch: 026, Loss: 1.3038 \n",
      "trigger times: 23\n",
      "Epoch: 027, Loss: 1.2999 \n",
      "trigger times: 24\n",
      "Epoch: 028, Loss: 1.3013 \n",
      "trigger times: 25\n",
      "Epoch: 029, Loss: 1.3294 \n",
      "trigger times: 26\n",
      "Epoch: 030, Loss: 1.2966 \n",
      "trigger times: 27\n",
      "Epoch: 031, Loss: 1.2896 \n",
      "trigger times: 28\n",
      "Epoch: 032, Loss: 1.2937 \n",
      "trigger times: 29\n",
      "Epoch: 033, Loss: 1.2958 \n",
      "trigger times: 30\n",
      "Epoch: 034, Loss: 1.2996 \n",
      "trigger times: 31\n",
      "Epoch: 035, Loss: 1.3078 \n",
      "trigger times: 32\n",
      "Epoch: 036, Loss: 1.2893 \n",
      "trigger times: 33\n",
      "Epoch: 037, Loss: 1.3253 \n",
      "trigger times: 34\n",
      "Epoch: 038, Loss: 1.3089 \n",
      "trigger times: 35\n",
      "Epoch: 039, Loss: 1.2935 \n",
      "trigger times: 36\n",
      "Epoch: 040, Loss: 1.2927 \n",
      "trigger times: 37\n",
      "Epoch: 041, Loss: 1.3150 \n",
      "trigger times: 38\n",
      "Epoch: 042, Loss: 1.2916 \n",
      "trigger times: 39\n",
      "Epoch: 043, Loss: 1.2931 \n",
      "trigger times: 40\n",
      "Epoch: 044, Loss: 1.3014 \n",
      "trigger times: 41\n",
      "Epoch: 045, Loss: 1.2836 \n",
      "Epoch: 046, Loss: 1.2744 \n",
      "Epoch: 047, Loss: 1.2910 \n",
      "trigger times: 1\n",
      "Epoch: 048, Loss: 1.2921 \n",
      "trigger times: 2\n",
      "Epoch: 049, Loss: 1.2970 \n",
      "trigger times: 3\n",
      "Epoch: 050, Loss: 1.2816 \n",
      "trigger times: 4\n",
      "Epoch: 051, Loss: 1.2919 \n",
      "trigger times: 5\n",
      "Epoch: 052, Loss: 1.2928 \n",
      "trigger times: 6\n",
      "Epoch: 053, Loss: 1.3162 \n",
      "trigger times: 7\n",
      "Epoch: 054, Loss: 1.3010 \n",
      "trigger times: 8\n",
      "Epoch: 055, Loss: 1.2824 \n",
      "trigger times: 9\n",
      "Epoch: 056, Loss: 1.2836 \n",
      "trigger times: 10\n",
      "Epoch: 057, Loss: 1.3028 \n",
      "trigger times: 11\n",
      "Epoch: 058, Loss: 1.2892 \n",
      "trigger times: 12\n",
      "Epoch: 059, Loss: 1.2813 \n",
      "trigger times: 13\n",
      "Epoch: 060, Loss: 1.2987 \n",
      "trigger times: 14\n",
      "Epoch: 061, Loss: 1.2931 \n",
      "trigger times: 15\n",
      "Epoch: 062, Loss: 1.2891 \n",
      "trigger times: 16\n",
      "Epoch: 063, Loss: 1.2980 \n",
      "trigger times: 17\n",
      "Epoch: 064, Loss: 1.2881 \n",
      "trigger times: 18\n",
      "Epoch: 065, Loss: 1.2896 \n",
      "trigger times: 19\n",
      "Epoch: 066, Loss: 1.3104 \n",
      "trigger times: 20\n",
      "Epoch: 067, Loss: 1.3039 \n",
      "trigger times: 21\n",
      "Epoch: 068, Loss: 1.2952 \n",
      "trigger times: 22\n",
      "Epoch: 069, Loss: 1.2814 \n",
      "trigger times: 23\n",
      "Epoch: 070, Loss: 1.3071 \n",
      "trigger times: 24\n",
      "Epoch: 071, Loss: 1.3081 \n",
      "trigger times: 25\n",
      "Epoch: 072, Loss: 1.3025 \n",
      "trigger times: 26\n",
      "Epoch: 073, Loss: 1.3236 \n",
      "trigger times: 27\n",
      "Epoch: 074, Loss: 1.2845 \n",
      "trigger times: 28\n",
      "Epoch: 075, Loss: 1.2792 \n",
      "trigger times: 29\n",
      "Epoch: 076, Loss: 1.2885 \n",
      "trigger times: 30\n",
      "Epoch: 077, Loss: 1.2940 \n",
      "trigger times: 31\n",
      "Epoch: 078, Loss: 1.2947 \n",
      "trigger times: 32\n",
      "Epoch: 079, Loss: 1.3175 \n",
      "trigger times: 33\n",
      "Epoch: 080, Loss: 1.2945 \n",
      "trigger times: 34\n",
      "Epoch: 081, Loss: 1.2949 \n",
      "trigger times: 35\n",
      "Epoch: 082, Loss: 1.2957 \n",
      "trigger times: 36\n",
      "Epoch: 083, Loss: 1.2945 \n",
      "trigger times: 37\n",
      "Epoch: 084, Loss: 1.3044 \n",
      "trigger times: 38\n",
      "Epoch: 085, Loss: 1.2817 \n",
      "trigger times: 39\n",
      "Epoch: 086, Loss: 1.3054 \n",
      "trigger times: 40\n",
      "Epoch: 087, Loss: 1.2849 \n",
      "trigger times: 41\n",
      "Epoch: 088, Loss: 1.3170 \n",
      "trigger times: 42\n",
      "Epoch: 089, Loss: 1.2947 \n",
      "trigger times: 43\n",
      "Epoch: 090, Loss: 1.2868 \n",
      "trigger times: 44\n",
      "Epoch: 091, Loss: 1.2909 \n",
      "trigger times: 45\n",
      "Epoch: 092, Loss: 1.3053 \n",
      "trigger times: 46\n",
      "Epoch: 093, Loss: 1.3125 \n",
      "trigger times: 47\n",
      "Epoch: 094, Loss: 1.3040 \n",
      "trigger times: 48\n",
      "Epoch: 095, Loss: 1.2923 \n",
      "trigger times: 49\n",
      "Epoch: 096, Loss: 1.2935 \n",
      "trigger times: 50\n",
      "Epoch: 097, Loss: 1.2954 \n",
      "trigger times: 51\n",
      "Epoch: 098, Loss: 1.2950 \n",
      "trigger times: 52\n",
      "Epoch: 099, Loss: 1.2916 \n",
      "trigger times: 53\n",
      "Epoch: 100, Loss: 1.2910 \n",
      "trigger times: 54\n",
      "Epoch: 101, Loss: 1.2985 \n",
      "trigger times: 55\n",
      "Epoch: 102, Loss: 1.2818 \n",
      "trigger times: 56\n",
      "Epoch: 103, Loss: 1.2974 \n",
      "trigger times: 57\n",
      "Epoch: 104, Loss: 1.2803 \n",
      "trigger times: 58\n",
      "Epoch: 105, Loss: 1.3096 \n",
      "trigger times: 59\n",
      "Epoch: 106, Loss: 1.3096 \n",
      "trigger times: 60\n",
      "Epoch: 107, Loss: 1.2988 \n",
      "trigger times: 61\n",
      "Epoch: 108, Loss: 1.2835 \n",
      "trigger times: 62\n",
      "Epoch: 109, Loss: 1.2947 \n",
      "trigger times: 63\n",
      "Epoch: 110, Loss: 1.2873 \n",
      "trigger times: 64\n",
      "Epoch: 111, Loss: 1.2897 \n",
      "trigger times: 65\n",
      "Epoch: 112, Loss: 1.2878 \n",
      "trigger times: 66\n",
      "Epoch: 113, Loss: 1.3162 \n",
      "trigger times: 67\n",
      "Epoch: 114, Loss: 1.3016 \n",
      "trigger times: 68\n",
      "Epoch: 115, Loss: 1.2848 \n",
      "trigger times: 69\n",
      "Epoch: 116, Loss: 1.2945 \n",
      "trigger times: 70\n",
      "Epoch: 117, Loss: 1.3171 \n",
      "trigger times: 71\n",
      "Epoch: 118, Loss: 1.2945 \n",
      "trigger times: 72\n",
      "Epoch: 119, Loss: 1.2878 \n",
      "trigger times: 73\n",
      "Epoch: 120, Loss: 1.2821 \n",
      "trigger times: 74\n",
      "Epoch: 121, Loss: 1.2805 \n",
      "trigger times: 75\n",
      "Epoch: 122, Loss: 1.2740 \n",
      "Epoch: 123, Loss: 1.2948 \n",
      "trigger times: 1\n",
      "Epoch: 124, Loss: 1.2917 \n",
      "trigger times: 2\n",
      "Epoch: 125, Loss: 1.2884 \n",
      "trigger times: 3\n",
      "Epoch: 126, Loss: 1.2994 \n",
      "trigger times: 4\n",
      "Epoch: 127, Loss: 1.2988 \n",
      "trigger times: 5\n",
      "Epoch: 128, Loss: 1.2840 \n",
      "trigger times: 6\n",
      "Epoch: 129, Loss: 1.2878 \n",
      "trigger times: 7\n",
      "Epoch: 130, Loss: 1.2919 \n",
      "trigger times: 8\n",
      "Epoch: 131, Loss: 1.2901 \n",
      "trigger times: 9\n",
      "Epoch: 132, Loss: 1.3108 \n",
      "trigger times: 10\n",
      "Epoch: 133, Loss: 1.2792 \n",
      "trigger times: 11\n",
      "Epoch: 134, Loss: 1.2899 \n",
      "trigger times: 12\n",
      "Epoch: 135, Loss: 1.2871 \n",
      "trigger times: 13\n",
      "Epoch: 136, Loss: 1.2812 \n",
      "trigger times: 14\n",
      "Epoch: 137, Loss: 1.2910 \n",
      "trigger times: 15\n",
      "Epoch: 138, Loss: 1.2761 \n",
      "trigger times: 16\n",
      "Epoch: 139, Loss: 1.2850 \n",
      "trigger times: 17\n",
      "Epoch: 140, Loss: 1.2867 \n",
      "trigger times: 18\n",
      "Epoch: 141, Loss: 1.2852 \n",
      "trigger times: 19\n",
      "Epoch: 142, Loss: 1.2696 \n",
      "Epoch: 143, Loss: 1.2688 \n",
      "Epoch: 144, Loss: 1.2838 \n",
      "trigger times: 1\n",
      "Epoch: 145, Loss: 1.2921 \n",
      "trigger times: 2\n",
      "Epoch: 146, Loss: 1.2810 \n",
      "trigger times: 3\n",
      "Epoch: 147, Loss: 1.2725 \n",
      "trigger times: 4\n",
      "Epoch: 148, Loss: 1.2670 \n",
      "Epoch: 149, Loss: 1.2811 \n",
      "trigger times: 1\n",
      "Epoch: 150, Loss: 1.2978 \n",
      "trigger times: 2\n",
      "Epoch: 151, Loss: 1.2725 \n",
      "trigger times: 3\n",
      "Epoch: 152, Loss: 1.2920 \n",
      "trigger times: 4\n",
      "Epoch: 153, Loss: 1.2814 \n",
      "trigger times: 5\n",
      "Epoch: 154, Loss: 1.2906 \n",
      "trigger times: 6\n",
      "Epoch: 155, Loss: 1.2729 \n",
      "trigger times: 7\n",
      "Epoch: 156, Loss: 1.2738 \n",
      "trigger times: 8\n",
      "Epoch: 157, Loss: 1.3305 \n",
      "trigger times: 9\n",
      "Epoch: 158, Loss: 1.2792 \n",
      "trigger times: 10\n",
      "Epoch: 159, Loss: 1.2906 \n",
      "trigger times: 11\n",
      "Epoch: 160, Loss: 1.2712 \n",
      "trigger times: 12\n",
      "Epoch: 161, Loss: 1.2819 \n",
      "trigger times: 13\n",
      "Epoch: 162, Loss: 1.2834 \n",
      "trigger times: 14\n",
      "Epoch: 163, Loss: 1.2863 \n",
      "trigger times: 15\n",
      "Epoch: 164, Loss: 1.2735 \n",
      "trigger times: 16\n",
      "Epoch: 165, Loss: 1.2778 \n",
      "trigger times: 17\n",
      "Epoch: 166, Loss: 1.2419 \n",
      "Epoch: 167, Loss: 1.2784 \n",
      "trigger times: 1\n",
      "Epoch: 168, Loss: 1.2824 \n",
      "trigger times: 2\n",
      "Epoch: 169, Loss: 1.2759 \n",
      "trigger times: 3\n",
      "Epoch: 170, Loss: 1.2932 \n",
      "trigger times: 4\n",
      "Epoch: 171, Loss: 1.2703 \n",
      "trigger times: 5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 172, Loss: 1.2666 \n",
      "trigger times: 6\n",
      "Epoch: 173, Loss: 1.2788 \n",
      "trigger times: 7\n",
      "Epoch: 174, Loss: 1.2896 \n",
      "trigger times: 8\n",
      "Epoch: 175, Loss: 1.2858 \n",
      "trigger times: 9\n",
      "Epoch: 176, Loss: 1.2785 \n",
      "trigger times: 10\n",
      "Epoch: 177, Loss: 1.2654 \n",
      "trigger times: 11\n",
      "Epoch: 178, Loss: 1.2914 \n",
      "trigger times: 12\n",
      "Epoch: 179, Loss: 1.2833 \n",
      "trigger times: 13\n",
      "Epoch: 180, Loss: 1.2731 \n",
      "trigger times: 14\n",
      "Epoch: 181, Loss: 1.2795 \n",
      "trigger times: 15\n",
      "Epoch: 182, Loss: 1.2770 \n",
      "trigger times: 16\n",
      "Epoch: 183, Loss: 1.2618 \n",
      "trigger times: 17\n",
      "Epoch: 184, Loss: 1.2636 \n",
      "trigger times: 18\n",
      "Epoch: 185, Loss: 1.2724 \n",
      "trigger times: 19\n",
      "Epoch: 186, Loss: 1.2732 \n",
      "trigger times: 20\n",
      "Epoch: 187, Loss: 1.2676 \n",
      "trigger times: 21\n",
      "Epoch: 188, Loss: 1.2662 \n",
      "trigger times: 22\n",
      "Epoch: 189, Loss: 1.2841 \n",
      "trigger times: 23\n",
      "Epoch: 190, Loss: 1.2826 \n",
      "trigger times: 24\n",
      "Epoch: 191, Loss: 1.2785 \n",
      "trigger times: 25\n",
      "Epoch: 192, Loss: 1.2665 \n",
      "trigger times: 26\n",
      "Epoch: 193, Loss: 1.2830 \n",
      "trigger times: 27\n",
      "Epoch: 194, Loss: 1.2779 \n",
      "trigger times: 28\n",
      "Epoch: 195, Loss: 1.2835 \n",
      "trigger times: 29\n",
      "Epoch: 196, Loss: 1.2877 \n",
      "trigger times: 30\n",
      "Epoch: 197, Loss: 1.2587 \n",
      "trigger times: 31\n",
      "Epoch: 198, Loss: 1.2558 \n",
      "trigger times: 32\n",
      "Epoch: 199, Loss: 1.2907 \n",
      "trigger times: 33\n",
      "Epoch: 000, Loss: 1.3829 \n",
      "Epoch: 001, Loss: 1.3788 \n",
      "Epoch: 002, Loss: 1.3547 \n",
      "Epoch: 003, Loss: 1.3611 \n",
      "trigger times: 1\n",
      "Epoch: 004, Loss: 1.3612 \n",
      "trigger times: 2\n",
      "Epoch: 005, Loss: 1.3792 \n",
      "trigger times: 3\n",
      "Epoch: 006, Loss: 1.3513 \n",
      "Epoch: 007, Loss: 1.4078 \n",
      "trigger times: 1\n",
      "Epoch: 008, Loss: 1.3496 \n",
      "Epoch: 009, Loss: 1.3596 \n",
      "trigger times: 1\n",
      "Epoch: 010, Loss: 1.3571 \n",
      "trigger times: 2\n",
      "Epoch: 011, Loss: 1.3656 \n",
      "trigger times: 3\n",
      "Epoch: 012, Loss: 1.3573 \n",
      "trigger times: 4\n",
      "Epoch: 013, Loss: 1.3383 \n",
      "Epoch: 014, Loss: 1.3659 \n",
      "trigger times: 1\n",
      "Epoch: 015, Loss: 1.3952 \n",
      "trigger times: 2\n",
      "Epoch: 016, Loss: 1.3489 \n",
      "trigger times: 3\n",
      "Epoch: 017, Loss: 1.3603 \n",
      "trigger times: 4\n",
      "Epoch: 018, Loss: 1.3568 \n",
      "trigger times: 5\n",
      "Epoch: 019, Loss: 1.3533 \n",
      "trigger times: 6\n",
      "Epoch: 020, Loss: 1.3676 \n",
      "trigger times: 7\n",
      "Epoch: 021, Loss: 1.3652 \n",
      "trigger times: 8\n",
      "Epoch: 022, Loss: 1.3704 \n",
      "trigger times: 9\n",
      "Epoch: 023, Loss: 1.3434 \n",
      "trigger times: 10\n",
      "Epoch: 024, Loss: 1.3557 \n",
      "trigger times: 11\n",
      "Epoch: 025, Loss: 1.3500 \n",
      "trigger times: 12\n",
      "Epoch: 026, Loss: 1.3590 \n",
      "trigger times: 13\n",
      "Epoch: 027, Loss: 1.3765 \n",
      "trigger times: 14\n",
      "Epoch: 028, Loss: 1.3680 \n",
      "trigger times: 15\n",
      "Epoch: 029, Loss: 1.3426 \n",
      "trigger times: 16\n",
      "Epoch: 030, Loss: 1.3412 \n",
      "trigger times: 17\n",
      "Epoch: 031, Loss: 1.3593 \n",
      "trigger times: 18\n",
      "Epoch: 032, Loss: 1.3607 \n",
      "trigger times: 19\n",
      "Epoch: 033, Loss: 1.3581 \n",
      "trigger times: 20\n",
      "Epoch: 034, Loss: 1.3551 \n",
      "trigger times: 21\n",
      "Epoch: 035, Loss: 1.3626 \n",
      "trigger times: 22\n",
      "Epoch: 036, Loss: 1.3667 \n",
      "trigger times: 23\n",
      "Epoch: 037, Loss: 1.3718 \n",
      "trigger times: 24\n",
      "Epoch: 038, Loss: 1.3642 \n",
      "trigger times: 25\n",
      "Epoch: 039, Loss: 1.3761 \n",
      "trigger times: 26\n",
      "Epoch: 040, Loss: 1.3451 \n",
      "trigger times: 27\n",
      "Epoch: 041, Loss: 1.3494 \n",
      "trigger times: 28\n",
      "Epoch: 042, Loss: 1.3568 \n",
      "trigger times: 29\n",
      "Epoch: 043, Loss: 1.3714 \n",
      "trigger times: 30\n",
      "Epoch: 044, Loss: 1.3471 \n",
      "trigger times: 31\n",
      "Epoch: 045, Loss: 1.3618 \n",
      "trigger times: 32\n",
      "Epoch: 046, Loss: 1.3536 \n",
      "trigger times: 33\n",
      "Epoch: 047, Loss: 1.3624 \n",
      "trigger times: 34\n",
      "Epoch: 048, Loss: 1.3591 \n",
      "trigger times: 35\n",
      "Epoch: 049, Loss: 1.3666 \n",
      "trigger times: 36\n",
      "Epoch: 050, Loss: 1.3647 \n",
      "trigger times: 37\n",
      "Epoch: 051, Loss: 1.3657 \n",
      "trigger times: 38\n",
      "Epoch: 052, Loss: 1.3443 \n",
      "trigger times: 39\n",
      "Epoch: 053, Loss: 1.3557 \n",
      "trigger times: 40\n",
      "Epoch: 054, Loss: 1.3486 \n",
      "trigger times: 41\n",
      "Epoch: 055, Loss: 1.3676 \n",
      "trigger times: 42\n",
      "Epoch: 056, Loss: 1.3639 \n",
      "trigger times: 43\n",
      "Epoch: 057, Loss: 1.3696 \n",
      "trigger times: 44\n",
      "Epoch: 058, Loss: 1.3557 \n",
      "trigger times: 45\n",
      "Epoch: 059, Loss: 1.3462 \n",
      "trigger times: 46\n",
      "Epoch: 060, Loss: 1.3774 \n",
      "trigger times: 47\n",
      "Epoch: 061, Loss: 1.3481 \n",
      "trigger times: 48\n",
      "Epoch: 062, Loss: 1.3605 \n",
      "trigger times: 49\n",
      "Epoch: 063, Loss: 1.3590 \n",
      "trigger times: 50\n",
      "Epoch: 064, Loss: 1.3526 \n",
      "trigger times: 51\n",
      "Epoch: 065, Loss: 1.3417 \n",
      "trigger times: 52\n",
      "Epoch: 066, Loss: 1.3722 \n",
      "trigger times: 53\n",
      "Epoch: 067, Loss: 1.3568 \n",
      "trigger times: 54\n",
      "Epoch: 068, Loss: 1.3570 \n",
      "trigger times: 55\n",
      "Epoch: 069, Loss: 1.3570 \n",
      "trigger times: 56\n",
      "Epoch: 070, Loss: 1.3680 \n",
      "trigger times: 57\n",
      "Epoch: 071, Loss: 1.3644 \n",
      "trigger times: 58\n",
      "Epoch: 072, Loss: 1.3464 \n",
      "trigger times: 59\n",
      "Epoch: 073, Loss: 1.3471 \n",
      "trigger times: 60\n",
      "Epoch: 074, Loss: 1.3380 \n",
      "Epoch: 075, Loss: 1.3414 \n",
      "trigger times: 1\n",
      "Epoch: 076, Loss: 1.3543 \n",
      "trigger times: 2\n",
      "Epoch: 077, Loss: 1.3745 \n",
      "trigger times: 3\n",
      "Epoch: 078, Loss: 1.3594 \n",
      "trigger times: 4\n",
      "Epoch: 079, Loss: 1.3472 \n",
      "trigger times: 5\n",
      "Epoch: 080, Loss: 1.3657 \n",
      "trigger times: 6\n",
      "Epoch: 081, Loss: 1.3584 \n",
      "trigger times: 7\n",
      "Epoch: 082, Loss: 1.3673 \n",
      "trigger times: 8\n",
      "Epoch: 083, Loss: 1.3631 \n",
      "trigger times: 9\n",
      "Epoch: 084, Loss: 1.3373 \n",
      "Epoch: 085, Loss: 1.3634 \n",
      "trigger times: 1\n",
      "Epoch: 086, Loss: 1.3605 \n",
      "trigger times: 2\n",
      "Epoch: 087, Loss: 1.3494 \n",
      "trigger times: 3\n",
      "Epoch: 088, Loss: 1.3492 \n",
      "trigger times: 4\n",
      "Epoch: 089, Loss: 1.3513 \n",
      "trigger times: 5\n",
      "Epoch: 090, Loss: 1.3542 \n",
      "trigger times: 6\n",
      "Epoch: 091, Loss: 1.3511 \n",
      "trigger times: 7\n",
      "Epoch: 092, Loss: 1.3606 \n",
      "trigger times: 8\n",
      "Epoch: 093, Loss: 1.3584 \n",
      "trigger times: 9\n",
      "Epoch: 094, Loss: 1.3498 \n",
      "trigger times: 10\n",
      "Epoch: 095, Loss: 1.3644 \n",
      "trigger times: 11\n",
      "Epoch: 096, Loss: 1.3440 \n",
      "trigger times: 12\n",
      "Epoch: 097, Loss: 1.3405 \n",
      "trigger times: 13\n",
      "Epoch: 098, Loss: 1.3537 \n",
      "trigger times: 14\n",
      "Epoch: 099, Loss: 1.3412 \n",
      "trigger times: 15\n",
      "Epoch: 100, Loss: 1.3430 \n",
      "trigger times: 16\n",
      "Epoch: 101, Loss: 1.3348 \n",
      "Epoch: 102, Loss: 1.3579 \n",
      "trigger times: 1\n",
      "Epoch: 103, Loss: 1.3407 \n",
      "trigger times: 2\n",
      "Epoch: 104, Loss: 1.3554 \n",
      "trigger times: 3\n",
      "Epoch: 105, Loss: 1.3478 \n",
      "trigger times: 4\n",
      "Epoch: 106, Loss: 1.3472 \n",
      "trigger times: 5\n",
      "Epoch: 107, Loss: 1.3527 \n",
      "trigger times: 6\n",
      "Epoch: 108, Loss: 1.3673 \n",
      "trigger times: 7\n",
      "Epoch: 109, Loss: 1.3742 \n",
      "trigger times: 8\n",
      "Epoch: 110, Loss: 1.3401 \n",
      "trigger times: 9\n",
      "Epoch: 111, Loss: 1.3443 \n",
      "trigger times: 10\n",
      "Epoch: 112, Loss: 1.3422 \n",
      "trigger times: 11\n",
      "Epoch: 113, Loss: 1.3711 \n",
      "trigger times: 12\n",
      "Epoch: 114, Loss: 1.3424 \n",
      "trigger times: 13\n",
      "Epoch: 115, Loss: 1.3475 \n",
      "trigger times: 14\n",
      "Epoch: 116, Loss: 1.3375 \n",
      "trigger times: 15\n",
      "Epoch: 117, Loss: 1.3598 \n",
      "trigger times: 16\n",
      "Epoch: 118, Loss: 1.3650 \n",
      "trigger times: 17\n",
      "Epoch: 119, Loss: 1.3452 \n",
      "trigger times: 18\n",
      "Epoch: 120, Loss: 1.3560 \n",
      "trigger times: 19\n",
      "Epoch: 121, Loss: 1.3961 \n",
      "trigger times: 20\n",
      "Epoch: 122, Loss: 1.3578 \n",
      "trigger times: 21\n",
      "Epoch: 123, Loss: 1.3526 \n",
      "trigger times: 22\n",
      "Epoch: 124, Loss: 1.3657 \n",
      "trigger times: 23\n",
      "Epoch: 125, Loss: 1.3550 \n",
      "trigger times: 24\n",
      "Epoch: 126, Loss: 1.3573 \n",
      "trigger times: 25\n",
      "Epoch: 127, Loss: 1.3615 \n",
      "trigger times: 26\n",
      "Epoch: 128, Loss: 1.3421 \n",
      "trigger times: 27\n",
      "Epoch: 129, Loss: 1.3669 \n",
      "trigger times: 28\n",
      "Epoch: 130, Loss: 1.3627 \n",
      "trigger times: 29\n",
      "Epoch: 131, Loss: 1.3555 \n",
      "trigger times: 30\n",
      "Epoch: 132, Loss: 1.3414 \n",
      "trigger times: 31\n",
      "Epoch: 133, Loss: 1.3447 \n",
      "trigger times: 32\n",
      "Epoch: 134, Loss: 1.3581 \n",
      "trigger times: 33\n",
      "Epoch: 135, Loss: 1.3658 \n",
      "trigger times: 34\n",
      "Epoch: 136, Loss: 1.3420 \n",
      "trigger times: 35\n",
      "Epoch: 137, Loss: 1.3583 \n",
      "trigger times: 36\n",
      "Epoch: 138, Loss: 1.3658 \n",
      "trigger times: 37\n",
      "Epoch: 139, Loss: 1.3666 \n",
      "trigger times: 38\n",
      "Epoch: 140, Loss: 1.3470 \n",
      "trigger times: 39\n",
      "Epoch: 141, Loss: 1.3352 \n",
      "trigger times: 40\n",
      "Epoch: 142, Loss: 1.3458 \n",
      "trigger times: 41\n",
      "Epoch: 143, Loss: 1.3767 \n",
      "trigger times: 42\n",
      "Epoch: 144, Loss: 1.3600 \n",
      "trigger times: 43\n",
      "Epoch: 145, Loss: 1.3685 \n",
      "trigger times: 44\n",
      "Epoch: 146, Loss: 1.3616 \n",
      "trigger times: 45\n",
      "Epoch: 147, Loss: 1.3663 \n",
      "trigger times: 46\n",
      "Epoch: 148, Loss: 1.3412 \n",
      "trigger times: 47\n",
      "Epoch: 149, Loss: 1.3449 \n",
      "trigger times: 48\n",
      "Epoch: 150, Loss: 1.3508 \n",
      "trigger times: 49\n",
      "Epoch: 151, Loss: 1.3431 \n",
      "trigger times: 50\n",
      "Epoch: 152, Loss: 1.3420 \n",
      "trigger times: 51\n",
      "Epoch: 153, Loss: 1.3720 \n",
      "trigger times: 52\n",
      "Epoch: 154, Loss: 1.3472 \n",
      "trigger times: 53\n",
      "Epoch: 155, Loss: 1.3685 \n",
      "trigger times: 54\n",
      "Epoch: 156, Loss: 1.3506 \n",
      "trigger times: 55\n",
      "Epoch: 157, Loss: 1.3458 \n",
      "trigger times: 56\n",
      "Epoch: 158, Loss: 1.3438 \n",
      "trigger times: 57\n",
      "Epoch: 159, Loss: 1.3595 \n",
      "trigger times: 58\n",
      "Epoch: 160, Loss: 1.3722 \n",
      "trigger times: 59\n",
      "Epoch: 161, Loss: 1.3609 \n",
      "trigger times: 60\n",
      "Epoch: 162, Loss: 1.3617 \n",
      "trigger times: 61\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 163, Loss: 1.3472 \n",
      "trigger times: 62\n",
      "Epoch: 164, Loss: 1.3583 \n",
      "trigger times: 63\n",
      "Epoch: 165, Loss: 1.3440 \n",
      "trigger times: 64\n",
      "Epoch: 166, Loss: 1.3643 \n",
      "trigger times: 65\n",
      "Epoch: 167, Loss: 1.3518 \n",
      "trigger times: 66\n",
      "Epoch: 168, Loss: 1.3650 \n",
      "trigger times: 67\n",
      "Epoch: 169, Loss: 1.3420 \n",
      "trigger times: 68\n",
      "Epoch: 170, Loss: 1.3574 \n",
      "trigger times: 69\n",
      "Epoch: 171, Loss: 1.3637 \n",
      "trigger times: 70\n",
      "Epoch: 172, Loss: 1.3532 \n",
      "trigger times: 71\n",
      "Epoch: 173, Loss: 1.3576 \n",
      "trigger times: 72\n",
      "Epoch: 174, Loss: 1.3705 \n",
      "trigger times: 73\n",
      "Epoch: 175, Loss: 1.3342 \n",
      "Epoch: 176, Loss: 1.3703 \n",
      "trigger times: 1\n",
      "Epoch: 177, Loss: 1.3507 \n",
      "trigger times: 2\n",
      "Epoch: 178, Loss: 1.3550 \n",
      "trigger times: 3\n",
      "Epoch: 179, Loss: 1.3518 \n",
      "trigger times: 4\n",
      "Epoch: 180, Loss: 1.3531 \n",
      "trigger times: 5\n",
      "Epoch: 181, Loss: 1.3780 \n",
      "trigger times: 6\n",
      "Epoch: 182, Loss: 1.3606 \n",
      "trigger times: 7\n",
      "Epoch: 183, Loss: 1.3548 \n",
      "trigger times: 8\n",
      "Epoch: 184, Loss: 1.3454 \n",
      "trigger times: 9\n",
      "Epoch: 185, Loss: 1.3460 \n",
      "trigger times: 10\n",
      "Epoch: 186, Loss: 1.3709 \n",
      "trigger times: 11\n",
      "Epoch: 187, Loss: 1.3528 \n",
      "trigger times: 12\n",
      "Epoch: 188, Loss: 1.3468 \n",
      "trigger times: 13\n",
      "Epoch: 189, Loss: 1.3557 \n",
      "trigger times: 14\n",
      "Epoch: 190, Loss: 1.3782 \n",
      "trigger times: 15\n",
      "Epoch: 191, Loss: 1.3455 \n",
      "trigger times: 16\n",
      "Epoch: 192, Loss: 1.3685 \n",
      "trigger times: 17\n",
      "Epoch: 193, Loss: 1.3533 \n",
      "trigger times: 18\n",
      "Epoch: 194, Loss: 1.3715 \n",
      "trigger times: 19\n",
      "Epoch: 195, Loss: 1.3565 \n",
      "trigger times: 20\n",
      "Epoch: 196, Loss: 1.3661 \n",
      "trigger times: 21\n",
      "Epoch: 197, Loss: 1.3368 \n",
      "trigger times: 22\n",
      "Epoch: 198, Loss: 1.3460 \n",
      "trigger times: 23\n",
      "Epoch: 199, Loss: 1.3575 \n",
      "trigger times: 24\n",
      "Epoch: 000, Loss: 1.2787 \n",
      "Epoch: 001, Loss: 1.2800 \n",
      "trigger times: 1\n",
      "Epoch: 002, Loss: 1.2838 \n",
      "trigger times: 2\n",
      "Epoch: 003, Loss: 1.2839 \n",
      "trigger times: 3\n",
      "Epoch: 004, Loss: 1.2844 \n",
      "trigger times: 4\n",
      "Epoch: 005, Loss: 1.2662 \n",
      "Epoch: 006, Loss: 1.2903 \n",
      "trigger times: 1\n",
      "Epoch: 007, Loss: 1.2915 \n",
      "trigger times: 2\n",
      "Epoch: 008, Loss: 1.2716 \n",
      "trigger times: 3\n",
      "Epoch: 009, Loss: 1.2665 \n",
      "trigger times: 4\n",
      "Epoch: 010, Loss: 1.2701 \n",
      "trigger times: 5\n",
      "Epoch: 011, Loss: 1.2856 \n",
      "trigger times: 6\n",
      "Epoch: 012, Loss: 1.2822 \n",
      "trigger times: 7\n",
      "Epoch: 013, Loss: 1.2940 \n",
      "trigger times: 8\n",
      "Epoch: 014, Loss: 1.3079 \n",
      "trigger times: 9\n",
      "Epoch: 015, Loss: 1.2604 \n",
      "Epoch: 016, Loss: 1.2918 \n",
      "trigger times: 1\n",
      "Epoch: 017, Loss: 1.2708 \n",
      "trigger times: 2\n",
      "Epoch: 018, Loss: 1.2808 \n",
      "trigger times: 3\n",
      "Epoch: 019, Loss: 1.2642 \n",
      "trigger times: 4\n",
      "Epoch: 020, Loss: 1.2837 \n",
      "trigger times: 5\n",
      "Epoch: 021, Loss: 1.3317 \n",
      "trigger times: 6\n",
      "Epoch: 022, Loss: 1.2732 \n",
      "trigger times: 7\n",
      "Epoch: 023, Loss: 1.2823 \n",
      "trigger times: 8\n",
      "Epoch: 024, Loss: 1.2863 \n",
      "trigger times: 9\n",
      "Epoch: 025, Loss: 1.2895 \n",
      "trigger times: 10\n",
      "Epoch: 026, Loss: 1.2791 \n",
      "trigger times: 11\n",
      "Epoch: 027, Loss: 1.2872 \n",
      "trigger times: 12\n",
      "Epoch: 028, Loss: 1.2746 \n",
      "trigger times: 13\n",
      "Epoch: 029, Loss: 1.2882 \n",
      "trigger times: 14\n",
      "Epoch: 030, Loss: 1.2848 \n",
      "trigger times: 15\n",
      "Epoch: 031, Loss: 1.2915 \n",
      "trigger times: 16\n",
      "Epoch: 032, Loss: 1.2853 \n",
      "trigger times: 17\n",
      "Epoch: 033, Loss: 1.2742 \n",
      "trigger times: 18\n",
      "Epoch: 034, Loss: 1.2792 \n",
      "trigger times: 19\n",
      "Epoch: 035, Loss: 1.2700 \n",
      "trigger times: 20\n",
      "Epoch: 036, Loss: 1.2850 \n",
      "trigger times: 21\n",
      "Epoch: 037, Loss: 1.2834 \n",
      "trigger times: 22\n",
      "Epoch: 038, Loss: 1.2771 \n",
      "trigger times: 23\n",
      "Epoch: 039, Loss: 1.2837 \n",
      "trigger times: 24\n",
      "Epoch: 040, Loss: 1.2737 \n",
      "trigger times: 25\n",
      "Epoch: 041, Loss: 1.2699 \n",
      "trigger times: 26\n",
      "Epoch: 042, Loss: 1.2852 \n",
      "trigger times: 27\n",
      "Epoch: 043, Loss: 1.2778 \n",
      "trigger times: 28\n",
      "Epoch: 044, Loss: 1.2850 \n",
      "trigger times: 29\n",
      "Epoch: 045, Loss: 1.2700 \n",
      "trigger times: 30\n",
      "Epoch: 046, Loss: 1.2761 \n",
      "trigger times: 31\n",
      "Epoch: 047, Loss: 1.2738 \n",
      "trigger times: 32\n",
      "Epoch: 048, Loss: 1.2664 \n",
      "trigger times: 33\n",
      "Epoch: 049, Loss: 1.3017 \n",
      "trigger times: 34\n",
      "Epoch: 050, Loss: 1.2678 \n",
      "trigger times: 35\n",
      "Epoch: 051, Loss: 1.2550 \n",
      "Epoch: 052, Loss: 1.2732 \n",
      "trigger times: 1\n",
      "Epoch: 053, Loss: 1.3002 \n",
      "trigger times: 2\n",
      "Epoch: 054, Loss: 1.3087 \n",
      "trigger times: 3\n",
      "Epoch: 055, Loss: 1.2933 \n",
      "trigger times: 4\n",
      "Epoch: 056, Loss: 1.2653 \n",
      "trigger times: 5\n",
      "Epoch: 057, Loss: 1.2737 \n",
      "trigger times: 6\n",
      "Epoch: 058, Loss: 1.2654 \n",
      "trigger times: 7\n",
      "Epoch: 059, Loss: 1.2852 \n",
      "trigger times: 8\n",
      "Epoch: 060, Loss: 1.2863 \n",
      "trigger times: 9\n",
      "Epoch: 061, Loss: 1.2647 \n",
      "trigger times: 10\n",
      "Epoch: 062, Loss: 1.2722 \n",
      "trigger times: 11\n",
      "Epoch: 063, Loss: 1.2883 \n",
      "trigger times: 12\n",
      "Epoch: 064, Loss: 1.2894 \n",
      "trigger times: 13\n",
      "Epoch: 065, Loss: 1.2594 \n",
      "trigger times: 14\n",
      "Epoch: 066, Loss: 1.2704 \n",
      "trigger times: 15\n",
      "Epoch: 067, Loss: 1.2850 \n",
      "trigger times: 16\n",
      "Epoch: 068, Loss: 1.2649 \n",
      "trigger times: 17\n",
      "Epoch: 069, Loss: 1.2700 \n",
      "trigger times: 18\n",
      "Epoch: 070, Loss: 1.2720 \n",
      "trigger times: 19\n",
      "Epoch: 071, Loss: 1.2643 \n",
      "trigger times: 20\n",
      "Epoch: 072, Loss: 1.2646 \n",
      "trigger times: 21\n",
      "Epoch: 073, Loss: 1.2924 \n",
      "trigger times: 22\n",
      "Epoch: 074, Loss: 1.2817 \n",
      "trigger times: 23\n",
      "Epoch: 075, Loss: 1.2999 \n",
      "trigger times: 24\n",
      "Epoch: 076, Loss: 1.2742 \n",
      "trigger times: 25\n",
      "Epoch: 077, Loss: 1.2674 \n",
      "trigger times: 26\n",
      "Epoch: 078, Loss: 1.2728 \n",
      "trigger times: 27\n",
      "Epoch: 079, Loss: 1.2796 \n",
      "trigger times: 28\n",
      "Epoch: 080, Loss: 1.2859 \n",
      "trigger times: 29\n",
      "Epoch: 081, Loss: 1.2589 \n",
      "trigger times: 30\n",
      "Epoch: 082, Loss: 1.2810 \n",
      "trigger times: 31\n",
      "Epoch: 083, Loss: 1.2691 \n",
      "trigger times: 32\n",
      "Epoch: 084, Loss: 1.2775 \n",
      "trigger times: 33\n",
      "Epoch: 085, Loss: 1.2669 \n",
      "trigger times: 34\n",
      "Epoch: 086, Loss: 1.2784 \n",
      "trigger times: 35\n",
      "Epoch: 087, Loss: 1.2789 \n",
      "trigger times: 36\n",
      "Epoch: 088, Loss: 1.2600 \n",
      "trigger times: 37\n",
      "Epoch: 089, Loss: 1.2699 \n",
      "trigger times: 38\n",
      "Epoch: 090, Loss: 1.3040 \n",
      "trigger times: 39\n",
      "Epoch: 091, Loss: 1.2787 \n",
      "trigger times: 40\n",
      "Epoch: 092, Loss: 1.2626 \n",
      "trigger times: 41\n",
      "Epoch: 093, Loss: 1.2793 \n",
      "trigger times: 42\n",
      "Epoch: 094, Loss: 1.2657 \n",
      "trigger times: 43\n",
      "Epoch: 095, Loss: 1.2944 \n",
      "trigger times: 44\n",
      "Epoch: 096, Loss: 1.2539 \n",
      "Epoch: 097, Loss: 1.2780 \n",
      "trigger times: 1\n",
      "Epoch: 098, Loss: 1.2763 \n",
      "trigger times: 2\n",
      "Epoch: 099, Loss: 1.2843 \n",
      "trigger times: 3\n",
      "Epoch: 100, Loss: 1.2661 \n",
      "trigger times: 4\n",
      "Epoch: 101, Loss: 1.2768 \n",
      "trigger times: 5\n",
      "Epoch: 102, Loss: 1.2648 \n",
      "trigger times: 6\n",
      "Epoch: 103, Loss: 1.2924 \n",
      "trigger times: 7\n",
      "Epoch: 104, Loss: 1.2784 \n",
      "trigger times: 8\n",
      "Epoch: 105, Loss: 1.2753 \n",
      "trigger times: 9\n",
      "Epoch: 106, Loss: 1.2850 \n",
      "trigger times: 10\n",
      "Epoch: 107, Loss: 1.2925 \n",
      "trigger times: 11\n",
      "Epoch: 108, Loss: 1.3021 \n",
      "trigger times: 12\n",
      "Epoch: 109, Loss: 1.2866 \n",
      "trigger times: 13\n",
      "Epoch: 110, Loss: 1.2648 \n",
      "trigger times: 14\n",
      "Epoch: 111, Loss: 1.2717 \n",
      "trigger times: 15\n",
      "Epoch: 112, Loss: 1.2627 \n",
      "trigger times: 16\n",
      "Epoch: 113, Loss: 1.2864 \n",
      "trigger times: 17\n",
      "Epoch: 114, Loss: 1.2974 \n",
      "trigger times: 18\n",
      "Epoch: 115, Loss: 1.2553 \n",
      "trigger times: 19\n",
      "Epoch: 116, Loss: 1.2998 \n",
      "trigger times: 20\n",
      "Epoch: 117, Loss: 1.2939 \n",
      "trigger times: 21\n",
      "Epoch: 118, Loss: 1.2833 \n",
      "trigger times: 22\n",
      "Epoch: 119, Loss: 1.2586 \n",
      "trigger times: 23\n",
      "Epoch: 120, Loss: 1.2725 \n",
      "trigger times: 24\n",
      "Epoch: 121, Loss: 1.2636 \n",
      "trigger times: 25\n",
      "Epoch: 122, Loss: 1.2910 \n",
      "trigger times: 26\n",
      "Epoch: 123, Loss: 1.2946 \n",
      "trigger times: 27\n",
      "Epoch: 124, Loss: 1.2805 \n",
      "trigger times: 28\n",
      "Epoch: 125, Loss: 1.2941 \n",
      "trigger times: 29\n",
      "Epoch: 126, Loss: 1.2781 \n",
      "trigger times: 30\n",
      "Epoch: 127, Loss: 1.2632 \n",
      "trigger times: 31\n",
      "Epoch: 128, Loss: 1.2662 \n",
      "trigger times: 32\n",
      "Epoch: 129, Loss: 1.2735 \n",
      "trigger times: 33\n",
      "Epoch: 130, Loss: 1.2688 \n",
      "trigger times: 34\n",
      "Epoch: 131, Loss: 1.2840 \n",
      "trigger times: 35\n",
      "Epoch: 132, Loss: 1.2762 \n",
      "trigger times: 36\n",
      "Epoch: 133, Loss: 1.2769 \n",
      "trigger times: 37\n",
      "Epoch: 134, Loss: 1.2723 \n",
      "trigger times: 38\n",
      "Epoch: 135, Loss: 1.2629 \n",
      "trigger times: 39\n",
      "Epoch: 136, Loss: 1.2590 \n",
      "trigger times: 40\n",
      "Epoch: 137, Loss: 1.2742 \n",
      "trigger times: 41\n",
      "Epoch: 138, Loss: 1.2760 \n",
      "trigger times: 42\n",
      "Epoch: 139, Loss: 1.2807 \n",
      "trigger times: 43\n",
      "Epoch: 140, Loss: 1.2660 \n",
      "trigger times: 44\n",
      "Epoch: 141, Loss: 1.2574 \n",
      "trigger times: 45\n",
      "Epoch: 142, Loss: 1.2887 \n",
      "trigger times: 46\n",
      "Epoch: 143, Loss: 1.2900 \n",
      "trigger times: 47\n",
      "Epoch: 144, Loss: 1.2802 \n",
      "trigger times: 48\n",
      "Epoch: 145, Loss: 1.2706 \n",
      "trigger times: 49\n",
      "Epoch: 146, Loss: 1.2727 \n",
      "trigger times: 50\n",
      "Epoch: 147, Loss: 1.2540 \n",
      "trigger times: 51\n",
      "Epoch: 148, Loss: 1.2848 \n",
      "trigger times: 52\n",
      "Epoch: 149, Loss: 1.2779 \n",
      "trigger times: 53\n",
      "Epoch: 150, Loss: 1.2817 \n",
      "trigger times: 54\n",
      "Epoch: 151, Loss: 1.3013 \n",
      "trigger times: 55\n",
      "Epoch: 152, Loss: 1.2998 \n",
      "trigger times: 56\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 153, Loss: 1.2722 \n",
      "trigger times: 57\n",
      "Epoch: 154, Loss: 1.2763 \n",
      "trigger times: 58\n",
      "Epoch: 155, Loss: 1.2663 \n",
      "trigger times: 59\n",
      "Epoch: 156, Loss: 1.2811 \n",
      "trigger times: 60\n",
      "Epoch: 157, Loss: 1.2652 \n",
      "trigger times: 61\n",
      "Epoch: 158, Loss: 1.2712 \n",
      "trigger times: 62\n",
      "Epoch: 159, Loss: 1.2594 \n",
      "trigger times: 63\n",
      "Epoch: 160, Loss: 1.2863 \n",
      "trigger times: 64\n",
      "Epoch: 161, Loss: 1.2924 \n",
      "trigger times: 65\n",
      "Epoch: 162, Loss: 1.2683 \n",
      "trigger times: 66\n",
      "Epoch: 163, Loss: 1.2694 \n",
      "trigger times: 67\n",
      "Epoch: 164, Loss: 1.2836 \n",
      "trigger times: 68\n",
      "Epoch: 165, Loss: 1.2829 \n",
      "trigger times: 69\n",
      "Epoch: 166, Loss: 1.2584 \n",
      "trigger times: 70\n",
      "Epoch: 167, Loss: 1.2609 \n",
      "trigger times: 71\n",
      "Epoch: 168, Loss: 1.2712 \n",
      "trigger times: 72\n",
      "Epoch: 169, Loss: 1.2946 \n",
      "trigger times: 73\n",
      "Epoch: 170, Loss: 1.2915 \n",
      "trigger times: 74\n",
      "Epoch: 171, Loss: 1.2743 \n",
      "trigger times: 75\n",
      "Epoch: 172, Loss: 1.2761 \n",
      "trigger times: 76\n",
      "Epoch: 173, Loss: 1.2688 \n",
      "trigger times: 77\n",
      "Epoch: 174, Loss: 1.2890 \n",
      "trigger times: 78\n",
      "Epoch: 175, Loss: 1.2957 \n",
      "trigger times: 79\n",
      "Epoch: 176, Loss: 1.2622 \n",
      "trigger times: 80\n",
      "Epoch: 177, Loss: 1.2682 \n",
      "trigger times: 81\n",
      "Epoch: 178, Loss: 1.2813 \n",
      "trigger times: 82\n",
      "Epoch: 179, Loss: 1.2500 \n",
      "Epoch: 180, Loss: 1.2860 \n",
      "trigger times: 1\n",
      "Epoch: 181, Loss: 1.2808 \n",
      "trigger times: 2\n",
      "Epoch: 182, Loss: 1.2926 \n",
      "trigger times: 3\n",
      "Epoch: 183, Loss: 1.2811 \n",
      "trigger times: 4\n",
      "Epoch: 184, Loss: 1.2689 \n",
      "trigger times: 5\n",
      "Epoch: 185, Loss: 1.2836 \n",
      "trigger times: 6\n",
      "Epoch: 186, Loss: 1.2586 \n",
      "trigger times: 7\n",
      "Epoch: 187, Loss: 1.2670 \n",
      "trigger times: 8\n",
      "Epoch: 188, Loss: 1.2853 \n",
      "trigger times: 9\n",
      "Epoch: 189, Loss: 1.2740 \n",
      "trigger times: 10\n",
      "Epoch: 190, Loss: 1.2541 \n",
      "trigger times: 11\n",
      "Epoch: 191, Loss: 1.2791 \n",
      "trigger times: 12\n",
      "Epoch: 192, Loss: 1.2931 \n",
      "trigger times: 13\n",
      "Epoch: 193, Loss: 1.2772 \n",
      "trigger times: 14\n",
      "Epoch: 194, Loss: 1.2691 \n",
      "trigger times: 15\n",
      "Epoch: 195, Loss: 1.2771 \n",
      "trigger times: 16\n",
      "Epoch: 196, Loss: 1.2769 \n",
      "trigger times: 17\n",
      "Epoch: 197, Loss: 1.2684 \n",
      "trigger times: 18\n",
      "Epoch: 198, Loss: 1.2731 \n",
      "trigger times: 19\n",
      "Epoch: 199, Loss: 1.2671 \n",
      "trigger times: 20\n",
      "Epoch: 000, Loss: 1.4134 \n",
      "Epoch: 001, Loss: 1.4288 \n",
      "trigger times: 1\n",
      "Epoch: 002, Loss: 1.3890 \n",
      "Epoch: 003, Loss: 1.3896 \n",
      "trigger times: 1\n",
      "Epoch: 004, Loss: 1.3835 \n",
      "Epoch: 005, Loss: 1.3867 \n",
      "trigger times: 1\n",
      "Epoch: 006, Loss: 1.3750 \n",
      "Epoch: 007, Loss: 1.3835 \n",
      "trigger times: 1\n",
      "Epoch: 008, Loss: 1.3925 \n",
      "trigger times: 2\n",
      "Epoch: 009, Loss: 1.3904 \n",
      "trigger times: 3\n",
      "Epoch: 010, Loss: 1.3858 \n",
      "trigger times: 4\n",
      "Epoch: 011, Loss: 1.3813 \n",
      "trigger times: 5\n",
      "Epoch: 012, Loss: 1.3819 \n",
      "trigger times: 6\n",
      "Epoch: 013, Loss: 1.3890 \n",
      "trigger times: 7\n",
      "Epoch: 014, Loss: 1.3803 \n",
      "trigger times: 8\n",
      "Epoch: 015, Loss: 1.3896 \n",
      "trigger times: 9\n",
      "Epoch: 016, Loss: 1.3851 \n",
      "trigger times: 10\n",
      "Epoch: 017, Loss: 1.3683 \n",
      "Epoch: 018, Loss: 1.3826 \n",
      "trigger times: 1\n",
      "Epoch: 019, Loss: 1.3796 \n",
      "trigger times: 2\n",
      "Epoch: 020, Loss: 1.3683 \n",
      "Epoch: 021, Loss: 1.3845 \n",
      "trigger times: 1\n",
      "Epoch: 022, Loss: 1.3979 \n",
      "trigger times: 2\n",
      "Epoch: 023, Loss: 1.3703 \n",
      "trigger times: 3\n",
      "Epoch: 024, Loss: 1.3570 \n",
      "Epoch: 025, Loss: 1.3378 \n",
      "Epoch: 026, Loss: 1.3482 \n",
      "trigger times: 1\n",
      "Epoch: 027, Loss: 1.3245 \n",
      "Epoch: 028, Loss: 1.3282 \n",
      "trigger times: 1\n",
      "Epoch: 029, Loss: 1.3074 \n",
      "Epoch: 030, Loss: 1.3425 \n",
      "trigger times: 1\n",
      "Epoch: 031, Loss: 1.3251 \n",
      "trigger times: 2\n",
      "Epoch: 032, Loss: 1.3062 \n",
      "Epoch: 033, Loss: 1.3124 \n",
      "trigger times: 1\n",
      "Epoch: 034, Loss: 1.3186 \n",
      "trigger times: 2\n",
      "Epoch: 035, Loss: 1.2930 \n",
      "Epoch: 036, Loss: 1.3014 \n",
      "trigger times: 1\n",
      "Epoch: 037, Loss: 1.3323 \n",
      "trigger times: 2\n",
      "Epoch: 038, Loss: 1.3077 \n",
      "trigger times: 3\n",
      "Epoch: 039, Loss: 1.2935 \n",
      "trigger times: 4\n",
      "Epoch: 040, Loss: 1.3159 \n",
      "trigger times: 5\n",
      "Epoch: 041, Loss: 1.3018 \n",
      "trigger times: 6\n",
      "Epoch: 042, Loss: 1.2854 \n",
      "Epoch: 043, Loss: 1.3124 \n",
      "trigger times: 1\n",
      "Epoch: 044, Loss: 1.2767 \n",
      "Epoch: 045, Loss: 1.2973 \n",
      "trigger times: 1\n",
      "Epoch: 046, Loss: 1.3094 \n",
      "trigger times: 2\n",
      "Epoch: 047, Loss: 1.3097 \n",
      "trigger times: 3\n",
      "Epoch: 048, Loss: 1.2867 \n",
      "trigger times: 4\n",
      "Epoch: 049, Loss: 1.3213 \n",
      "trigger times: 5\n",
      "Epoch: 050, Loss: 1.3074 \n",
      "trigger times: 6\n",
      "Epoch: 051, Loss: 1.2830 \n",
      "trigger times: 7\n",
      "Epoch: 052, Loss: 1.2902 \n",
      "trigger times: 8\n",
      "Epoch: 053, Loss: 1.3029 \n",
      "trigger times: 9\n",
      "Epoch: 054, Loss: 1.2977 \n",
      "trigger times: 10\n",
      "Epoch: 055, Loss: 1.2854 \n",
      "trigger times: 11\n",
      "Epoch: 056, Loss: 1.2979 \n",
      "trigger times: 12\n",
      "Epoch: 057, Loss: 1.2986 \n",
      "trigger times: 13\n",
      "Epoch: 058, Loss: 1.2991 \n",
      "trigger times: 14\n",
      "Epoch: 059, Loss: 1.2853 \n",
      "trigger times: 15\n",
      "Epoch: 060, Loss: 1.2909 \n",
      "trigger times: 16\n",
      "Epoch: 061, Loss: 1.3004 \n",
      "trigger times: 17\n",
      "Epoch: 062, Loss: 1.3131 \n",
      "trigger times: 18\n",
      "Epoch: 063, Loss: 1.2750 \n",
      "Epoch: 064, Loss: 1.3117 \n",
      "trigger times: 1\n",
      "Epoch: 065, Loss: 1.3097 \n",
      "trigger times: 2\n",
      "Epoch: 066, Loss: 1.2989 \n",
      "trigger times: 3\n",
      "Epoch: 067, Loss: 1.3089 \n",
      "trigger times: 4\n",
      "Epoch: 068, Loss: 1.2804 \n",
      "trigger times: 5\n",
      "Epoch: 069, Loss: 1.2949 \n",
      "trigger times: 6\n",
      "Epoch: 070, Loss: 1.2863 \n",
      "trigger times: 7\n",
      "Epoch: 071, Loss: 1.3213 \n",
      "trigger times: 8\n",
      "Epoch: 072, Loss: 1.3036 \n",
      "trigger times: 9\n",
      "Epoch: 073, Loss: 1.2874 \n",
      "trigger times: 10\n",
      "Epoch: 074, Loss: 1.2851 \n",
      "trigger times: 11\n",
      "Epoch: 075, Loss: 1.3115 \n",
      "trigger times: 12\n",
      "Epoch: 076, Loss: 1.2821 \n",
      "trigger times: 13\n",
      "Epoch: 077, Loss: 1.2703 \n",
      "Epoch: 078, Loss: 1.3070 \n",
      "trigger times: 1\n",
      "Epoch: 079, Loss: 1.2978 \n",
      "trigger times: 2\n",
      "Epoch: 080, Loss: 1.2774 \n",
      "trigger times: 3\n",
      "Epoch: 081, Loss: 1.2868 \n",
      "trigger times: 4\n",
      "Epoch: 082, Loss: 1.2740 \n",
      "trigger times: 5\n",
      "Epoch: 083, Loss: 1.2852 \n",
      "trigger times: 6\n",
      "Epoch: 084, Loss: 1.2880 \n",
      "trigger times: 7\n",
      "Epoch: 085, Loss: 1.2772 \n",
      "trigger times: 8\n",
      "Epoch: 086, Loss: 1.2760 \n",
      "trigger times: 9\n",
      "Epoch: 087, Loss: 1.2886 \n",
      "trigger times: 10\n",
      "Epoch: 088, Loss: 1.2915 \n",
      "trigger times: 11\n",
      "Epoch: 089, Loss: 1.3088 \n",
      "trigger times: 12\n",
      "Epoch: 090, Loss: 1.3228 \n",
      "trigger times: 13\n",
      "Epoch: 091, Loss: 1.2749 \n",
      "trigger times: 14\n",
      "Epoch: 092, Loss: 1.2761 \n",
      "trigger times: 15\n",
      "Epoch: 093, Loss: 1.2723 \n",
      "trigger times: 16\n",
      "Epoch: 094, Loss: 1.2771 \n",
      "trigger times: 17\n",
      "Epoch: 095, Loss: 1.3031 \n",
      "trigger times: 18\n",
      "Epoch: 096, Loss: 1.2796 \n",
      "trigger times: 19\n",
      "Epoch: 097, Loss: 1.2877 \n",
      "trigger times: 20\n",
      "Epoch: 098, Loss: 1.2888 \n",
      "trigger times: 21\n",
      "Epoch: 099, Loss: 1.3004 \n",
      "trigger times: 22\n",
      "Epoch: 100, Loss: 1.2668 \n",
      "Epoch: 101, Loss: 1.2812 \n",
      "trigger times: 1\n",
      "Epoch: 102, Loss: 1.3012 \n",
      "trigger times: 2\n",
      "Epoch: 103, Loss: 1.2979 \n",
      "trigger times: 3\n",
      "Epoch: 104, Loss: 1.2859 \n",
      "trigger times: 4\n",
      "Epoch: 105, Loss: 1.2727 \n",
      "trigger times: 5\n",
      "Epoch: 106, Loss: 1.3056 \n",
      "trigger times: 6\n",
      "Epoch: 107, Loss: 1.3045 \n",
      "trigger times: 7\n",
      "Epoch: 108, Loss: 1.2851 \n",
      "trigger times: 8\n",
      "Epoch: 109, Loss: 1.2989 \n",
      "trigger times: 9\n",
      "Epoch: 110, Loss: 1.2679 \n",
      "trigger times: 10\n",
      "Epoch: 111, Loss: 1.2766 \n",
      "trigger times: 11\n",
      "Epoch: 112, Loss: 1.2805 \n",
      "trigger times: 12\n",
      "Epoch: 113, Loss: 1.2626 \n",
      "Epoch: 114, Loss: 1.3117 \n",
      "trigger times: 1\n",
      "Epoch: 115, Loss: 1.2928 \n",
      "trigger times: 2\n",
      "Epoch: 116, Loss: 1.2764 \n",
      "trigger times: 3\n",
      "Epoch: 117, Loss: 1.2789 \n",
      "trigger times: 4\n",
      "Epoch: 118, Loss: 1.2819 \n",
      "trigger times: 5\n",
      "Epoch: 119, Loss: 1.2956 \n",
      "trigger times: 6\n",
      "Epoch: 120, Loss: 1.2954 \n",
      "trigger times: 7\n",
      "Epoch: 121, Loss: 1.2755 \n",
      "trigger times: 8\n",
      "Epoch: 122, Loss: 1.2753 \n",
      "trigger times: 9\n",
      "Epoch: 123, Loss: 1.2993 \n",
      "trigger times: 10\n",
      "Epoch: 124, Loss: 1.2874 \n",
      "trigger times: 11\n",
      "Epoch: 125, Loss: 1.2621 \n",
      "Epoch: 126, Loss: 1.2791 \n",
      "trigger times: 1\n",
      "Epoch: 127, Loss: 1.2891 \n",
      "trigger times: 2\n",
      "Epoch: 128, Loss: 1.3009 \n",
      "trigger times: 3\n",
      "Epoch: 129, Loss: 1.2841 \n",
      "trigger times: 4\n",
      "Epoch: 130, Loss: 1.3098 \n",
      "trigger times: 5\n",
      "Epoch: 131, Loss: 1.2846 \n",
      "trigger times: 6\n",
      "Epoch: 132, Loss: 1.2729 \n",
      "trigger times: 7\n",
      "Epoch: 133, Loss: 1.2660 \n",
      "trigger times: 8\n",
      "Epoch: 134, Loss: 1.2761 \n",
      "trigger times: 9\n",
      "Epoch: 135, Loss: 1.2972 \n",
      "trigger times: 10\n",
      "Epoch: 136, Loss: 1.2787 \n",
      "trigger times: 11\n",
      "Epoch: 137, Loss: 1.2723 \n",
      "trigger times: 12\n",
      "Epoch: 138, Loss: 1.2668 \n",
      "trigger times: 13\n",
      "Epoch: 139, Loss: 1.2782 \n",
      "trigger times: 14\n",
      "Epoch: 140, Loss: 1.2788 \n",
      "trigger times: 15\n",
      "Epoch: 141, Loss: 1.3085 \n",
      "trigger times: 16\n",
      "Epoch: 142, Loss: 1.2822 \n",
      "trigger times: 17\n",
      "Epoch: 143, Loss: 1.2734 \n",
      "trigger times: 18\n",
      "Epoch: 144, Loss: 1.2670 \n",
      "trigger times: 19\n",
      "Epoch: 145, Loss: 1.2935 \n",
      "trigger times: 20\n",
      "Epoch: 146, Loss: 1.2919 \n",
      "trigger times: 21\n",
      "Epoch: 147, Loss: 1.3227 \n",
      "trigger times: 22\n",
      "Epoch: 148, Loss: 1.2732 \n",
      "trigger times: 23\n",
      "Epoch: 149, Loss: 1.2827 \n",
      "trigger times: 24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 150, Loss: 1.2816 \n",
      "trigger times: 25\n",
      "Epoch: 151, Loss: 1.2926 \n",
      "trigger times: 26\n",
      "Epoch: 152, Loss: 1.2842 \n",
      "trigger times: 27\n",
      "Epoch: 153, Loss: 1.2965 \n",
      "trigger times: 28\n",
      "Epoch: 154, Loss: 1.2697 \n",
      "trigger times: 29\n",
      "Epoch: 155, Loss: 1.2765 \n",
      "trigger times: 30\n",
      "Epoch: 156, Loss: 1.2767 \n",
      "trigger times: 31\n",
      "Epoch: 157, Loss: 1.2795 \n",
      "trigger times: 32\n",
      "Epoch: 158, Loss: 1.2695 \n",
      "trigger times: 33\n",
      "Epoch: 159, Loss: 1.2857 \n",
      "trigger times: 34\n",
      "Epoch: 160, Loss: 1.2765 \n",
      "trigger times: 35\n",
      "Epoch: 161, Loss: 1.2881 \n",
      "trigger times: 36\n",
      "Epoch: 162, Loss: 1.2802 \n",
      "trigger times: 37\n",
      "Epoch: 163, Loss: 1.2694 \n",
      "trigger times: 38\n",
      "Epoch: 164, Loss: 1.2741 \n",
      "trigger times: 39\n",
      "Epoch: 165, Loss: 1.2799 \n",
      "trigger times: 40\n",
      "Epoch: 166, Loss: 1.3302 \n",
      "trigger times: 41\n",
      "Epoch: 167, Loss: 1.2654 \n",
      "trigger times: 42\n",
      "Epoch: 168, Loss: 1.2993 \n",
      "trigger times: 43\n",
      "Epoch: 169, Loss: 1.2773 \n",
      "trigger times: 44\n",
      "Epoch: 170, Loss: 1.2837 \n",
      "trigger times: 45\n",
      "Epoch: 171, Loss: 1.2810 \n",
      "trigger times: 46\n",
      "Epoch: 172, Loss: 1.2826 \n",
      "trigger times: 47\n",
      "Epoch: 173, Loss: 1.2754 \n",
      "trigger times: 48\n",
      "Epoch: 174, Loss: 1.2807 \n",
      "trigger times: 49\n",
      "Epoch: 175, Loss: 1.2648 \n",
      "trigger times: 50\n",
      "Epoch: 176, Loss: 1.2751 \n",
      "trigger times: 51\n",
      "Epoch: 177, Loss: 1.2665 \n",
      "trigger times: 52\n",
      "Epoch: 178, Loss: 1.2538 \n",
      "Epoch: 179, Loss: 1.2720 \n",
      "trigger times: 1\n",
      "Epoch: 180, Loss: 1.2750 \n",
      "trigger times: 2\n",
      "Epoch: 181, Loss: 1.2959 \n",
      "trigger times: 3\n",
      "Epoch: 182, Loss: 1.2632 \n",
      "trigger times: 4\n",
      "Epoch: 183, Loss: 1.2644 \n",
      "trigger times: 5\n",
      "Epoch: 184, Loss: 1.2779 \n",
      "trigger times: 6\n",
      "Epoch: 185, Loss: 1.2869 \n",
      "trigger times: 7\n",
      "Epoch: 186, Loss: 1.2895 \n",
      "trigger times: 8\n",
      "Epoch: 187, Loss: 1.2687 \n",
      "trigger times: 9\n",
      "Epoch: 188, Loss: 1.2774 \n",
      "trigger times: 10\n",
      "Epoch: 189, Loss: 1.2646 \n",
      "trigger times: 11\n",
      "Epoch: 190, Loss: 1.2842 \n",
      "trigger times: 12\n",
      "Epoch: 191, Loss: 1.2684 \n",
      "trigger times: 13\n",
      "Epoch: 192, Loss: 1.2727 \n",
      "trigger times: 14\n",
      "Epoch: 193, Loss: 1.2672 \n",
      "trigger times: 15\n",
      "Epoch: 194, Loss: 1.2847 \n",
      "trigger times: 16\n",
      "Epoch: 195, Loss: 1.2766 \n",
      "trigger times: 17\n",
      "Epoch: 196, Loss: 1.2702 \n",
      "trigger times: 18\n",
      "Epoch: 197, Loss: 1.2604 \n",
      "trigger times: 19\n",
      "Epoch: 198, Loss: 1.2607 \n",
      "trigger times: 20\n",
      "Epoch: 199, Loss: 1.2732 \n",
      "trigger times: 21\n",
      "Epoch: 000, Loss: 1.3928 \n",
      "Epoch: 001, Loss: 1.3838 \n",
      "Epoch: 002, Loss: 1.3682 \n",
      "Epoch: 003, Loss: 1.3801 \n",
      "trigger times: 1\n",
      "Epoch: 004, Loss: 1.3630 \n",
      "Epoch: 005, Loss: 1.3697 \n",
      "trigger times: 1\n",
      "Epoch: 006, Loss: 1.3854 \n",
      "trigger times: 2\n",
      "Epoch: 007, Loss: 1.3620 \n",
      "Epoch: 008, Loss: 1.3482 \n",
      "Epoch: 009, Loss: 1.3663 \n",
      "trigger times: 1\n",
      "Epoch: 010, Loss: 1.3642 \n",
      "trigger times: 2\n",
      "Epoch: 011, Loss: 1.3505 \n",
      "trigger times: 3\n",
      "Epoch: 012, Loss: 1.3701 \n",
      "trigger times: 4\n",
      "Epoch: 013, Loss: 1.3634 \n",
      "trigger times: 5\n",
      "Epoch: 014, Loss: 1.3596 \n",
      "trigger times: 6\n",
      "Epoch: 015, Loss: 1.3386 \n",
      "Epoch: 016, Loss: 1.3591 \n",
      "trigger times: 1\n",
      "Epoch: 017, Loss: 1.3796 \n",
      "trigger times: 2\n",
      "Epoch: 018, Loss: 1.3641 \n",
      "trigger times: 3\n",
      "Epoch: 019, Loss: 1.3820 \n",
      "trigger times: 4\n",
      "Epoch: 020, Loss: 1.3790 \n",
      "trigger times: 5\n",
      "Epoch: 021, Loss: 1.3595 \n",
      "trigger times: 6\n",
      "Epoch: 022, Loss: 1.3566 \n",
      "trigger times: 7\n",
      "Epoch: 023, Loss: 1.3632 \n",
      "trigger times: 8\n",
      "Epoch: 024, Loss: 1.3907 \n",
      "trigger times: 9\n",
      "Epoch: 025, Loss: 1.3766 \n",
      "trigger times: 10\n",
      "Epoch: 026, Loss: 1.3646 \n",
      "trigger times: 11\n",
      "Epoch: 027, Loss: 1.3526 \n",
      "trigger times: 12\n",
      "Epoch: 028, Loss: 1.4003 \n",
      "trigger times: 13\n",
      "Epoch: 029, Loss: 1.3565 \n",
      "trigger times: 14\n",
      "Epoch: 030, Loss: 1.3689 \n",
      "trigger times: 15\n",
      "Epoch: 031, Loss: 1.3489 \n",
      "trigger times: 16\n",
      "Epoch: 032, Loss: 1.3804 \n",
      "trigger times: 17\n",
      "Epoch: 033, Loss: 1.3813 \n",
      "trigger times: 18\n",
      "Epoch: 034, Loss: 1.3540 \n",
      "trigger times: 19\n",
      "Epoch: 035, Loss: 1.3568 \n",
      "trigger times: 20\n",
      "Epoch: 036, Loss: 1.3702 \n",
      "trigger times: 21\n",
      "Epoch: 037, Loss: 1.3479 \n",
      "trigger times: 22\n",
      "Epoch: 038, Loss: 1.3740 \n",
      "trigger times: 23\n",
      "Epoch: 039, Loss: 1.3519 \n",
      "trigger times: 24\n",
      "Epoch: 040, Loss: 1.3510 \n",
      "trigger times: 25\n",
      "Epoch: 041, Loss: 1.3777 \n",
      "trigger times: 26\n",
      "Epoch: 042, Loss: 1.3634 \n",
      "trigger times: 27\n",
      "Epoch: 043, Loss: 1.3733 \n",
      "trigger times: 28\n",
      "Epoch: 044, Loss: 1.3721 \n",
      "trigger times: 29\n",
      "Epoch: 045, Loss: 1.3674 \n",
      "trigger times: 30\n",
      "Epoch: 046, Loss: 1.3687 \n",
      "trigger times: 31\n",
      "Epoch: 047, Loss: 1.3715 \n",
      "trigger times: 32\n",
      "Epoch: 048, Loss: 1.3618 \n",
      "trigger times: 33\n",
      "Epoch: 049, Loss: 1.4036 \n",
      "trigger times: 34\n",
      "Epoch: 050, Loss: 1.3612 \n",
      "trigger times: 35\n",
      "Epoch: 051, Loss: 1.3554 \n",
      "trigger times: 36\n",
      "Epoch: 052, Loss: 1.3506 \n",
      "trigger times: 37\n",
      "Epoch: 053, Loss: 1.3476 \n",
      "trigger times: 38\n",
      "Epoch: 054, Loss: 1.3694 \n",
      "trigger times: 39\n",
      "Epoch: 055, Loss: 1.3656 \n",
      "trigger times: 40\n",
      "Epoch: 056, Loss: 1.3704 \n",
      "trigger times: 41\n",
      "Epoch: 057, Loss: 1.3714 \n",
      "trigger times: 42\n",
      "Epoch: 058, Loss: 1.3670 \n",
      "trigger times: 43\n",
      "Epoch: 059, Loss: 1.3640 \n",
      "trigger times: 44\n",
      "Epoch: 060, Loss: 1.3579 \n",
      "trigger times: 45\n",
      "Epoch: 061, Loss: 1.3515 \n",
      "trigger times: 46\n",
      "Epoch: 062, Loss: 1.3580 \n",
      "trigger times: 47\n",
      "Epoch: 063, Loss: 1.3508 \n",
      "trigger times: 48\n",
      "Epoch: 064, Loss: 1.3574 \n",
      "trigger times: 49\n",
      "Epoch: 065, Loss: 1.3772 \n",
      "trigger times: 50\n",
      "Epoch: 066, Loss: 1.3542 \n",
      "trigger times: 51\n",
      "Epoch: 067, Loss: 1.3761 \n",
      "trigger times: 52\n",
      "Epoch: 068, Loss: 1.3840 \n",
      "trigger times: 53\n",
      "Epoch: 069, Loss: 1.3709 \n",
      "trigger times: 54\n",
      "Epoch: 070, Loss: 1.4005 \n",
      "trigger times: 55\n",
      "Epoch: 071, Loss: 1.3683 \n",
      "trigger times: 56\n",
      "Epoch: 072, Loss: 1.3697 \n",
      "trigger times: 57\n",
      "Epoch: 073, Loss: 1.3683 \n",
      "trigger times: 58\n",
      "Epoch: 074, Loss: 1.3551 \n",
      "trigger times: 59\n",
      "Epoch: 075, Loss: 1.3494 \n",
      "trigger times: 60\n",
      "Epoch: 076, Loss: 1.3586 \n",
      "trigger times: 61\n",
      "Epoch: 077, Loss: 1.3500 \n",
      "trigger times: 62\n",
      "Epoch: 078, Loss: 1.3786 \n",
      "trigger times: 63\n",
      "Epoch: 079, Loss: 1.3682 \n",
      "trigger times: 64\n",
      "Epoch: 080, Loss: 1.3682 \n",
      "trigger times: 65\n",
      "Epoch: 081, Loss: 1.3886 \n",
      "trigger times: 66\n",
      "Epoch: 082, Loss: 1.3754 \n",
      "trigger times: 67\n",
      "Epoch: 083, Loss: 1.3730 \n",
      "trigger times: 68\n",
      "Epoch: 084, Loss: 1.3628 \n",
      "trigger times: 69\n",
      "Epoch: 085, Loss: 1.4035 \n",
      "trigger times: 70\n",
      "Epoch: 086, Loss: 1.3446 \n",
      "trigger times: 71\n",
      "Epoch: 087, Loss: 1.3470 \n",
      "trigger times: 72\n",
      "Epoch: 088, Loss: 1.3618 \n",
      "trigger times: 73\n",
      "Epoch: 089, Loss: 1.3694 \n",
      "trigger times: 74\n",
      "Epoch: 090, Loss: 1.3564 \n",
      "trigger times: 75\n",
      "Epoch: 091, Loss: 1.3681 \n",
      "trigger times: 76\n",
      "Epoch: 092, Loss: 1.3667 \n",
      "trigger times: 77\n",
      "Epoch: 093, Loss: 1.3612 \n",
      "trigger times: 78\n",
      "Epoch: 094, Loss: 1.3492 \n",
      "trigger times: 79\n",
      "Epoch: 095, Loss: 1.3808 \n",
      "trigger times: 80\n",
      "Epoch: 096, Loss: 1.4096 \n",
      "trigger times: 81\n",
      "Epoch: 097, Loss: 1.3594 \n",
      "trigger times: 82\n",
      "Epoch: 098, Loss: 1.3510 \n",
      "trigger times: 83\n",
      "Epoch: 099, Loss: 1.3648 \n",
      "trigger times: 84\n",
      "Epoch: 100, Loss: 1.3973 \n",
      "trigger times: 85\n",
      "Epoch: 101, Loss: 1.3739 \n",
      "trigger times: 86\n",
      "Epoch: 102, Loss: 1.3678 \n",
      "trigger times: 87\n",
      "Epoch: 103, Loss: 1.3523 \n",
      "trigger times: 88\n",
      "Epoch: 104, Loss: 1.3613 \n",
      "trigger times: 89\n",
      "Epoch: 105, Loss: 1.3559 \n",
      "trigger times: 90\n",
      "Epoch: 106, Loss: 1.3891 \n",
      "trigger times: 91\n",
      "Epoch: 107, Loss: 1.3515 \n",
      "trigger times: 92\n",
      "Epoch: 108, Loss: 1.3784 \n",
      "trigger times: 93\n",
      "Epoch: 109, Loss: 1.3419 \n",
      "trigger times: 94\n",
      "Epoch: 110, Loss: 1.3665 \n",
      "trigger times: 95\n",
      "Epoch: 111, Loss: 1.3474 \n",
      "trigger times: 96\n",
      "Epoch: 112, Loss: 1.3569 \n",
      "trigger times: 97\n",
      "Epoch: 113, Loss: 1.3663 \n",
      "trigger times: 98\n",
      "Epoch: 114, Loss: 1.3698 \n",
      "trigger times: 99\n",
      "Epoch: 115, Loss: 1.3682 \n",
      "trigger times: 100\n",
      "Epoch: 116, Loss: 1.3709 \n",
      "trigger times: 101\n",
      "Epoch: 117, Loss: 1.3696 \n",
      "trigger times: 102\n",
      "Epoch: 118, Loss: 1.3552 \n",
      "trigger times: 103\n",
      "Epoch: 119, Loss: 1.3761 \n",
      "trigger times: 104\n",
      "Epoch: 120, Loss: 1.3542 \n",
      "trigger times: 105\n",
      "Epoch: 121, Loss: 1.3497 \n",
      "trigger times: 106\n",
      "Epoch: 122, Loss: 1.3527 \n",
      "trigger times: 107\n",
      "Epoch: 123, Loss: 1.3771 \n",
      "trigger times: 108\n",
      "Epoch: 124, Loss: 1.3464 \n",
      "trigger times: 109\n",
      "Epoch: 125, Loss: 1.3494 \n",
      "trigger times: 110\n",
      "Epoch: 126, Loss: 1.3596 \n",
      "trigger times: 111\n",
      "Epoch: 127, Loss: 1.3551 \n",
      "trigger times: 112\n",
      "Epoch: 128, Loss: 1.3770 \n",
      "trigger times: 113\n",
      "Epoch: 129, Loss: 1.3790 \n",
      "trigger times: 114\n",
      "Epoch: 130, Loss: 1.3489 \n",
      "trigger times: 115\n",
      "Epoch: 131, Loss: 1.3595 \n",
      "trigger times: 116\n",
      "Epoch: 132, Loss: 1.3724 \n",
      "trigger times: 117\n",
      "Epoch: 133, Loss: 1.3481 \n",
      "trigger times: 118\n",
      "Epoch: 134, Loss: 1.3611 \n",
      "trigger times: 119\n",
      "Epoch: 135, Loss: 1.3591 \n",
      "trigger times: 120\n",
      "Epoch: 136, Loss: 1.3571 \n",
      "trigger times: 121\n",
      "Epoch: 137, Loss: 1.3608 \n",
      "trigger times: 122\n",
      "Epoch: 138, Loss: 1.3452 \n",
      "trigger times: 123\n",
      "Epoch: 139, Loss: 1.3745 \n",
      "trigger times: 124\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 140, Loss: 1.3570 \n",
      "trigger times: 125\n",
      "Epoch: 141, Loss: 1.3459 \n",
      "trigger times: 126\n",
      "Epoch: 142, Loss: 1.3630 \n",
      "trigger times: 127\n",
      "Epoch: 143, Loss: 1.3667 \n",
      "trigger times: 128\n",
      "Epoch: 144, Loss: 1.3834 \n",
      "trigger times: 129\n",
      "Epoch: 145, Loss: 1.3386 \n",
      "Epoch: 146, Loss: 1.3622 \n",
      "trigger times: 1\n",
      "Epoch: 147, Loss: 1.3720 \n",
      "trigger times: 2\n",
      "Epoch: 148, Loss: 1.3773 \n",
      "trigger times: 3\n",
      "Epoch: 149, Loss: 1.3689 \n",
      "trigger times: 4\n",
      "Epoch: 150, Loss: 1.3535 \n",
      "trigger times: 5\n",
      "Epoch: 151, Loss: 1.3492 \n",
      "trigger times: 6\n",
      "Epoch: 152, Loss: 1.3560 \n",
      "trigger times: 7\n",
      "Epoch: 153, Loss: 1.3603 \n",
      "trigger times: 8\n",
      "Epoch: 154, Loss: 1.3838 \n",
      "trigger times: 9\n",
      "Epoch: 155, Loss: 1.3545 \n",
      "trigger times: 10\n",
      "Epoch: 156, Loss: 1.3505 \n",
      "trigger times: 11\n",
      "Epoch: 157, Loss: 1.3686 \n",
      "trigger times: 12\n",
      "Epoch: 158, Loss: 1.3588 \n",
      "trigger times: 13\n",
      "Epoch: 159, Loss: 1.3582 \n",
      "trigger times: 14\n",
      "Epoch: 160, Loss: 1.3682 \n",
      "trigger times: 15\n",
      "Epoch: 161, Loss: 1.3580 \n",
      "trigger times: 16\n",
      "Epoch: 162, Loss: 1.3791 \n",
      "trigger times: 17\n",
      "Epoch: 163, Loss: 1.3626 \n",
      "trigger times: 18\n",
      "Epoch: 164, Loss: 1.3777 \n",
      "trigger times: 19\n",
      "Epoch: 165, Loss: 1.3551 \n",
      "trigger times: 20\n",
      "Epoch: 166, Loss: 1.3474 \n",
      "trigger times: 21\n",
      "Epoch: 167, Loss: 1.3523 \n",
      "trigger times: 22\n",
      "Epoch: 168, Loss: 1.3618 \n",
      "trigger times: 23\n",
      "Epoch: 169, Loss: 1.3648 \n",
      "trigger times: 24\n",
      "Epoch: 170, Loss: 1.3589 \n",
      "trigger times: 25\n",
      "Epoch: 171, Loss: 1.3604 \n",
      "trigger times: 26\n",
      "Epoch: 172, Loss: 1.3961 \n",
      "trigger times: 27\n",
      "Epoch: 173, Loss: 1.3512 \n",
      "trigger times: 28\n",
      "Epoch: 174, Loss: 1.3580 \n",
      "trigger times: 29\n",
      "Epoch: 175, Loss: 1.3668 \n",
      "trigger times: 30\n",
      "Epoch: 176, Loss: 1.3894 \n",
      "trigger times: 31\n",
      "Epoch: 177, Loss: 1.3506 \n",
      "trigger times: 32\n",
      "Epoch: 178, Loss: 1.3594 \n",
      "trigger times: 33\n",
      "Epoch: 179, Loss: 1.3689 \n",
      "trigger times: 34\n",
      "Epoch: 180, Loss: 1.3787 \n",
      "trigger times: 35\n",
      "Epoch: 181, Loss: 1.3649 \n",
      "trigger times: 36\n",
      "Epoch: 182, Loss: 1.3477 \n",
      "trigger times: 37\n",
      "Epoch: 183, Loss: 1.3610 \n",
      "trigger times: 38\n",
      "Epoch: 184, Loss: 1.3472 \n",
      "trigger times: 39\n",
      "Epoch: 185, Loss: 1.3590 \n",
      "trigger times: 40\n",
      "Epoch: 186, Loss: 1.3947 \n",
      "trigger times: 41\n",
      "Epoch: 187, Loss: 1.3621 \n",
      "trigger times: 42\n",
      "Epoch: 188, Loss: 1.3525 \n",
      "trigger times: 43\n",
      "Epoch: 189, Loss: 1.3569 \n",
      "trigger times: 44\n",
      "Epoch: 190, Loss: 1.3850 \n",
      "trigger times: 45\n",
      "Epoch: 191, Loss: 1.3629 \n",
      "trigger times: 46\n",
      "Epoch: 192, Loss: 1.3529 \n",
      "trigger times: 47\n",
      "Epoch: 193, Loss: 1.3736 \n",
      "trigger times: 48\n",
      "Epoch: 194, Loss: 1.3658 \n",
      "trigger times: 49\n",
      "Epoch: 195, Loss: 1.3559 \n",
      "trigger times: 50\n",
      "Epoch: 196, Loss: 1.4125 \n",
      "trigger times: 51\n",
      "Epoch: 197, Loss: 1.3554 \n",
      "trigger times: 52\n",
      "Epoch: 198, Loss: 1.3567 \n",
      "trigger times: 53\n",
      "Epoch: 199, Loss: 1.3552 \n",
      "trigger times: 54\n",
      "Epoch: 000, Loss: 1.3536 \n",
      "Epoch: 001, Loss: 1.3265 \n",
      "Epoch: 002, Loss: 1.3265 \n",
      "trigger times: 1\n",
      "Epoch: 003, Loss: 1.3269 \n",
      "trigger times: 2\n",
      "Epoch: 004, Loss: 1.3380 \n",
      "trigger times: 3\n",
      "Epoch: 005, Loss: 1.3168 \n",
      "Epoch: 006, Loss: 1.3137 \n",
      "Epoch: 007, Loss: 1.3364 \n",
      "trigger times: 1\n",
      "Epoch: 008, Loss: 1.3392 \n",
      "trigger times: 2\n",
      "Epoch: 009, Loss: 1.3252 \n",
      "trigger times: 3\n",
      "Epoch: 010, Loss: 1.3167 \n",
      "trigger times: 4\n",
      "Epoch: 011, Loss: 1.3277 \n",
      "trigger times: 5\n",
      "Epoch: 012, Loss: 1.3375 \n",
      "trigger times: 6\n",
      "Epoch: 013, Loss: 1.3415 \n",
      "trigger times: 7\n",
      "Epoch: 014, Loss: 1.3321 \n",
      "trigger times: 8\n",
      "Epoch: 015, Loss: 1.3490 \n",
      "trigger times: 9\n",
      "Epoch: 016, Loss: 1.3145 \n",
      "trigger times: 10\n",
      "Epoch: 017, Loss: 1.3205 \n",
      "trigger times: 11\n",
      "Epoch: 018, Loss: 1.3373 \n",
      "trigger times: 12\n",
      "Epoch: 019, Loss: 1.3145 \n",
      "trigger times: 13\n",
      "Epoch: 020, Loss: 1.3163 \n",
      "trigger times: 14\n",
      "Epoch: 021, Loss: 1.3182 \n",
      "trigger times: 15\n",
      "Epoch: 022, Loss: 1.3351 \n",
      "trigger times: 16\n",
      "Epoch: 023, Loss: 1.3383 \n",
      "trigger times: 17\n",
      "Epoch: 024, Loss: 1.3442 \n",
      "trigger times: 18\n",
      "Epoch: 025, Loss: 1.3315 \n",
      "trigger times: 19\n",
      "Epoch: 026, Loss: 1.3139 \n",
      "trigger times: 20\n",
      "Epoch: 027, Loss: 1.3061 \n",
      "Epoch: 028, Loss: 1.3174 \n",
      "trigger times: 1\n",
      "Epoch: 029, Loss: 1.3445 \n",
      "trigger times: 2\n",
      "Epoch: 030, Loss: 1.3181 \n",
      "trigger times: 3\n",
      "Epoch: 031, Loss: 1.3427 \n",
      "trigger times: 4\n",
      "Epoch: 032, Loss: 1.2996 \n",
      "Epoch: 033, Loss: 1.3175 \n",
      "trigger times: 1\n",
      "Epoch: 034, Loss: 1.3130 \n",
      "trigger times: 2\n",
      "Epoch: 035, Loss: 1.3384 \n",
      "trigger times: 3\n",
      "Epoch: 036, Loss: 1.3298 \n",
      "trigger times: 4\n",
      "Epoch: 037, Loss: 1.3473 \n",
      "trigger times: 5\n",
      "Epoch: 038, Loss: 1.3265 \n",
      "trigger times: 6\n",
      "Epoch: 039, Loss: 1.3509 \n",
      "trigger times: 7\n",
      "Epoch: 040, Loss: 1.3278 \n",
      "trigger times: 8\n",
      "Epoch: 041, Loss: 1.3147 \n",
      "trigger times: 9\n",
      "Epoch: 042, Loss: 1.3065 \n",
      "trigger times: 10\n",
      "Epoch: 043, Loss: 1.3399 \n",
      "trigger times: 11\n",
      "Epoch: 044, Loss: 1.3525 \n",
      "trigger times: 12\n",
      "Epoch: 045, Loss: 1.3104 \n",
      "trigger times: 13\n",
      "Epoch: 046, Loss: 1.3235 \n",
      "trigger times: 14\n",
      "Epoch: 047, Loss: 1.3222 \n",
      "trigger times: 15\n",
      "Epoch: 048, Loss: 1.3297 \n",
      "trigger times: 16\n",
      "Epoch: 049, Loss: 1.3266 \n",
      "trigger times: 17\n",
      "Epoch: 050, Loss: 1.3010 \n",
      "trigger times: 18\n",
      "Epoch: 051, Loss: 1.3225 \n",
      "trigger times: 19\n",
      "Epoch: 052, Loss: 1.3264 \n",
      "trigger times: 20\n",
      "Epoch: 053, Loss: 1.3288 \n",
      "trigger times: 21\n",
      "Epoch: 054, Loss: 1.3313 \n",
      "trigger times: 22\n",
      "Epoch: 055, Loss: 1.3199 \n",
      "trigger times: 23\n",
      "Epoch: 056, Loss: 1.3154 \n",
      "trigger times: 24\n",
      "Epoch: 057, Loss: 1.3296 \n",
      "trigger times: 25\n",
      "Epoch: 058, Loss: 1.3215 \n",
      "trigger times: 26\n",
      "Epoch: 059, Loss: 1.3293 \n",
      "trigger times: 27\n",
      "Epoch: 060, Loss: 1.3130 \n",
      "trigger times: 28\n",
      "Epoch: 061, Loss: 1.3079 \n",
      "trigger times: 29\n",
      "Epoch: 062, Loss: 1.3263 \n",
      "trigger times: 30\n",
      "Epoch: 063, Loss: 1.3337 \n",
      "trigger times: 31\n",
      "Epoch: 064, Loss: 1.3288 \n",
      "trigger times: 32\n",
      "Epoch: 065, Loss: 1.3262 \n",
      "trigger times: 33\n",
      "Epoch: 066, Loss: 1.3293 \n",
      "trigger times: 34\n",
      "Epoch: 067, Loss: 1.3197 \n",
      "trigger times: 35\n",
      "Epoch: 068, Loss: 1.3080 \n",
      "trigger times: 36\n",
      "Epoch: 069, Loss: 1.3099 \n",
      "trigger times: 37\n",
      "Epoch: 070, Loss: 1.3721 \n",
      "trigger times: 38\n",
      "Epoch: 071, Loss: 1.3309 \n",
      "trigger times: 39\n",
      "Epoch: 072, Loss: 1.3135 \n",
      "trigger times: 40\n",
      "Epoch: 073, Loss: 1.3222 \n",
      "trigger times: 41\n",
      "Epoch: 074, Loss: 1.3753 \n",
      "trigger times: 42\n",
      "Epoch: 075, Loss: 1.3327 \n",
      "trigger times: 43\n",
      "Epoch: 076, Loss: 1.3408 \n",
      "trigger times: 44\n",
      "Epoch: 077, Loss: 1.3183 \n",
      "trigger times: 45\n",
      "Epoch: 078, Loss: 1.3351 \n",
      "trigger times: 46\n",
      "Epoch: 079, Loss: 1.3041 \n",
      "trigger times: 47\n",
      "Epoch: 080, Loss: 1.3235 \n",
      "trigger times: 48\n",
      "Epoch: 081, Loss: 1.3078 \n",
      "trigger times: 49\n",
      "Epoch: 082, Loss: 1.3179 \n",
      "trigger times: 50\n",
      "Epoch: 083, Loss: 1.3130 \n",
      "trigger times: 51\n",
      "Epoch: 084, Loss: 1.3239 \n",
      "trigger times: 52\n",
      "Epoch: 085, Loss: 1.3455 \n",
      "trigger times: 53\n",
      "Epoch: 086, Loss: 1.3195 \n",
      "trigger times: 54\n",
      "Epoch: 087, Loss: 1.3211 \n",
      "trigger times: 55\n",
      "Epoch: 088, Loss: 1.3196 \n",
      "trigger times: 56\n",
      "Epoch: 089, Loss: 1.3130 \n",
      "trigger times: 57\n",
      "Epoch: 090, Loss: 1.3246 \n",
      "trigger times: 58\n",
      "Epoch: 091, Loss: 1.2994 \n",
      "Epoch: 092, Loss: 1.3187 \n",
      "trigger times: 1\n",
      "Epoch: 093, Loss: 1.3165 \n",
      "trigger times: 2\n",
      "Epoch: 094, Loss: 1.3097 \n",
      "trigger times: 3\n",
      "Epoch: 095, Loss: 1.3158 \n",
      "trigger times: 4\n",
      "Epoch: 096, Loss: 1.3242 \n",
      "trigger times: 5\n",
      "Epoch: 097, Loss: 1.3256 \n",
      "trigger times: 6\n",
      "Epoch: 098, Loss: 1.3135 \n",
      "trigger times: 7\n",
      "Epoch: 099, Loss: 1.3102 \n",
      "trigger times: 8\n",
      "Epoch: 100, Loss: 1.3404 \n",
      "trigger times: 9\n",
      "Epoch: 101, Loss: 1.3196 \n",
      "trigger times: 10\n",
      "Epoch: 102, Loss: 1.3286 \n",
      "trigger times: 11\n",
      "Epoch: 103, Loss: 1.3168 \n",
      "trigger times: 12\n",
      "Epoch: 104, Loss: 1.3345 \n",
      "trigger times: 13\n",
      "Epoch: 105, Loss: 1.3247 \n",
      "trigger times: 14\n",
      "Epoch: 106, Loss: 1.3059 \n",
      "trigger times: 15\n",
      "Epoch: 107, Loss: 1.3067 \n",
      "trigger times: 16\n",
      "Epoch: 108, Loss: 1.3084 \n",
      "trigger times: 17\n",
      "Epoch: 109, Loss: 1.3089 \n",
      "trigger times: 18\n",
      "Epoch: 110, Loss: 1.3056 \n",
      "trigger times: 19\n",
      "Epoch: 111, Loss: 1.3245 \n",
      "trigger times: 20\n",
      "Epoch: 112, Loss: 1.3315 \n",
      "trigger times: 21\n",
      "Epoch: 113, Loss: 1.3381 \n",
      "trigger times: 22\n",
      "Epoch: 114, Loss: 1.3263 \n",
      "trigger times: 23\n",
      "Epoch: 115, Loss: 1.3182 \n",
      "trigger times: 24\n",
      "Epoch: 116, Loss: 1.3160 \n",
      "trigger times: 25\n",
      "Epoch: 117, Loss: 1.2998 \n",
      "trigger times: 26\n",
      "Epoch: 118, Loss: 1.3268 \n",
      "trigger times: 27\n",
      "Epoch: 119, Loss: 1.3004 \n",
      "trigger times: 28\n",
      "Epoch: 120, Loss: 1.3222 \n",
      "trigger times: 29\n",
      "Epoch: 121, Loss: 1.3071 \n",
      "trigger times: 30\n",
      "Epoch: 122, Loss: 1.3066 \n",
      "trigger times: 31\n",
      "Epoch: 123, Loss: 1.3405 \n",
      "trigger times: 32\n",
      "Epoch: 124, Loss: 1.3251 \n",
      "trigger times: 33\n",
      "Epoch: 125, Loss: 1.3236 \n",
      "trigger times: 34\n",
      "Epoch: 126, Loss: 1.3048 \n",
      "trigger times: 35\n",
      "Epoch: 127, Loss: 1.3234 \n",
      "trigger times: 36\n",
      "Epoch: 128, Loss: 1.3194 \n",
      "trigger times: 37\n",
      "Epoch: 129, Loss: 1.3228 \n",
      "trigger times: 38\n",
      "Epoch: 130, Loss: 1.3126 \n",
      "trigger times: 39\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 131, Loss: 1.3004 \n",
      "trigger times: 40\n",
      "Epoch: 132, Loss: 1.3111 \n",
      "trigger times: 41\n",
      "Epoch: 133, Loss: 1.2998 \n",
      "trigger times: 42\n",
      "Epoch: 134, Loss: 1.3227 \n",
      "trigger times: 43\n",
      "Epoch: 135, Loss: 1.3178 \n",
      "trigger times: 44\n",
      "Epoch: 136, Loss: 1.3266 \n",
      "trigger times: 45\n",
      "Epoch: 137, Loss: 1.3054 \n",
      "trigger times: 46\n",
      "Epoch: 138, Loss: 1.3114 \n",
      "trigger times: 47\n",
      "Epoch: 139, Loss: 1.3302 \n",
      "trigger times: 48\n",
      "Epoch: 140, Loss: 1.3185 \n",
      "trigger times: 49\n",
      "Epoch: 141, Loss: 1.3020 \n",
      "trigger times: 50\n",
      "Epoch: 142, Loss: 1.3236 \n",
      "trigger times: 51\n",
      "Epoch: 143, Loss: 1.3040 \n",
      "trigger times: 52\n",
      "Epoch: 144, Loss: 1.3114 \n",
      "trigger times: 53\n",
      "Epoch: 145, Loss: 1.3059 \n",
      "trigger times: 54\n",
      "Epoch: 146, Loss: 1.3246 \n",
      "trigger times: 55\n",
      "Epoch: 147, Loss: 1.3231 \n",
      "trigger times: 56\n",
      "Epoch: 148, Loss: 1.2933 \n",
      "Epoch: 149, Loss: 1.2973 \n",
      "trigger times: 1\n",
      "Epoch: 150, Loss: 1.2881 \n",
      "Epoch: 151, Loss: 1.3034 \n",
      "trigger times: 1\n",
      "Epoch: 152, Loss: 1.3066 \n",
      "trigger times: 2\n",
      "Epoch: 153, Loss: 1.3138 \n",
      "trigger times: 3\n",
      "Epoch: 154, Loss: 1.2996 \n",
      "trigger times: 4\n",
      "Epoch: 155, Loss: 1.3021 \n",
      "trigger times: 5\n",
      "Epoch: 156, Loss: 1.3034 \n",
      "trigger times: 6\n",
      "Epoch: 157, Loss: 1.3563 \n",
      "trigger times: 7\n",
      "Epoch: 158, Loss: 1.3032 \n",
      "trigger times: 8\n",
      "Epoch: 159, Loss: 1.3159 \n",
      "trigger times: 9\n",
      "Epoch: 160, Loss: 1.3099 \n",
      "trigger times: 10\n",
      "Epoch: 161, Loss: 1.3057 \n",
      "trigger times: 11\n",
      "Epoch: 162, Loss: 1.2994 \n",
      "trigger times: 12\n",
      "Epoch: 163, Loss: 1.2851 \n",
      "Epoch: 164, Loss: 1.3294 \n",
      "trigger times: 1\n",
      "Epoch: 165, Loss: 1.3003 \n",
      "trigger times: 2\n",
      "Epoch: 166, Loss: 1.2976 \n",
      "trigger times: 3\n",
      "Epoch: 167, Loss: 1.3034 \n",
      "trigger times: 4\n",
      "Epoch: 168, Loss: 1.3037 \n",
      "trigger times: 5\n",
      "Epoch: 169, Loss: 1.3052 \n",
      "trigger times: 6\n",
      "Epoch: 170, Loss: 1.2991 \n",
      "trigger times: 7\n",
      "Epoch: 171, Loss: 1.3135 \n",
      "trigger times: 8\n",
      "Epoch: 172, Loss: 1.2929 \n",
      "trigger times: 9\n",
      "Epoch: 173, Loss: 1.2944 \n",
      "trigger times: 10\n",
      "Epoch: 174, Loss: 1.2906 \n",
      "trigger times: 11\n",
      "Epoch: 175, Loss: 1.3299 \n",
      "trigger times: 12\n",
      "Epoch: 176, Loss: 1.3135 \n",
      "trigger times: 13\n",
      "Epoch: 177, Loss: 1.3018 \n",
      "trigger times: 14\n",
      "Epoch: 178, Loss: 1.2839 \n",
      "Epoch: 179, Loss: 1.2955 \n",
      "trigger times: 1\n",
      "Epoch: 180, Loss: 1.2917 \n",
      "trigger times: 2\n",
      "Epoch: 181, Loss: 1.2924 \n",
      "trigger times: 3\n",
      "Epoch: 182, Loss: 1.3129 \n",
      "trigger times: 4\n",
      "Epoch: 183, Loss: 1.2904 \n",
      "trigger times: 5\n",
      "Epoch: 184, Loss: 1.2905 \n",
      "trigger times: 6\n",
      "Epoch: 185, Loss: 1.3017 \n",
      "trigger times: 7\n",
      "Epoch: 186, Loss: 1.2876 \n",
      "trigger times: 8\n",
      "Epoch: 187, Loss: 1.2851 \n",
      "trigger times: 9\n",
      "Epoch: 188, Loss: 1.3099 \n",
      "trigger times: 10\n",
      "Epoch: 189, Loss: 1.2889 \n",
      "trigger times: 11\n",
      "Epoch: 190, Loss: 1.2876 \n",
      "trigger times: 12\n",
      "Epoch: 191, Loss: 1.3010 \n",
      "trigger times: 13\n",
      "Epoch: 192, Loss: 1.3088 \n",
      "trigger times: 14\n",
      "Epoch: 193, Loss: 1.3083 \n",
      "trigger times: 15\n",
      "Epoch: 194, Loss: 1.3120 \n",
      "trigger times: 16\n",
      "Epoch: 195, Loss: 1.3025 \n",
      "trigger times: 17\n",
      "Epoch: 196, Loss: 1.3128 \n",
      "trigger times: 18\n",
      "Epoch: 197, Loss: 1.2937 \n",
      "trigger times: 19\n",
      "Epoch: 198, Loss: 1.3077 \n",
      "trigger times: 20\n",
      "Epoch: 199, Loss: 1.3003 \n",
      "trigger times: 21\n",
      "Epoch: 000, Loss: 1.2989 \n",
      "Epoch: 001, Loss: 1.2783 \n",
      "Epoch: 002, Loss: 1.2975 \n",
      "trigger times: 1\n",
      "Epoch: 003, Loss: 1.2826 \n",
      "trigger times: 2\n",
      "Epoch: 004, Loss: 1.2761 \n",
      "Epoch: 005, Loss: 1.2969 \n",
      "trigger times: 1\n",
      "Epoch: 006, Loss: 1.2869 \n",
      "trigger times: 2\n",
      "Epoch: 007, Loss: 1.3021 \n",
      "trigger times: 3\n",
      "Epoch: 008, Loss: 1.2836 \n",
      "trigger times: 4\n",
      "Epoch: 009, Loss: 1.2835 \n",
      "trigger times: 5\n",
      "Epoch: 010, Loss: 1.2850 \n",
      "trigger times: 6\n",
      "Epoch: 011, Loss: 1.2770 \n",
      "trigger times: 7\n",
      "Epoch: 012, Loss: 1.2994 \n",
      "trigger times: 8\n",
      "Epoch: 013, Loss: 1.2859 \n",
      "trigger times: 9\n",
      "Epoch: 014, Loss: 1.3122 \n",
      "trigger times: 10\n",
      "Epoch: 015, Loss: 1.3115 \n",
      "trigger times: 11\n",
      "Epoch: 016, Loss: 1.2786 \n",
      "trigger times: 12\n",
      "Epoch: 017, Loss: 1.2814 \n",
      "trigger times: 13\n",
      "Epoch: 018, Loss: 1.2853 \n",
      "trigger times: 14\n",
      "Epoch: 019, Loss: 1.2861 \n",
      "trigger times: 15\n",
      "Epoch: 020, Loss: 1.3006 \n",
      "trigger times: 16\n",
      "Epoch: 021, Loss: 1.2878 \n",
      "trigger times: 17\n",
      "Epoch: 022, Loss: 1.2733 \n",
      "Epoch: 023, Loss: 1.2937 \n",
      "trigger times: 1\n",
      "Epoch: 024, Loss: 1.2988 \n",
      "trigger times: 2\n",
      "Epoch: 025, Loss: 1.2856 \n",
      "trigger times: 3\n",
      "Epoch: 026, Loss: 1.2870 \n",
      "trigger times: 4\n",
      "Epoch: 027, Loss: 1.2779 \n",
      "trigger times: 5\n",
      "Epoch: 028, Loss: 1.2689 \n",
      "Epoch: 029, Loss: 1.2896 \n",
      "trigger times: 1\n",
      "Epoch: 030, Loss: 1.2995 \n",
      "trigger times: 2\n",
      "Epoch: 031, Loss: 1.2942 \n",
      "trigger times: 3\n",
      "Epoch: 032, Loss: 1.2712 \n",
      "trigger times: 4\n",
      "Epoch: 033, Loss: 1.2690 \n",
      "trigger times: 5\n",
      "Epoch: 034, Loss: 1.2982 \n",
      "trigger times: 6\n",
      "Epoch: 035, Loss: 1.2924 \n",
      "trigger times: 7\n",
      "Epoch: 036, Loss: 1.2825 \n",
      "trigger times: 8\n",
      "Epoch: 037, Loss: 1.2732 \n",
      "trigger times: 9\n",
      "Epoch: 038, Loss: 1.2853 \n",
      "trigger times: 10\n",
      "Epoch: 039, Loss: 1.2696 \n",
      "trigger times: 11\n",
      "Epoch: 040, Loss: 1.2715 \n",
      "trigger times: 12\n",
      "Epoch: 041, Loss: 1.2722 \n",
      "trigger times: 13\n",
      "Epoch: 042, Loss: 1.2629 \n",
      "Epoch: 043, Loss: 1.2889 \n",
      "trigger times: 1\n",
      "Epoch: 044, Loss: 1.2944 \n",
      "trigger times: 2\n",
      "Epoch: 045, Loss: 1.2704 \n",
      "trigger times: 3\n",
      "Epoch: 046, Loss: 1.2788 \n",
      "trigger times: 4\n",
      "Epoch: 047, Loss: 1.2994 \n",
      "trigger times: 5\n",
      "Epoch: 048, Loss: 1.2848 \n",
      "trigger times: 6\n",
      "Epoch: 049, Loss: 1.2822 \n",
      "trigger times: 7\n",
      "Epoch: 050, Loss: 1.2663 \n",
      "trigger times: 8\n",
      "Epoch: 051, Loss: 1.3006 \n",
      "trigger times: 9\n",
      "Epoch: 052, Loss: 1.2673 \n",
      "trigger times: 10\n",
      "Epoch: 053, Loss: 1.2780 \n",
      "trigger times: 11\n",
      "Epoch: 054, Loss: 1.2690 \n",
      "trigger times: 12\n",
      "Epoch: 055, Loss: 1.2652 \n",
      "trigger times: 13\n",
      "Epoch: 056, Loss: 1.2869 \n",
      "trigger times: 14\n",
      "Epoch: 057, Loss: 1.2942 \n",
      "trigger times: 15\n",
      "Epoch: 058, Loss: 1.2679 \n",
      "trigger times: 16\n",
      "Epoch: 059, Loss: 1.2738 \n",
      "trigger times: 17\n",
      "Epoch: 060, Loss: 1.2813 \n",
      "trigger times: 18\n",
      "Epoch: 061, Loss: 1.2618 \n",
      "Epoch: 062, Loss: 1.2936 \n",
      "trigger times: 1\n",
      "Epoch: 063, Loss: 1.2683 \n",
      "trigger times: 2\n",
      "Epoch: 064, Loss: 1.2736 \n",
      "trigger times: 3\n",
      "Epoch: 065, Loss: 1.2988 \n",
      "trigger times: 4\n",
      "Epoch: 066, Loss: 1.2992 \n",
      "trigger times: 5\n",
      "Epoch: 067, Loss: 1.2821 \n",
      "trigger times: 6\n",
      "Epoch: 068, Loss: 1.2742 \n",
      "trigger times: 7\n",
      "Epoch: 069, Loss: 1.2832 \n",
      "trigger times: 8\n",
      "Epoch: 070, Loss: 1.2883 \n",
      "trigger times: 9\n",
      "Epoch: 071, Loss: 1.2711 \n",
      "trigger times: 10\n",
      "Epoch: 072, Loss: 1.2909 \n",
      "trigger times: 11\n",
      "Epoch: 073, Loss: 1.2756 \n",
      "trigger times: 12\n",
      "Epoch: 074, Loss: 1.2679 \n",
      "trigger times: 13\n",
      "Epoch: 075, Loss: 1.2758 \n",
      "trigger times: 14\n",
      "Epoch: 076, Loss: 1.3162 \n",
      "trigger times: 15\n",
      "Epoch: 077, Loss: 1.2708 \n",
      "trigger times: 16\n",
      "Epoch: 078, Loss: 1.2781 \n",
      "trigger times: 17\n",
      "Epoch: 079, Loss: 1.2642 \n",
      "trigger times: 18\n",
      "Epoch: 080, Loss: 1.2639 \n",
      "trigger times: 19\n",
      "Epoch: 081, Loss: 1.2683 \n",
      "trigger times: 20\n",
      "Epoch: 082, Loss: 1.2681 \n",
      "trigger times: 21\n",
      "Epoch: 083, Loss: 1.2821 \n",
      "trigger times: 22\n",
      "Epoch: 084, Loss: 1.2937 \n",
      "trigger times: 23\n",
      "Epoch: 085, Loss: 1.2866 \n",
      "trigger times: 24\n",
      "Epoch: 086, Loss: 1.2762 \n",
      "trigger times: 25\n",
      "Epoch: 087, Loss: 1.2593 \n",
      "Epoch: 088, Loss: 1.2980 \n",
      "trigger times: 1\n",
      "Epoch: 089, Loss: 1.2825 \n",
      "trigger times: 2\n",
      "Epoch: 090, Loss: 1.2719 \n",
      "trigger times: 3\n",
      "Epoch: 091, Loss: 1.2941 \n",
      "trigger times: 4\n",
      "Epoch: 092, Loss: 1.3235 \n",
      "trigger times: 5\n",
      "Epoch: 093, Loss: 1.2900 \n",
      "trigger times: 6\n",
      "Epoch: 094, Loss: 1.2720 \n",
      "trigger times: 7\n",
      "Epoch: 095, Loss: 1.2863 \n",
      "trigger times: 8\n",
      "Epoch: 096, Loss: 1.3003 \n",
      "trigger times: 9\n",
      "Epoch: 097, Loss: 1.2856 \n",
      "trigger times: 10\n",
      "Epoch: 098, Loss: 1.2627 \n",
      "trigger times: 11\n",
      "Epoch: 099, Loss: 1.2687 \n",
      "trigger times: 12\n",
      "Epoch: 100, Loss: 1.2701 \n",
      "trigger times: 13\n",
      "Epoch: 101, Loss: 1.3122 \n",
      "trigger times: 14\n",
      "Epoch: 102, Loss: 1.2743 \n",
      "trigger times: 15\n",
      "Epoch: 103, Loss: 1.2726 \n",
      "trigger times: 16\n",
      "Epoch: 104, Loss: 1.2934 \n",
      "trigger times: 17\n",
      "Epoch: 105, Loss: 1.2943 \n",
      "trigger times: 18\n",
      "Epoch: 106, Loss: 1.2630 \n",
      "trigger times: 19\n",
      "Epoch: 107, Loss: 1.2671 \n",
      "trigger times: 20\n",
      "Epoch: 108, Loss: 1.2934 \n",
      "trigger times: 21\n",
      "Epoch: 109, Loss: 1.2640 \n",
      "trigger times: 22\n",
      "Epoch: 110, Loss: 1.2656 \n",
      "trigger times: 23\n",
      "Epoch: 111, Loss: 1.2697 \n",
      "trigger times: 24\n",
      "Epoch: 112, Loss: 1.3147 \n",
      "trigger times: 25\n",
      "Epoch: 113, Loss: 1.2692 \n",
      "trigger times: 26\n",
      "Epoch: 114, Loss: 1.2746 \n",
      "trigger times: 27\n",
      "Epoch: 115, Loss: 1.2961 \n",
      "trigger times: 28\n",
      "Epoch: 116, Loss: 1.2605 \n",
      "trigger times: 29\n",
      "Epoch: 117, Loss: 1.2619 \n",
      "trigger times: 30\n",
      "Epoch: 118, Loss: 1.2750 \n",
      "trigger times: 31\n",
      "Epoch: 119, Loss: 1.2801 \n",
      "trigger times: 32\n",
      "Epoch: 120, Loss: 1.2789 \n",
      "trigger times: 33\n",
      "Epoch: 121, Loss: 1.2799 \n",
      "trigger times: 34\n",
      "Epoch: 122, Loss: 1.2674 \n",
      "trigger times: 35\n",
      "Epoch: 123, Loss: 1.2865 \n",
      "trigger times: 36\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 124, Loss: 1.2745 \n",
      "trigger times: 37\n",
      "Epoch: 125, Loss: 1.2692 \n",
      "trigger times: 38\n",
      "Epoch: 126, Loss: 1.2698 \n",
      "trigger times: 39\n",
      "Epoch: 127, Loss: 1.2804 \n",
      "trigger times: 40\n",
      "Epoch: 128, Loss: 1.2769 \n",
      "trigger times: 41\n",
      "Epoch: 129, Loss: 1.2923 \n",
      "trigger times: 42\n",
      "Epoch: 130, Loss: 1.2619 \n",
      "trigger times: 43\n",
      "Epoch: 131, Loss: 1.2752 \n",
      "trigger times: 44\n",
      "Epoch: 132, Loss: 1.2913 \n",
      "trigger times: 45\n",
      "Epoch: 133, Loss: 1.2796 \n",
      "trigger times: 46\n",
      "Epoch: 134, Loss: 1.2772 \n",
      "trigger times: 47\n",
      "Epoch: 135, Loss: 1.2626 \n",
      "trigger times: 48\n",
      "Epoch: 136, Loss: 1.2805 \n",
      "trigger times: 49\n",
      "Epoch: 137, Loss: 1.2706 \n",
      "trigger times: 50\n",
      "Epoch: 138, Loss: 1.2751 \n",
      "trigger times: 51\n",
      "Epoch: 139, Loss: 1.2699 \n",
      "trigger times: 52\n",
      "Epoch: 140, Loss: 1.2743 \n",
      "trigger times: 53\n",
      "Epoch: 141, Loss: 1.2752 \n",
      "trigger times: 54\n",
      "Epoch: 142, Loss: 1.2797 \n",
      "trigger times: 55\n",
      "Epoch: 143, Loss: 1.2643 \n",
      "trigger times: 56\n",
      "Epoch: 144, Loss: 1.2727 \n",
      "trigger times: 57\n",
      "Epoch: 145, Loss: 1.2770 \n",
      "trigger times: 58\n",
      "Epoch: 146, Loss: 1.2796 \n",
      "trigger times: 59\n",
      "Epoch: 147, Loss: 1.2900 \n",
      "trigger times: 60\n",
      "Epoch: 148, Loss: 1.2634 \n",
      "trigger times: 61\n",
      "Epoch: 149, Loss: 1.2713 \n",
      "trigger times: 62\n",
      "Epoch: 150, Loss: 1.2656 \n",
      "trigger times: 63\n",
      "Epoch: 151, Loss: 1.2722 \n",
      "trigger times: 64\n",
      "Epoch: 152, Loss: 1.2619 \n",
      "trigger times: 65\n",
      "Epoch: 153, Loss: 1.2942 \n",
      "trigger times: 66\n",
      "Epoch: 154, Loss: 1.2915 \n",
      "trigger times: 67\n",
      "Epoch: 155, Loss: 1.2703 \n",
      "trigger times: 68\n",
      "Epoch: 156, Loss: 1.2660 \n",
      "trigger times: 69\n",
      "Epoch: 157, Loss: 1.2907 \n",
      "trigger times: 70\n",
      "Epoch: 158, Loss: 1.2637 \n",
      "trigger times: 71\n",
      "Epoch: 159, Loss: 1.2894 \n",
      "trigger times: 72\n",
      "Epoch: 160, Loss: 1.2783 \n",
      "trigger times: 73\n",
      "Epoch: 161, Loss: 1.2554 \n",
      "Epoch: 162, Loss: 1.2855 \n",
      "trigger times: 1\n",
      "Epoch: 163, Loss: 1.2663 \n",
      "trigger times: 2\n",
      "Epoch: 164, Loss: 1.2756 \n",
      "trigger times: 3\n",
      "Epoch: 165, Loss: 1.2827 \n",
      "trigger times: 4\n",
      "Epoch: 166, Loss: 1.2832 \n",
      "trigger times: 5\n",
      "Epoch: 167, Loss: 1.2709 \n",
      "trigger times: 6\n",
      "Epoch: 168, Loss: 1.2819 \n",
      "trigger times: 7\n",
      "Epoch: 169, Loss: 1.2949 \n",
      "trigger times: 8\n",
      "Epoch: 170, Loss: 1.2996 \n",
      "trigger times: 9\n",
      "Epoch: 171, Loss: 1.2883 \n",
      "trigger times: 10\n",
      "Epoch: 172, Loss: 1.2921 \n",
      "trigger times: 11\n",
      "Epoch: 173, Loss: 1.2809 \n",
      "trigger times: 12\n",
      "Epoch: 174, Loss: 1.2702 \n",
      "trigger times: 13\n",
      "Epoch: 175, Loss: 1.2723 \n",
      "trigger times: 14\n",
      "Epoch: 176, Loss: 1.2678 \n",
      "trigger times: 15\n",
      "Epoch: 177, Loss: 1.2787 \n",
      "trigger times: 16\n",
      "Epoch: 178, Loss: 1.2757 \n",
      "trigger times: 17\n",
      "Epoch: 179, Loss: 1.2739 \n",
      "trigger times: 18\n",
      "Epoch: 180, Loss: 1.2881 \n",
      "trigger times: 19\n",
      "Epoch: 181, Loss: 1.2698 \n",
      "trigger times: 20\n",
      "Epoch: 182, Loss: 1.2731 \n",
      "trigger times: 21\n",
      "Epoch: 183, Loss: 1.2658 \n",
      "trigger times: 22\n",
      "Epoch: 184, Loss: 1.2597 \n",
      "trigger times: 23\n",
      "Epoch: 185, Loss: 1.2670 \n",
      "trigger times: 24\n",
      "Epoch: 186, Loss: 1.2931 \n",
      "trigger times: 25\n",
      "Epoch: 187, Loss: 1.2991 \n",
      "trigger times: 26\n",
      "Epoch: 188, Loss: 1.2702 \n",
      "trigger times: 27\n",
      "Epoch: 189, Loss: 1.2711 \n",
      "trigger times: 28\n",
      "Epoch: 190, Loss: 1.2508 \n",
      "Epoch: 191, Loss: 1.2744 \n",
      "trigger times: 1\n",
      "Epoch: 192, Loss: 1.2962 \n",
      "trigger times: 2\n",
      "Epoch: 193, Loss: 1.2863 \n",
      "trigger times: 3\n",
      "Epoch: 194, Loss: 1.2768 \n",
      "trigger times: 4\n",
      "Epoch: 195, Loss: 1.2967 \n",
      "trigger times: 5\n",
      "Epoch: 196, Loss: 1.2677 \n",
      "trigger times: 6\n",
      "Epoch: 197, Loss: 1.2664 \n",
      "trigger times: 7\n",
      "Epoch: 198, Loss: 1.2776 \n",
      "trigger times: 8\n",
      "Epoch: 199, Loss: 1.2650 \n",
      "trigger times: 9\n",
      "Epoch: 000, Loss: 1.3024 \n",
      "Epoch: 001, Loss: 1.3183 \n",
      "trigger times: 1\n",
      "Epoch: 002, Loss: 1.3288 \n",
      "trigger times: 2\n",
      "Epoch: 003, Loss: 1.3019 \n",
      "Epoch: 004, Loss: 1.2964 \n",
      "Epoch: 005, Loss: 1.2855 \n",
      "Epoch: 006, Loss: 1.2979 \n",
      "trigger times: 1\n",
      "Epoch: 007, Loss: 1.3085 \n",
      "trigger times: 2\n",
      "Epoch: 008, Loss: 1.2996 \n",
      "trigger times: 3\n",
      "Epoch: 009, Loss: 1.3028 \n",
      "trigger times: 4\n",
      "Epoch: 010, Loss: 1.3262 \n",
      "trigger times: 5\n",
      "Epoch: 011, Loss: 1.2968 \n",
      "trigger times: 6\n",
      "Epoch: 012, Loss: 1.2885 \n",
      "trigger times: 7\n",
      "Epoch: 013, Loss: 1.2777 \n",
      "Epoch: 014, Loss: 1.2944 \n",
      "trigger times: 1\n",
      "Epoch: 015, Loss: 1.3031 \n",
      "trigger times: 2\n",
      "Epoch: 016, Loss: 1.3052 \n",
      "trigger times: 3\n",
      "Epoch: 017, Loss: 1.2943 \n",
      "trigger times: 4\n",
      "Epoch: 018, Loss: 1.2951 \n",
      "trigger times: 5\n",
      "Epoch: 019, Loss: 1.2905 \n",
      "trigger times: 6\n",
      "Epoch: 020, Loss: 1.3016 \n",
      "trigger times: 7\n",
      "Epoch: 021, Loss: 1.2938 \n",
      "trigger times: 8\n",
      "Epoch: 022, Loss: 1.2835 \n",
      "trigger times: 9\n",
      "Epoch: 023, Loss: 1.2911 \n",
      "trigger times: 10\n",
      "Epoch: 024, Loss: 1.2750 \n",
      "Epoch: 025, Loss: 1.2632 \n",
      "Epoch: 026, Loss: 1.2994 \n",
      "trigger times: 1\n",
      "Epoch: 027, Loss: 1.2920 \n",
      "trigger times: 2\n",
      "Epoch: 028, Loss: 1.2874 \n",
      "trigger times: 3\n",
      "Epoch: 029, Loss: 1.2685 \n",
      "trigger times: 4\n",
      "Epoch: 030, Loss: 1.2732 \n",
      "trigger times: 5\n",
      "Epoch: 031, Loss: 1.3002 \n",
      "trigger times: 6\n",
      "Epoch: 032, Loss: 1.2826 \n",
      "trigger times: 7\n",
      "Epoch: 033, Loss: 1.2843 \n",
      "trigger times: 8\n",
      "Epoch: 034, Loss: 1.2708 \n",
      "trigger times: 9\n",
      "Epoch: 035, Loss: 1.3026 \n",
      "trigger times: 10\n",
      "Epoch: 036, Loss: 1.2869 \n",
      "trigger times: 11\n",
      "Epoch: 037, Loss: 1.2796 \n",
      "trigger times: 12\n",
      "Epoch: 038, Loss: 1.2730 \n",
      "trigger times: 13\n",
      "Epoch: 039, Loss: 1.2664 \n",
      "trigger times: 14\n",
      "Epoch: 040, Loss: 1.2716 \n",
      "trigger times: 15\n",
      "Epoch: 041, Loss: 1.2748 \n",
      "trigger times: 16\n",
      "Epoch: 042, Loss: 1.2864 \n",
      "trigger times: 17\n",
      "Epoch: 043, Loss: 1.2880 \n",
      "trigger times: 18\n",
      "Epoch: 044, Loss: 1.2716 \n",
      "trigger times: 19\n",
      "Epoch: 045, Loss: 1.2785 \n",
      "trigger times: 20\n",
      "Epoch: 046, Loss: 1.2721 \n",
      "trigger times: 21\n",
      "Epoch: 047, Loss: 1.2681 \n",
      "trigger times: 22\n",
      "Epoch: 048, Loss: 1.2721 \n",
      "trigger times: 23\n",
      "Epoch: 049, Loss: 1.3055 \n",
      "trigger times: 24\n",
      "Epoch: 050, Loss: 1.2730 \n",
      "trigger times: 25\n",
      "Epoch: 051, Loss: 1.2597 \n",
      "Epoch: 052, Loss: 1.2803 \n",
      "trigger times: 1\n",
      "Epoch: 053, Loss: 1.2924 \n",
      "trigger times: 2\n",
      "Epoch: 054, Loss: 1.2599 \n",
      "trigger times: 3\n",
      "Epoch: 055, Loss: 1.2867 \n",
      "trigger times: 4\n",
      "Epoch: 056, Loss: 1.2788 \n",
      "trigger times: 5\n",
      "Epoch: 057, Loss: 1.2657 \n",
      "trigger times: 6\n",
      "Epoch: 058, Loss: 1.2856 \n",
      "trigger times: 7\n",
      "Epoch: 059, Loss: 1.2824 \n",
      "trigger times: 8\n",
      "Epoch: 060, Loss: 1.2573 \n",
      "Epoch: 061, Loss: 1.2764 \n",
      "trigger times: 1\n",
      "Epoch: 062, Loss: 1.2865 \n",
      "trigger times: 2\n",
      "Epoch: 063, Loss: 1.2829 \n",
      "trigger times: 3\n",
      "Epoch: 064, Loss: 1.2736 \n",
      "trigger times: 4\n",
      "Epoch: 065, Loss: 1.2692 \n",
      "trigger times: 5\n",
      "Epoch: 066, Loss: 1.2743 \n",
      "trigger times: 6\n",
      "Epoch: 067, Loss: 1.2588 \n",
      "trigger times: 7\n",
      "Epoch: 068, Loss: 1.2815 \n",
      "trigger times: 8\n",
      "Epoch: 069, Loss: 1.2765 \n",
      "trigger times: 9\n",
      "Epoch: 070, Loss: 1.2690 \n",
      "trigger times: 10\n",
      "Epoch: 071, Loss: 1.2896 \n",
      "trigger times: 11\n",
      "Epoch: 072, Loss: 1.2816 \n",
      "trigger times: 12\n",
      "Epoch: 073, Loss: 1.2721 \n",
      "trigger times: 13\n",
      "Epoch: 074, Loss: 1.2682 \n",
      "trigger times: 14\n",
      "Epoch: 075, Loss: 1.2608 \n",
      "trigger times: 15\n",
      "Epoch: 076, Loss: 1.2716 \n",
      "trigger times: 16\n",
      "Epoch: 077, Loss: 1.2837 \n",
      "trigger times: 17\n",
      "Epoch: 078, Loss: 1.2888 \n",
      "trigger times: 18\n",
      "Epoch: 079, Loss: 1.2615 \n",
      "trigger times: 19\n",
      "Epoch: 080, Loss: 1.2763 \n",
      "trigger times: 20\n",
      "Epoch: 081, Loss: 1.2847 \n",
      "trigger times: 21\n",
      "Epoch: 082, Loss: 1.2691 \n",
      "trigger times: 22\n",
      "Epoch: 083, Loss: 1.2703 \n",
      "trigger times: 23\n",
      "Epoch: 084, Loss: 1.2870 \n",
      "trigger times: 24\n",
      "Epoch: 085, Loss: 1.2745 \n",
      "trigger times: 25\n",
      "Epoch: 086, Loss: 1.2891 \n",
      "trigger times: 26\n",
      "Epoch: 087, Loss: 1.2984 \n",
      "trigger times: 27\n",
      "Epoch: 088, Loss: 1.2650 \n",
      "trigger times: 28\n",
      "Epoch: 089, Loss: 1.2843 \n",
      "trigger times: 29\n",
      "Epoch: 090, Loss: 1.2892 \n",
      "trigger times: 30\n",
      "Epoch: 091, Loss: 1.2711 \n",
      "trigger times: 31\n",
      "Epoch: 092, Loss: 1.2658 \n",
      "trigger times: 32\n",
      "Epoch: 093, Loss: 1.2908 \n",
      "trigger times: 33\n",
      "Epoch: 094, Loss: 1.2689 \n",
      "trigger times: 34\n",
      "Epoch: 095, Loss: 1.2728 \n",
      "trigger times: 35\n",
      "Epoch: 096, Loss: 1.2770 \n",
      "trigger times: 36\n",
      "Epoch: 097, Loss: 1.2753 \n",
      "trigger times: 37\n",
      "Epoch: 098, Loss: 1.2853 \n",
      "trigger times: 38\n",
      "Epoch: 099, Loss: 1.2784 \n",
      "trigger times: 39\n",
      "Epoch: 100, Loss: 1.2752 \n",
      "trigger times: 40\n",
      "Epoch: 101, Loss: 1.2875 \n",
      "trigger times: 41\n",
      "Epoch: 102, Loss: 1.2611 \n",
      "trigger times: 42\n",
      "Epoch: 103, Loss: 1.2742 \n",
      "trigger times: 43\n",
      "Epoch: 104, Loss: 1.2781 \n",
      "trigger times: 44\n",
      "Epoch: 105, Loss: 1.2857 \n",
      "trigger times: 45\n",
      "Epoch: 106, Loss: 1.2589 \n",
      "trigger times: 46\n",
      "Epoch: 107, Loss: 1.2783 \n",
      "trigger times: 47\n",
      "Epoch: 108, Loss: 1.2560 \n",
      "Epoch: 109, Loss: 1.2764 \n",
      "trigger times: 1\n",
      "Epoch: 110, Loss: 1.3023 \n",
      "trigger times: 2\n",
      "Epoch: 111, Loss: 1.3212 \n",
      "trigger times: 3\n",
      "Epoch: 112, Loss: 1.2917 \n",
      "trigger times: 4\n",
      "Epoch: 113, Loss: 1.2840 \n",
      "trigger times: 5\n",
      "Epoch: 114, Loss: 1.3022 \n",
      "trigger times: 6\n",
      "Epoch: 115, Loss: 1.2985 \n",
      "trigger times: 7\n",
      "Epoch: 116, Loss: 1.2730 \n",
      "trigger times: 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 117, Loss: 1.2746 \n",
      "trigger times: 9\n",
      "Epoch: 118, Loss: 1.2632 \n",
      "trigger times: 10\n",
      "Epoch: 119, Loss: 1.2605 \n",
      "trigger times: 11\n",
      "Epoch: 120, Loss: 1.2846 \n",
      "trigger times: 12\n",
      "Epoch: 121, Loss: 1.2732 \n",
      "trigger times: 13\n",
      "Epoch: 122, Loss: 1.2607 \n",
      "trigger times: 14\n",
      "Epoch: 123, Loss: 1.2661 \n",
      "trigger times: 15\n",
      "Epoch: 124, Loss: 1.2624 \n",
      "trigger times: 16\n",
      "Epoch: 125, Loss: 1.2698 \n",
      "trigger times: 17\n",
      "Epoch: 126, Loss: 1.2871 \n",
      "trigger times: 18\n",
      "Epoch: 127, Loss: 1.2985 \n",
      "trigger times: 19\n",
      "Epoch: 128, Loss: 1.2640 \n",
      "trigger times: 20\n",
      "Epoch: 129, Loss: 1.2819 \n",
      "trigger times: 21\n",
      "Epoch: 130, Loss: 1.2732 \n",
      "trigger times: 22\n",
      "Epoch: 131, Loss: 1.2764 \n",
      "trigger times: 23\n",
      "Epoch: 132, Loss: 1.2558 \n",
      "Epoch: 133, Loss: 1.2658 \n",
      "trigger times: 1\n",
      "Epoch: 134, Loss: 1.2758 \n",
      "trigger times: 2\n",
      "Epoch: 135, Loss: 1.2699 \n",
      "trigger times: 3\n",
      "Epoch: 136, Loss: 1.2777 \n",
      "trigger times: 4\n",
      "Epoch: 137, Loss: 1.2903 \n",
      "trigger times: 5\n",
      "Epoch: 138, Loss: 1.2827 \n",
      "trigger times: 6\n",
      "Epoch: 139, Loss: 1.2689 \n",
      "trigger times: 7\n",
      "Epoch: 140, Loss: 1.2768 \n",
      "trigger times: 8\n",
      "Epoch: 141, Loss: 1.2863 \n",
      "trigger times: 9\n",
      "Epoch: 142, Loss: 1.2845 \n",
      "trigger times: 10\n",
      "Epoch: 143, Loss: 1.2879 \n",
      "trigger times: 11\n",
      "Epoch: 144, Loss: 1.2837 \n",
      "trigger times: 12\n",
      "Epoch: 145, Loss: 1.3002 \n",
      "trigger times: 13\n",
      "Epoch: 146, Loss: 1.2724 \n",
      "trigger times: 14\n",
      "Epoch: 147, Loss: 1.2640 \n",
      "trigger times: 15\n",
      "Epoch: 148, Loss: 1.2689 \n",
      "trigger times: 16\n",
      "Epoch: 149, Loss: 1.2600 \n",
      "trigger times: 17\n",
      "Epoch: 150, Loss: 1.2713 \n",
      "trigger times: 18\n",
      "Epoch: 151, Loss: 1.2609 \n",
      "trigger times: 19\n",
      "Epoch: 152, Loss: 1.2899 \n",
      "trigger times: 20\n",
      "Epoch: 153, Loss: 1.2719 \n",
      "trigger times: 21\n",
      "Epoch: 154, Loss: 1.2746 \n",
      "trigger times: 22\n",
      "Epoch: 155, Loss: 1.2781 \n",
      "trigger times: 23\n",
      "Epoch: 156, Loss: 1.2631 \n",
      "trigger times: 24\n",
      "Epoch: 157, Loss: 1.2669 \n",
      "trigger times: 25\n",
      "Epoch: 158, Loss: 1.2793 \n",
      "trigger times: 26\n",
      "Epoch: 159, Loss: 1.2702 \n",
      "trigger times: 27\n",
      "Epoch: 160, Loss: 1.2786 \n",
      "trigger times: 28\n",
      "Epoch: 161, Loss: 1.2718 \n",
      "trigger times: 29\n",
      "Epoch: 162, Loss: 1.2924 \n",
      "trigger times: 30\n",
      "Epoch: 163, Loss: 1.2785 \n",
      "trigger times: 31\n",
      "Epoch: 164, Loss: 1.2698 \n",
      "trigger times: 32\n",
      "Epoch: 165, Loss: 1.2722 \n",
      "trigger times: 33\n",
      "Epoch: 166, Loss: 1.2618 \n",
      "trigger times: 34\n",
      "Epoch: 167, Loss: 1.2741 \n",
      "trigger times: 35\n",
      "Epoch: 168, Loss: 1.2614 \n",
      "trigger times: 36\n",
      "Epoch: 169, Loss: 1.2883 \n",
      "trigger times: 37\n",
      "Epoch: 170, Loss: 1.2788 \n",
      "trigger times: 38\n",
      "Epoch: 171, Loss: 1.3067 \n",
      "trigger times: 39\n",
      "Epoch: 172, Loss: 1.2740 \n",
      "trigger times: 40\n",
      "Epoch: 173, Loss: 1.2779 \n",
      "trigger times: 41\n",
      "Epoch: 174, Loss: 1.2861 \n",
      "trigger times: 42\n",
      "Epoch: 175, Loss: 1.2587 \n",
      "trigger times: 43\n",
      "Epoch: 176, Loss: 1.2989 \n",
      "trigger times: 44\n",
      "Epoch: 177, Loss: 1.2851 \n",
      "trigger times: 45\n",
      "Epoch: 178, Loss: 1.3058 \n",
      "trigger times: 46\n",
      "Epoch: 179, Loss: 1.3022 \n",
      "trigger times: 47\n",
      "Epoch: 180, Loss: 1.2519 \n",
      "Epoch: 181, Loss: 1.2613 \n",
      "trigger times: 1\n",
      "Epoch: 182, Loss: 1.2851 \n",
      "trigger times: 2\n",
      "Epoch: 183, Loss: 1.2712 \n",
      "trigger times: 3\n",
      "Epoch: 184, Loss: 1.2903 \n",
      "trigger times: 4\n",
      "Epoch: 185, Loss: 1.2584 \n",
      "trigger times: 5\n",
      "Epoch: 186, Loss: 1.2724 \n",
      "trigger times: 6\n",
      "Epoch: 187, Loss: 1.2879 \n",
      "trigger times: 7\n",
      "Epoch: 188, Loss: 1.2990 \n",
      "trigger times: 8\n",
      "Epoch: 189, Loss: 1.2693 \n",
      "trigger times: 9\n",
      "Epoch: 190, Loss: 1.2929 \n",
      "trigger times: 10\n",
      "Epoch: 191, Loss: 1.2802 \n",
      "trigger times: 11\n",
      "Epoch: 192, Loss: 1.2728 \n",
      "trigger times: 12\n",
      "Epoch: 193, Loss: 1.2826 \n",
      "trigger times: 13\n",
      "Epoch: 194, Loss: 1.2731 \n",
      "trigger times: 14\n",
      "Epoch: 195, Loss: 1.2895 \n",
      "trigger times: 15\n",
      "Epoch: 196, Loss: 1.2640 \n",
      "trigger times: 16\n",
      "Epoch: 197, Loss: 1.2772 \n",
      "trigger times: 17\n",
      "Epoch: 198, Loss: 1.2827 \n",
      "trigger times: 18\n",
      "Epoch: 199, Loss: 1.2761 \n",
      "trigger times: 19\n"
     ]
    }
   ],
   "source": [
    "# training whole dataset. first loading each fold model and train on whole dataset\n",
    "folds = 10\n",
    "results = []\n",
    "best_rmse_arr = []\n",
    "scores = []\n",
    "true_val = []\n",
    "pred_val = []\n",
    "wholetrain_data = createTestData('Data_Prep','solubility_1.csv','solubility_1')\n",
    "for fold in tqdm(range(folds)):\n",
    "    wholetrain_loader  = DataLoader(wholetrain_data,batch_size=TRAIN_BATCH_SIZE,shuffle=True)\n",
    "    model = AttentionConvNet().to(device)\n",
    "    # model = define_model(trial).to(device)\n",
    "    #optimizer_name = trial.suggest_categorical(\"optimizer\", [\"Adam\", \"RMSprop\", \"SGD\"])\n",
    "    # optimizer = torch.optim.Adam(model.parameters(), lr=.0023467,\n",
    "    #                              weight_decay=.00095)\n",
    "#     optimizer = torch.optim.Adam(model.parameters(), lr=0.007531829,\n",
    "#                                    weight_decay=0.000252036)\n",
    "#     model = AttentiveFP(in_channels=39, hidden_channels=200, out_channels=1,\n",
    "#                     edge_dim=10, num_layers=2, num_timesteps=2,\n",
    "#                     dropout=0.2).to(device)\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate,\n",
    "                             weight_decay=weight_decay)\n",
    "    val_losses = []\n",
    "    train_losses = []\n",
    "    mae_arr = []\n",
    "    patience = 30\n",
    "    trigger_times = 0\n",
    "    the_last_loss = 100\n",
    "    \n",
    "    load_model_file_name = 'saved_models/model_' +  str(fold) +  '.model'\n",
    "    model_file_name = 'saved_models/wholetrainmodel_' +  str(fold) +  '.model'\n",
    "    result_file_name = 'wholetrainresult_' + str(fold) +  '.csv'\n",
    "    checkpoint = torch.load(load_model_file_name, map_location=torch.device(device))\n",
    "    model.load_state_dict(checkpoint)\n",
    "    train_data = Molecule_data(root='data', dataset='train_data_set_fold_'+str(fold),y=None,smile_graph=None,smiles=None)\n",
    "#     test_data = Molecule_data(root='data', dataset='test_data_set_fold_'+str(fold),y=None,smile_graph=None,smiles=None)\n",
    "    \n",
    "#     TRAIN_BATCH_SIZE = 64\n",
    "    \n",
    "#     train_loader   = DataLoader(train_data,batch_size=TRAIN_BATCH_SIZE,shuffle=True)\n",
    "#     test_loader  = DataLoader(test_data,batch_size=TRAIN_BATCH_SIZE,shuffle=True)\n",
    "#     model = AttentiveFP(in_channels=112, hidden_channels=279, out_channels=1,\n",
    "#                     num_layers=3, num_timesteps=2,\n",
    "#                     dropout=0.047352327938708194).to(device)\n",
    "    best_ret = []\n",
    "    \n",
    "#     model = model.cuda(device)\n",
    "#     optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "#     best_mae = 0.00\n",
    "    \n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        train_loss,train_rmse=train(model, optimizer,train_loader)\n",
    "#         test_loss,test_rmse = test(test_loader, model)\n",
    "#         score = metrics.r2_score(true, prediction)\n",
    "#         , true, prediction\n",
    "        \n",
    "        print(f'Epoch: {epoch:03d}, Loss: {train_rmse:.4f} '\n",
    "          ) #f'Test: {test_rmse:.4f} 'f'score: {score:.4f} '   \n",
    "        \n",
    "        ret = [epoch,train_rmse]\n",
    "        \n",
    "        train_losses.append(train_rmse)\n",
    "#         val_losses.append(test_rmse)\n",
    "#         scores.append(score)\n",
    "        # Early Stopping\n",
    "        the_current_loss = train_rmse   #.item()\n",
    "        best_ret.append(ret)\n",
    "        if the_current_loss > the_last_loss:\n",
    "            trigger_times += 1\n",
    "            print('trigger times:', trigger_times)\n",
    "    \n",
    "            if trigger_times >= 200:   #patience\n",
    "                print('Early stopping!\\nStart to test process.')\n",
    "                break\n",
    "        else:\n",
    "            ret = [epoch,train_rmse] #, ,test_rmse, score\n",
    "            trigger_times = 0\n",
    "            the_last_loss = the_current_loss\n",
    "            best_rmse = the_current_loss\n",
    "            \n",
    "            torch.save(model.state_dict(), model_file_name)\n",
    "        # Early stopping\n",
    "#         the_current_loss = test_loss.item()\n",
    "        \n",
    "#         best_ret.append(ret)\n",
    "        \n",
    "#         if the_current_loss > the_last_loss:\n",
    "#             trigger_times += 1\n",
    "#             print('trigger times:', trigger_times)\n",
    "            \n",
    "#             if trigger_times >= patience:\n",
    "#                 print('Early stopping!\\nStart to test process.')\n",
    "#                 break\n",
    "#         else:\n",
    "#             ret = [epoch,train_loss,test_loss.item()]\n",
    "#             trigger_times = 0\n",
    "#             best_mae = the_current_loss\n",
    "#             the_last_loss = the_current_loss\n",
    "            \n",
    "#             torch.save(model.state_dict(), model_file_name)\n",
    "\n",
    "    results.append(best_ret)\n",
    "    best_rmse_arr.append(best_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "noveltest_data = createTestData('New_fold','testset_novel.csv','testset_novel')\n",
    "# noveltest_data = Molecule_data(root='data', dataset='testset_novel',y=None,smile_graph=None,smiles=None)\n",
    "# noveltest_loader  = DataLoader(noveltest_data,batch_size=TRAIN_BATCH_SIZE,shuffle=True)\n",
    "#     model = AttentiveFP(in_channels=112, hidden_channels=279, out_channels=1,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aaaaadaaa2904e38b3b0104fff244bea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test R2:  -0.3722552284381133\n",
      "Test RMSE: 1.0402326376854274\n",
      "Test R2:  -0.3293383950495463\n",
      "Test RMSE: 1.0238368296335063\n",
      "Test R2:  0.19496060676094606\n",
      "Test RMSE: 0.7967490302356173\n",
      "Test R2:  0.11180247270791832\n",
      "Test RMSE: 0.8368888503987569\n",
      "Test R2:  0.08157689697427473\n",
      "Test RMSE: 0.8510094692967483\n",
      "Test R2:  0.04345770656160519\n",
      "Test RMSE: 0.8684905289049544\n",
      "Test R2:  -0.24601657688629985\n",
      "Test RMSE: 0.991231051837554\n",
      "Test R2:  -0.06026466984586887\n",
      "Test RMSE: 0.9143661581512806\n",
      "Test R2:  0.08074396672796025\n",
      "Test RMSE: 0.851395266849372\n",
      "Test R2:  0.18161184566778732\n",
      "Test RMSE: 0.8033275408225997\n"
     ]
    }
   ],
   "source": [
    "# test novel dataset on whole trained model.\n",
    "from sklearn import model_selection, preprocessing, metrics, decomposition\n",
    "import matplotlib.pyplot as plt\n",
    "folds = 10\n",
    "results = []\n",
    "best_rmse_arr = []\n",
    "bestrmsesum = 0\n",
    "scores = []\n",
    "true_val = []\n",
    "pred_val = []\n",
    "# fig = plt.figure()\n",
    "# for fold in tqdm(range(folds)):\n",
    "# val_losses = []\n",
    "# train_losses = []\n",
    "# mae_arr = []\n",
    "# patience = 30\n",
    "# trigger_times = 0\n",
    "# the_last_loss = 100\n",
    "for fold in tqdm(range(folds)):\n",
    "    noveltest_loader  = DataLoader(noveltest_data,batch_size=TRAIN_BATCH_SIZE,shuffle=True)\n",
    "    model = AttentionConvNet().to(device)\n",
    "    # model = define_model(trial).to(device)\n",
    "    #optimizer_name = trial.suggest_categorical(\"optimizer\", [\"Adam\", \"RMSprop\", \"SGD\"])\n",
    "    # optimizer = torch.optim.Adam(model.parameters(), lr=.0023467,\n",
    "    #                              weight_decay=.00095)\n",
    "#     optimizer = torch.optim.Adam(model.parameters(), lr=0.007531829,\n",
    "#                                    weight_decay=0.000252036)\n",
    "#     model = AttentiveFP(in_channels=39, hidden_channels=200, out_channels=1,\n",
    "#                     edge_dim=10, num_layers=2, num_timesteps=2,\n",
    "#                     dropout=0.2).to(device)\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate,\n",
    "                             weight_decay=weight_decay)\n",
    "    val_losses = []\n",
    "    train_losses = []\n",
    "    mae_arr = []\n",
    "    patience = 30\n",
    "    trigger_times = 0\n",
    "    the_last_loss = 100\n",
    "    \n",
    "    model_file_name = 'saved_models/wholetrainmodel_' +  str(fold) +  '.model'\n",
    "    checkpoint = torch.load(model_file_name, map_location=torch.device(device))\n",
    "    model.load_state_dict(checkpoint)\n",
    "#     train_data = Molecule_data(root='data', dataset='train_data_set_fold_'+str(fold),y=None,smile_graph=None,smiles=None)\n",
    "    test_loss,test_rmse, true, prediction = predicting(noveltest_loader, model)\n",
    "\n",
    "    best_ret = []\n",
    "    bestrmsesum = bestrmsesum + test_rmse\n",
    "    results.append(best_ret)\n",
    "    best_rmse_arr.append(best_rmse)\n",
    "    true_val.append(true)\n",
    "    pred_val.append(prediction)\n",
    "    score = metrics.r2_score(true, prediction)\n",
    "    scores.append(score)\n",
    "    print('Test R2: ', score)\n",
    "    print('Test RMSE:', test_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5db441f7bad4977ae065c0d1a86c95d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test R2:  -0.23047046753848743\n",
      "Test RMSE: 0.9850280351570297\n",
      "Test R2:  -0.20715626427090328\n",
      "Test RMSE: 0.9756515832147131\n",
      "Test R2:  -0.4215596003751987\n",
      "Test RMSE: 1.0587551655468816\n",
      "Test R2:  -0.2937654909750733\n",
      "Test RMSE: 1.0100450848440694\n",
      "Test R2:  -0.10334470509976246\n",
      "Test RMSE: 0.9327571743863304\n",
      "Test R2:  -0.6320166401800056\n",
      "Test RMSE: 1.1344236820588482\n",
      "Test R2:  -0.01823157064816483\n",
      "Test RMSE: 0.8960583241651369\n",
      "Test R2:  -0.9729481295278775\n",
      "Test RMSE: 1.2472997109390715\n",
      "Test R2:  -0.5871375018667397\n",
      "Test RMSE: 1.1187170801700368\n",
      "Test R2:  -0.8008077764165042\n",
      "Test RMSE: 1.191644363372447\n"
     ]
    }
   ],
   "source": [
    "# test novel dataset on whole trained model.\n",
    "from sklearn import model_selection, preprocessing, metrics, decomposition\n",
    "import matplotlib.pyplot as plt\n",
    "folds = 10\n",
    "results = []\n",
    "best_rmse_arr = []\n",
    "bestrmsesum = 0\n",
    "scores = []\n",
    "true_val = []\n",
    "pred_val = []\n",
    "for fold in tqdm(range(folds)):\n",
    "    noveltest_loader  = DataLoader(noveltest_data,batch_size=TRAIN_BATCH_SIZE,shuffle=True)\n",
    "    model = AttentionConvNet().to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate,\n",
    "                             weight_decay=weight_decay)\n",
    "    val_losses = []\n",
    "    train_losses = []\n",
    "    mae_arr = []\n",
    "    patience = 30\n",
    "    trigger_times = 0\n",
    "    the_last_loss = 100\n",
    "    \n",
    "    model_file_name = 'saved_models/model_' +  str(fold) +  '.model'\n",
    "    checkpoint = torch.load(model_file_name, map_location=torch.device(device))\n",
    "    model.load_state_dict(checkpoint)\n",
    "#     train_data = Molecule_data(root='data', dataset='train_data_set_fold_'+str(fold),y=None,smile_graph=None,smiles=None)\n",
    "    test_loss,test_rmse, true, prediction = predicting(noveltest_loader, model)\n",
    "\n",
    "    best_ret = []\n",
    "    bestrmsesum = bestrmsesum + test_rmse\n",
    "    results.append(best_ret)\n",
    "    best_rmse_arr.append(best_rmse)\n",
    "    true_val.append(true)\n",
    "    pred_val.append(prediction)\n",
    "    score = metrics.r2_score(true, prediction)\n",
    "    scores.append(score)\n",
    "    print('Test R2: ', score)\n",
    "    print('Test RMSE:', test_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
